{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each dataset (2 HR, 2 SR, 4 SLO):\n",
    "\n",
    "    - For each model (XLM-R-base, XLM-R-large, CSEBert, SloBERTa, BERTić, multiple versions of XLM-R-BERTić and XLM-R-SloBERTić):\n",
    "\n",
    "\n",
    "        - fine-tune the model and evaluate it - 5 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m data_dict \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39msentence_id\u001b[39m\u001b[39m\"\u001b[39m: sent_id_list, \u001b[39m\"\u001b[39m\u001b[39mwords\u001b[39m\u001b[39m\"\u001b[39m: word_list, \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m: NER_list, \u001b[39m\"\u001b[39m\u001b[39mdoc_ids\u001b[39m\u001b[39m\"\u001b[39m: doc_list}\n\u001b[1;32m     46\u001b[0m \u001b[39m# Create a pandas df out of the dictionary\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(data_dict)\n\u001b[1;32m     49\u001b[0m LABELS \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(df\u001b[39m.\u001b[39mlabels\u001b[39m.\u001b[39munique())\n\u001b[1;32m     50\u001b[0m \u001b[39m# If * is used, change * to O, because this causes errors\u001b[39;00m\n",
      "File \u001b[0;32m~/NER-recognition/ner/lib/python3.8/site-packages/pandas/core/frame.py:709\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    703\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[1;32m    704\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[1;32m    705\u001b[0m     )\n\u001b[1;32m    707\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    708\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 709\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[1;32m    710\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[1;32m    711\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m \u001b[39mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/NER-recognition/ner/lib/python3.8/site-packages/pandas/core/internals/construction.py:481\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    479\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[0;32m--> 481\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[0;32m~/NER-recognition/ner/lib/python3.8/site-packages/pandas/core/internals/construction.py:115\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    113\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[1;32m    116\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/NER-recognition/ner/lib/python3.8/site-packages/pandas/core/internals/construction.py:655\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    653\u001b[0m lengths \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(raw_lengths))\n\u001b[1;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(lengths) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAll arrays must be of the same length\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    657\u001b[0m \u001b[39mif\u001b[39;00m have_dicts:\n\u001b[1;32m    658\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    659\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    660\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "from conllu import parse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Loop through all the datasets if there are multiple datasets for one scenario\n",
    "doc = \"Janes-Tag.3.0.CoNLL-U/janes-tag.ud.conllu\"\n",
    "\n",
    "scenario = \"ns_Slovene\"\n",
    "\n",
    "# Open the dataset\n",
    "data = open(\"{}\".format(doc), \"r\").read()\n",
    "\n",
    "# Parse conllu file\n",
    "sentences = parse(data)\n",
    "\n",
    "word_list = []\n",
    "sent_id_list = []\n",
    "NER_list = []\n",
    "split_list = []\n",
    "doc_list = []\n",
    "\n",
    "# Slovene corpora are not split into train, dev, test splits and have NER information under different keys than Croatian and Serbian\n",
    "if \"Slovene\" in scenario:\n",
    "\t# Collect all important information from the dataset\n",
    "\tfor sentence in sentences:\n",
    "\t\tcurrent_sent_id = sentence.metadata[\"sent_id\"]\n",
    "\n",
    "\t# Extract doc_ids and create a list of doc_ids\n",
    "\t\tif sentence.metadata.get(\"newdoc id\", None) != None:\n",
    "\t\t\tcurrent_doc_id = sentence.metadata[\"newdoc id\"]\n",
    "\t\t# If sentence does not have a new doc id, use the one from the previous sentence that has it\n",
    "\n",
    "\t\tfor token in sentence:\n",
    "\t\t\tcurrent_word = token[\"form\"]\n",
    "\t\t\tcurrent_ner = token[\"misc\"][\"NER\"]\n",
    "\n",
    "\t\t\tword_list.append(current_word)\n",
    "\t\t\tsent_id_list.append(current_sent_id)\n",
    "\t\t\tNER_list.append(current_ner)\n",
    "\t\t\tdoc_list.append(current_doc_id)\n",
    "\n",
    "\n",
    "\t# Create a dictionary for all words and all needed information\n",
    "\tdata_dict = {\"sentence_id\": sent_id_list, \"words\": word_list, \"labels\": NER_list, \"doc_ids\": doc_list}\n",
    "\n",
    "\t# Create a pandas df out of the dictionary\n",
    "\tdf = pd.DataFrame(data_dict)\n",
    "\n",
    "\tLABELS = list(df.labels.unique())\n",
    "\t# If * is used, change * to O, because this causes errors\n",
    "\tif \"*\" in LABELS:\n",
    "\t\tLABELS[LABELS.index(\"*\")] = \"O\"\n",
    "\n",
    "\t\tdf[\"labels\"] = np.where(df[\"labels\"] == \"*\", \"O\", df[\"labels\"])\n",
    "\n",
    "\t# Show the df\n",
    "\tprint(df.head())\n",
    "\tprint(\"\\n\")\n",
    "\tprint(df.describe(include=\"all\"))\n",
    "\tprint(\"\\n\")\n",
    "\tprint(df.labels.value_counts(normalize=True))\n",
    "\tprint(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset based on doc ids in a 80:10:10 ratio\n",
    "doc_ids = list(df[\"doc_ids\"].unique())\n",
    "\n",
    "# Shuffle the doc_ids randomly\n",
    "random.shuffle(doc_ids)\n",
    "\n",
    "# Calculate the number of doc_ids for each split\n",
    "total_docs = len(doc_ids)\n",
    "train_size = int(0.8 * total_docs)\n",
    "test_size = int(0.1 * total_docs)\n",
    "dev_size = total_docs - train_size - test_size\n",
    "\n",
    "# Split the shuffled doc_ids into train, test, and dev sets\n",
    "train_ids = doc_ids[:train_size]\n",
    "test_ids = doc_ids[train_size:train_size + test_size]\n",
    "dev_ids = doc_ids[train_size + test_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Dataset Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "# Define the gpu on the gpu machine\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=3\n",
    "\n",
    "import evaluate\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from simpletransformers.ner import NERModel, NERArgs\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tqdm.autonotebook import tqdm as notebook_tqdm\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import logging\n",
    "import sklearn\n",
    "from numba import cuda\n",
    "import argparse\n",
    "import gc\n",
    "import torch\n",
    "import time\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B-loc', 'B-org', 'B-per', 'I-per', 'B-deriv-per', 'I-org', 'I-loc', 'B-misc', 'I-misc', 'I-deriv-per']\n",
      "(398681, 3) (51190, 3) (49764, 3)\n",
      "     sentence_id      words labels\n",
      "717            0      Kazna      O\n",
      "718            0  medijskom      O\n",
      "719            0     mogulu      O\n",
      "720            0   obnovila      O\n",
      "721            0   raspravu      O\n"
     ]
    }
   ],
   "source": [
    "# Import the dataset\n",
    "\n",
    "# Code for python script\n",
    "\"\"\"\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"dataset\", help=\"path to the dataset in JSON format\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "# Define the path to the dataset\n",
    "dataset_path = args.dataset\n",
    "\"\"\"\n",
    "# Define the path to the dataset\n",
    "dataset_path = \"datasets/hr500k.conllup_extracted.json\"\n",
    "\n",
    "# Load the json file\n",
    "with open(dataset_path, \"r\") as file:\n",
    "    json_dict = json.load(file)\n",
    "\n",
    "# Open the train, eval and test dictionaries as DataFrames\n",
    "train_df = pd.DataFrame(json_dict[\"train\"])\n",
    "test_df = pd.DataFrame(json_dict[\"test\"])\n",
    "dev_df = pd.DataFrame(json_dict[\"dev\"])\n",
    "\n",
    "# Change the sentence_ids to numbers\n",
    "test_df['sentence_id'] = pd.factorize(test_df['sentence_id'])[0]\n",
    "train_df['sentence_id'] = pd.factorize(train_df['sentence_id'])[0]\n",
    "dev_df['sentence_id'] = pd.factorize(dev_df['sentence_id'])[0]\n",
    "\n",
    "# Define the labels\n",
    "LABELS = json_dict[\"labels\"]\n",
    "print(LABELS)\n",
    "\n",
    "print(train_df.shape, test_df.shape, dev_df.shape)\n",
    "print(train_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(model, train_df, test_df, dataset_path):\n",
    "\n",
    "    # Set up the model's arguments\n",
    "    model_args = NERArgs()\n",
    "\n",
    "    # Define the model\n",
    "\n",
    "    # Define the model arguments - use the same one as for XLM-R-large if model is based on it,\n",
    "    # if the model is of same size as XLM-R-base, use its optimal hyperparameters (I searched for them before)\n",
    "    xlm_r_large_args = {\"overwrite_output_dir\": True,\n",
    "                \"num_train_epochs\": 7,\n",
    "                \"labels_list\": LABELS,\n",
    "                \"learning_rate\": 1e-5,\n",
    "                \"train_batch_size\": 32,\n",
    "                # Comment out no_cache and no_save if you want to save the model\n",
    "                \"no_cache\": True,\n",
    "                \"no_save\": True,\n",
    "                \"max_seq_length\": 256,\n",
    "                \"save_steps\": -1,\n",
    "                \"silent\": True,\n",
    "                }\n",
    "\n",
    "    xlm_r_base_args = {\"overwrite_output_dir\": True,\n",
    "             \"num_train_epochs\": 8,\n",
    "             \"labels_list\": LABELS,\n",
    "             \"learning_rate\": 1e-5,\n",
    "             \"train_batch_size\": 32,\n",
    "             # Comment out no_cache and no_save if you want to save the model\n",
    "             \"no_cache\": True,\n",
    "             \"no_save\": True,\n",
    "             \"max_seq_length\": 256,\n",
    "             \"save_steps\": -1,\n",
    "            \"silent\": True,\n",
    "             }\n",
    "\n",
    "\n",
    "    # Model type - a dictionary of type and model name.\n",
    "    # To refer to our own models, use the path to the model directory as the model name.\n",
    "    model_type_dict = {\n",
    "        \"sloberta\": [\"camembert\", \"EMBEDDIA/sloberta\", xlm_r_base_args],\n",
    "        \"csebert\": [\"bert\", \"EMBEDDIA/crosloengual-bert\", xlm_r_base_args],\n",
    "        \"xlm-r-base\": [\"xlmroberta\", \"xlm-roberta-base\", xlm_r_base_args],\n",
    "        \"xlm-r-large\": [\"xlmroberta\", \"xlm-roberta-large\", xlm_r_large_args],\n",
    "        \"bertic\": [\"electra\", \"classla/bcms-bertic\", xlm_r_base_args],\n",
    "        \"xlmrl-bcms-48\" : [\"xlmroberta\", \"outputs/checkpoint-48000\", xlm_r_large_args]\n",
    "    }\n",
    "\n",
    "    # Update the hyperparameters accordingly to the model\n",
    "    model_args = model_type_dict[model][2]\n",
    "\n",
    "    # Define the model\n",
    "    current_model = NERModel(\n",
    "    model_type_dict[model][0],\n",
    "    model_type_dict[model][1],\n",
    "    use_cuda=True,\n",
    "    args = model_args)\n",
    "\n",
    "    print(\"Training started. Current model: {}\".format(model))\n",
    "    print(\"Model arguments: epochs: {}, learning rate: {}, batch size: {}, max_seq_length: {}\".format(model_args[\"num_train_epochs\"], model_args[\"learning_rate\"], model_args[\"train_batch_size\"], model_args[\"max_seq_length\"]))\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Fine-tune the model\n",
    "    current_model.train_model(train_df)\n",
    "\n",
    "    print(\"Training completed.\")\n",
    "\n",
    "    training_time = round((time.time() - start_time)/60,2)\n",
    "\n",
    "    print(\"It took {} minutes for {} instances.\".format(training_time, train_df.shape[0]))\n",
    "\n",
    "    # Clean cache\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    start_evaluation_time = time.time()\n",
    "\n",
    "    # Evaluate the model\n",
    "    results = current_model.eval_model(test_df)\n",
    "\n",
    "    print(\"Evaluation completed.\")\n",
    "\n",
    "    evaluation_time = round((time.time() - start_evaluation_time)/60,2)\n",
    "\n",
    "    print(\"It took {} minutes for {} instances.\".format(evaluation_time, test_df.shape[0]))\n",
    "\n",
    "    # Get predictions\n",
    "    preds = results[1]\n",
    "\n",
    "    # Create a list with predictions - my method\n",
    "    preds_list = []\n",
    "\n",
    "    for sentence in preds:\n",
    "        for word in sentence:\n",
    "            current_word = []\n",
    "            for element in word:\n",
    "                # Find prediction with the highest value\n",
    "                highest_index = element.index(max(element))\n",
    "                # Transform the index to label\n",
    "                current_pred = current_model.config.id2label[highest_index]\n",
    "                # Append to the list\n",
    "                current_word.append(current_pred)\n",
    "            # Segmentation can result in multiple predictions for one word - use the first prediction only\n",
    "            preds_list.append(current_word[0])\n",
    "    \n",
    "    run_name = \"{}-{}\".format(dataset_path, model)\n",
    "\n",
    "    y_true = test_df.labels.tolist()\n",
    "\n",
    "    # Evaluate predictions\n",
    "    metrics = evaluate.testing(y_true, preds_list, list(test_df.labels.unique()), run_name, show_matrix=True)\n",
    "\n",
    "    # Add y_pred and y_true to the metrics dict\n",
    "    metrics[\"y_true_T\"] = y_true\n",
    "    metrics[\"y_pred_T\"] = preds_list\n",
    "\n",
    "   # Calculate macro F1 with Nikola's/Rik's method as well\n",
    "    preds_list_N = []\n",
    "\n",
    "    # Use factorize to convert sentence_id to integer labels\n",
    "    #test_df['sentence_id_f'] = pd.factorize(test_df['sentence_id'])[0]\n",
    "\n",
    "    preds_N = results[2]\n",
    "    kept_sentences = 0\n",
    "    discarded_sentences = 0\n",
    "\n",
    "    test_df[\"y_pred_N\"] = \"\"\n",
    "\n",
    "    # We unfold this list of lists, add it to original test data, and discard \n",
    "    # all of the sentences where there is a mismatch.\n",
    "    for i in test_df.sentence_id.unique():\n",
    "        subset = test_df[test_df.sentence_id == i]\n",
    "        if subset.shape[0] == len(preds_N[i]):\n",
    "            test_df.loc[test_df.sentence_id == i, \"y_pred_N\"] = preds_N[i]\n",
    "            kept_sentences += 1\n",
    "        else:\n",
    "            discarded_sentences += 1\n",
    "            continue\n",
    "\n",
    "    test_df_N = test_df[test_df.y_pred_N != \"\"]\n",
    "    y_true_N = test_df_N.labels.tolist()\n",
    "    y_pred_N = test_df_N.y_pred_N.tolist()\n",
    "\n",
    "    labels_N = list(test_df_N.labels.unique())\n",
    "\n",
    "    print(\"Number of kept and discarded sentences; percentage of discarded sentences:\")\n",
    "    print(kept_sentences)\n",
    "    print(discarded_sentences)\n",
    "    print(discarded_sentences/(kept_sentences+discarded_sentences)*100)\n",
    "\n",
    "    macrof1_N = f1_score(y_true_N, y_pred_N, labels=labels_N, average='macro')\n",
    "    microf1_N = f1_score(y_true_N, y_pred_N, labels=labels_N, average='micro')\n",
    "    clfreport = classification_report(y_true_N, y_pred_N, labels=labels_N)\n",
    "\n",
    "    # Let's also add entire results\n",
    "    metrics[\"results_output\"] = results\n",
    "\n",
    "    # Let's add Nikola's results\n",
    "    metrics[\"Micro F1 Nikola\"] = microf1_N\n",
    "    metrics[\"Macro F1 Nikola\"] = macrof1_N\n",
    "\n",
    "    print(\"Nikola's Macro F1: {} and Micro F1: {}\".format(macrof1_N, microf1_N))\n",
    "    \n",
    "    # The function returns a dict with accuracy, micro f1, macro f1, y_true and y_pred\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new file for results\n",
    "#with open(\"ner-results.txt\", \"w\") as file:\n",
    "#    file.write(\"Date\\tModel\\tRun\\tDataset\\tMicro F1\\tMacro F1\\tLabel Report\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at outputs/checkpoint-48000 were not used when initializing XLMRobertaForTokenClassification: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at outputs/checkpoint-48000 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NERModel' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m model \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxlmrl-bcms-48\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m run \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m current_results_dict \u001b[39m=\u001b[39m train_and_test(model, train_df, test_df, dataset_path)\n\u001b[1;32m      8\u001b[0m \u001b[39m# Add to the dict model name, dataset name and run\u001b[39;00m\n\u001b[1;32m      9\u001b[0m current_results_dict[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m model\n",
      "Cell \u001b[0;32mIn[15], line 59\u001b[0m, in \u001b[0;36mtrain_and_test\u001b[0;34m(model, train_df, test_df, dataset_path)\u001b[0m\n\u001b[1;32m     52\u001b[0m current_model \u001b[39m=\u001b[39m NERModel(\n\u001b[1;32m     53\u001b[0m model_type_dict[model][\u001b[39m0\u001b[39m],\n\u001b[1;32m     54\u001b[0m model_type_dict[model][\u001b[39m1\u001b[39m],\n\u001b[1;32m     55\u001b[0m use_cuda\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     56\u001b[0m args \u001b[39m=\u001b[39m model_args)\n\u001b[1;32m     58\u001b[0m     \u001b[39m# Initialize optimizer and scheduler for fine-tuning\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdamW(current_model\u001b[39m.\u001b[39;49mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-5\u001b[39m)  \u001b[39m# Example optimizer, adjust as needed\u001b[39;00m\n\u001b[1;32m     60\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mStepLR(optimizer, step_size\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, gamma\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m)  \u001b[39m# Example scheduler, adjust as needed\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTraining started. Current model: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(model))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NERModel' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "# Testing the models if they work as expected\n",
    "# models: [\"xlm-r-large\", \"sloberta\", \"csebert\", \"xlm-r-base\", \"bertic\"]\n",
    "model = \"xlmrl-bcms-48\"\n",
    "run = \"test\"\n",
    "\n",
    "current_results_dict = train_and_test(model, train_df, test_df, dataset_path)\n",
    "\n",
    "# Add to the dict model name, dataset name and run\n",
    "current_results_dict[\"model\"] = model\n",
    "current_results_dict[\"run\"] = \"{}-{}\".format(model, run)\n",
    "current_results_dict[\"dataset\"] = dataset_path\n",
    "\n",
    "# Add to the file with results all important information\n",
    "#with open(\"ner-results-testing.txt\", \"a\") as file:\n",
    "#    file.write(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n\".format(datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"), current_results_dict[\"model\"], current_results_dict[\"run\"], current_results_dict[\"dataset\"], current_results_dict[\"micro F1\"], current_results_dict[\"macro F1\"], current_results_dict[\"Micro F1 Nikola\"], current_results_dict[\"Macro F1 Nikola\"], current_results_dict[\"label-report\"]))\n",
    "\n",
    "# Add to the original test_df y_preds\n",
    "#test_df[\"y_pred_{}_{}\".format(model, run)] = current_results_dict[\"y_pred\"]\n",
    "\n",
    "# Save entire dict just in case\n",
    "#with open(\"{}-{}-{}-backlog.json\".format(dataset_path,model,run), \"w\") as backlog:\n",
    "#    json.dump(current_results_dict, backlog, indent=2)\n",
    "\n",
    "print(\"Run {} finished.\".format(run))\n",
    "\n",
    "# At the end, save the test_df with all predictions\n",
    "#test_df.to_csv(\"{}-test_df-with-predictions.csv\".format(dataset_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Model</th>\n",
       "      <th>Run</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Micro F1 Nikola</th>\n",
       "      <th>Macro F1 Nikola</th>\n",
       "      <th>Label Report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17/08/2023 08:51:20</td>\n",
       "      <td>xlm-r-base</td>\n",
       "      <td>xlm-r-base-testing xlm-r-base</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.839422</td>\n",
       "      <td>0.096976</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.103069</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17/08/2023 09:15:52</td>\n",
       "      <td>xlm-r-base</td>\n",
       "      <td>xlm-r-base-testing xlm-r-base</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.839344</td>\n",
       "      <td>0.097316</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>0.103009</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17/08/2023 10:03:24</td>\n",
       "      <td>xlm-r-base</td>\n",
       "      <td>xlm-r-base-epochs-to-30</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.839070</td>\n",
       "      <td>0.097772</td>\n",
       "      <td>0.867047</td>\n",
       "      <td>0.103251</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17/08/2023 10:17:52</td>\n",
       "      <td>xlm-r-base</td>\n",
       "      <td>xlm-r-base-lr-to-1e-6</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.839383</td>\n",
       "      <td>0.096620</td>\n",
       "      <td>0.861349</td>\n",
       "      <td>0.102992</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17/08/2023 10:28:55</td>\n",
       "      <td>xlm-r-base</td>\n",
       "      <td>xlm-r-base-lr-to-1e-4</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.839910</td>\n",
       "      <td>0.097347</td>\n",
       "      <td>0.870845</td>\n",
       "      <td>0.128229</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17/08/2023 11:07:01</td>\n",
       "      <td>xlm-r-base</td>\n",
       "      <td>xlm-r-base-Nikola-default-args</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.840496</td>\n",
       "      <td>0.098157</td>\n",
       "      <td>0.870309</td>\n",
       "      <td>0.103433</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date       Model                             Run  \\\n",
       "0  17/08/2023 08:51:20  xlm-r-base   xlm-r-base-testing xlm-r-base   \n",
       "1  17/08/2023 09:15:52  xlm-r-base   xlm-r-base-testing xlm-r-base   \n",
       "2  17/08/2023 10:03:24  xlm-r-base         xlm-r-base-epochs-to-30   \n",
       "3  17/08/2023 10:17:52  xlm-r-base           xlm-r-base-lr-to-1e-6   \n",
       "4  17/08/2023 10:28:55  xlm-r-base           xlm-r-base-lr-to-1e-4   \n",
       "5  17/08/2023 11:07:01  xlm-r-base  xlm-r-base-Nikola-default-args   \n",
       "\n",
       "                                  Dataset  Micro F1  Macro F1  \\\n",
       "0  datasets/hr500k.conllup_extracted.json  0.839422  0.096976   \n",
       "1  datasets/hr500k.conllup_extracted.json  0.839344  0.097316   \n",
       "2  datasets/hr500k.conllup_extracted.json  0.839070  0.097772   \n",
       "3  datasets/hr500k.conllup_extracted.json  0.839383  0.096620   \n",
       "4  datasets/hr500k.conllup_extracted.json  0.839910  0.097347   \n",
       "5  datasets/hr500k.conllup_extracted.json  0.840496  0.098157   \n",
       "\n",
       "   Micro F1 Nikola   Macro F1 Nikola  \\\n",
       "0         0.864198          0.103069   \n",
       "1         0.863248          0.103009   \n",
       "2         0.867047          0.103251   \n",
       "3         0.861349          0.102992   \n",
       "4         0.870845          0.128229   \n",
       "5         0.870309          0.103433   \n",
       "\n",
       "                                        Label Report  \n",
       "0  {'B-deriv-per': {'precision': 0.0, 'recall': 0...  \n",
       "1  {'B-deriv-per': {'precision': 0.0, 'recall': 0...  \n",
       "2  {'B-deriv-per': {'precision': 0.0, 'recall': 0...  \n",
       "3  {'B-deriv-per': {'precision': 0.0, 'recall': 0...  \n",
       "4  {'B-deriv-per': {'precision': 0.0, 'recall': 0...  \n",
       "5  {'B-deriv-per': {'precision': 0.0, 'recall': 0...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect results\n",
    "results_df = pd.read_csv(\"ner-results-testing.txt\", sep=\"\\t\")\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each model, repeat training and testing 5 times - let's do 2 times for starters\n",
    "model_list = [\"xlm-r-large\", \"sloberta\", \"csebert\", \"xlm-r-base\", \"bertic\"]\n",
    "\n",
    "for model in model_list:\n",
    "    for run in list(range(2)):\n",
    "        current_results_dict = train_and_test(model, train_df, test_df, dataset_path)\n",
    "\n",
    "        # Add to the dict model name, dataset name and run\n",
    "        current_results_dict[\"model\"] = model\n",
    "        current_results_dict[\"run\"] = \"{}-{}\".format(model, run)\n",
    "        current_results_dict[\"dataset\"] = dataset_path\n",
    "\n",
    "        # Add to the file with results all important information\n",
    "        with open(\"ner-results.txt\", \"a\") as file:\n",
    "            file.write(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n\".format(datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"), current_results_dict[\"model\"], current_results_dict[\"run\"], current_results_dict[\"dataset\"], current_results_dict[\"micro F1\"], current_results_dict[\"macro F1\"], current_results_dict[\"label-report\"]))\n",
    "\n",
    "        # Add to the original test_df y_preds\n",
    "        test_df[\"y_pred_{}_{}\".format(model, run)] = current_results_dict[\"y_pred\"]\n",
    "\n",
    "        # Save entire dict just in case\n",
    "        with open(\"{}-{}-{}-backlog.json\".format(dataset_path,model,run), \"w\") as backlog:\n",
    "            json.dump(current_results_dict, backlog, indent=2)\n",
    "    \n",
    "        print(\"Run {} finished.\".format(run))\n",
    "\n",
    "# At the end, save the test_df with all predictions\n",
    "test_df.to_csv(\"{}-test_df-with-predictions.csv\".format(dataset_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use factorize to convert sentence_id to integer labels\n",
    "test_df['sentence_id'] = pd.factorize(test_df['sentence_id'])[0]\n",
    "\n",
    "test_df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "predictions = results[2]\n",
    "kept_sentences = 0\n",
    "discarded_sentences = 0\n",
    "\n",
    "test_df[\"y_pred\"] = \"\"\n",
    "\n",
    " # We unfold this list of lists, add it to original test data, and discard \n",
    "# all of the sentences where  there is a mismatch.\n",
    "for i in test_df.sentence_id.unique():\n",
    "    subset = test_df[test_df.sentence_id == i]\n",
    "    if subset.shape[0] == len(predictions[i]):\n",
    "        test_df.loc[test_df.sentence_id == i, \"y_pred\"] = predictions[i]\n",
    "        kept_sentences += 1\n",
    "    else:\n",
    "        discarded_sentences += 1\n",
    "        continue\n",
    "\n",
    "test_df = test_df[test_df.y_pred != \"\"]\n",
    "y_true = test_df.labels.tolist()\n",
    "y_pred = test_df.y_pred.tolist()\n",
    "\n",
    "labels = list(test_df.labels.unique())\n",
    "\n",
    "print(len(y_true))\n",
    "print(kept_sentences)\n",
    "print(discarded_sentences)\n",
    "\n",
    "#print(y_true,y_pred)\n",
    "macrof1 = f1_score(y_true, y_pred, labels=labels, average='macro')\n",
    "microf1 = f1_score(y_true, y_pred, labels=labels, average='micro')\n",
    "clfreport = classification_report(y_true, y_pred, labels=labels)\n",
    "print(str(microf1)+'\\t'+str(macrof1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(model, train_df, test_df):\n",
    "\n",
    "    # Set up the model's arguments\n",
    "    model_args = NERArgs()\n",
    "\n",
    "    # Define the model\n",
    "\n",
    "    # Define the model arguments - use the same one as for XLM-R-large if model is based on it,\n",
    "    # if the model is of same size as XLM-R-base, use its optimal hyperparameters (I searched for them before)\n",
    "    xlm_r_large_args = {\"overwrite_output_dir\": True,\n",
    "                \"num_train_epochs\": 7,\n",
    "                \"labels_list\": LABELS,\n",
    "                \"learning_rate\": 1e-5,\n",
    "                \"train_batch_size\": 32,\n",
    "                # Comment out no_cache and no_save if you want to save the model\n",
    "                \"no_cache\": True,\n",
    "                \"no_save\": True,\n",
    "                \"max_seq_length\": 256,\n",
    "                \"save_steps\": -1,\n",
    "                \"wandb_project\": \"NER\",\n",
    "                \"silent\": True,\n",
    "                }\n",
    "\n",
    "    xlm_r_base_args = {\"overwrite_output_dir\": True,\n",
    "             \"num_train_epochs\": 8,\n",
    "             \"labels_list\": LABELS,\n",
    "             \"learning_rate\": 1e-5,\n",
    "             \"train_batch_size\": 32,\n",
    "             # Comment out no_cache and no_save if you want to save the model\n",
    "             \"no_cache\": True,\n",
    "             \"no_save\": True,\n",
    "             \"max_seq_length\": 256,\n",
    "             \"save_steps\": -1,\n",
    "            \"wandb_project\": \"NER\",\n",
    "            \"silent\": True,\n",
    "             }\n",
    "\n",
    "\n",
    "    # Model type - a dictionary of type and model name.\n",
    "    # To refer to our own models, use the path to the model directory as the model name.\n",
    "    model_type_dict = {\n",
    "        \"sloberta\": [\"camembert\", \"EMBEDDIA/sloberta\", xlm_r_base_args],\n",
    "        \"csebert\": [\"bert\", \"EMBEDDIA/crosloengual-bert\", xlm_r_base_args],\n",
    "        \"xlm-r-base\": [\"xlmroberta\", \"xlm-roberta-base\", xlm_r_base_args],\n",
    "        \"xlm-r-large\": [\"xlmroberta\", \"xlm-roberta-large\", xlm_r_large_args],\n",
    "        \"bertic\": [\"electra\", \"classla/bcms-bertic\", xlm_r_base_args]\n",
    "    }\n",
    "\n",
    "    # Update the hyperparameters accordingly to the model\n",
    "    model_args = model_type_dict[model][2]\n",
    "\n",
    "    # Define the model\n",
    "    current_model = NERModel(\n",
    "    model_type_dict[model][0],\n",
    "    model_type_dict[model][1],\n",
    "    use_cuda=True,\n",
    "    args = model_args)\n",
    "\n",
    "    print(\"Training started. Current model: {}\".format(model))\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Fine-tune the model\n",
    "    current_model.train_model(train_df)\n",
    "\n",
    "    print(\"Training completed.\")\n",
    "\n",
    "    training_time = round((time.time() - start_time)/60,2)\n",
    "\n",
    "    print(\"It took {} minutes for {} instances.\".format(training_time, train_df.shape[0]))\n",
    "\n",
    "    # Clean cache\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    start_evaluation_time = time.time()\n",
    "\n",
    "    # Evaluate the model\n",
    "    results = current_model.eval_model(test_df)\n",
    "\n",
    "    print(\"Evaluation completed.\")\n",
    "\n",
    "    evaluation_time = round((time.time() - start_evaluation_time)/60,2)\n",
    "\n",
    "    print(\"It took {} minutes for {} instances.\".format(evaluation_time, test_df.shape[0]))\n",
    "\n",
    "    # Get predictions\n",
    "    preds = results[1]\n",
    "\n",
    "    # Create a list with predictions\n",
    "    preds_list = []\n",
    "\n",
    "    for sentence in preds:\n",
    "        for word in sentence:\n",
    "            current_word = []\n",
    "            for element in word:\n",
    "                # Find prediction with the highest value\n",
    "                highest_index = element.index(max(element))\n",
    "                # Transform the index to label\n",
    "                current_pred = current_model.config.id2label[highest_index]\n",
    "                # Append to the list\n",
    "                current_word.append(current_pred)\n",
    "            # Segmentation can result in multiple predictions for one word - use the first prediction only\n",
    "            preds_list.append(current_word[0])\n",
    "    \n",
    "    # Get y_true\n",
    "    y_true = list(test_df.labels)\n",
    "\n",
    "    # Evaluate predictions\n",
    "    metrics = evaluate.testing(y_true, preds_list, list(test_df.labels.unique()), show_matrix=True)\n",
    "\n",
    "    # Add y_pred and y_true to the metrics dict\n",
    "    metrics[\"y_true\"] = y_true\n",
    "    metrics[\"y_pred\"] = preds_list\n",
    "    \n",
    "    # The function returns a dict with accuracy, micro f1, macro f1, y_true and y_pred\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a file with results\n",
    "with open(\"ner-results.txt\", \"w\") as file:\n",
    "    file.write(\"Date\\tModel\\tRun\\tDataset\\tMicro F1\\tMacro F1\\tLabel Report\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each model, repeat training and testing 5 times\n",
    "model_list = [\"xlm-r-large\"]\n",
    "\n",
    "for model in model_list:\n",
    "    for run in list(range(5)):\n",
    "        current_results_dict = train_and_test(model, train_df, test_df)\n",
    "\n",
    "        # Add to the dict model name, dataset name and run\n",
    "        current_results_dict[\"model\"] = model\n",
    "        current_results_dict[\"run\"] = \"{}-{}\".format(model, run)\n",
    "        current_results_dict[\"dataset\"] = dataset_path\n",
    "\n",
    "        # Add to the file with results all important information\n",
    "        with open(\"ner-results.txt\", \"a\") as file:\n",
    "            file.write(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n\".format(datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"), current_results_dict[\"model\"], current_results_dict[\"run\"], current_results_dict[\"dataset\"], current_results_dict[\"micro F1\"], current_results_dict[\"macro F1\"], current_results_dict[\"label-report\"]))\n",
    "\n",
    "        # Add to the original test_df y_preds\n",
    "        test_df[\"y_pred_{}_{}\".format(model, run)] = current_results_dict[\"y_pred\"]\n",
    "\n",
    "        # Save entire dict just in case\n",
    "        with open(\"{}-{}-{}-backlog.json\".format(dataset_path,model,run), \"w\") as backlog:\n",
    "            json.dump(current_results_dict, backlog, indent=2)\n",
    "    \n",
    "        print(\"Run {} finished.\".format(run))\n",
    "\n",
    "# At the end, save the test_df with all predictions\n",
    "test_df.to_csv(\"{}-test_df-with-predictions.csv\".format(dataset_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Model</th>\n",
       "      <th>Run</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Label Report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18/08/2023 16:39:46</td>\n",
       "      <td>xlm-r-large</td>\n",
       "      <td>xlm-r-large-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.918266</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.92105263157894...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18/08/2023 16:54:08</td>\n",
       "      <td>xlm-r-large</td>\n",
       "      <td>xlm-r-large-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990350</td>\n",
       "      <td>0.920143</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.92307692307692...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18/08/2023 17:02:56</td>\n",
       "      <td>sloberta</td>\n",
       "      <td>sloberta-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.986618</td>\n",
       "      <td>0.889416</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.91666666666666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18/08/2023 17:11:46</td>\n",
       "      <td>sloberta</td>\n",
       "      <td>sloberta-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.985681</td>\n",
       "      <td>0.884556</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.91666666666666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18/08/2023 17:20:49</td>\n",
       "      <td>csebert</td>\n",
       "      <td>csebert-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.989861</td>\n",
       "      <td>0.913822</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.94444444444444...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18/08/2023 17:29:55</td>\n",
       "      <td>csebert</td>\n",
       "      <td>csebert-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990174</td>\n",
       "      <td>0.912708</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.91666666666666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18/08/2023 17:40:13</td>\n",
       "      <td>xlm-r-base</td>\n",
       "      <td>xlm-r-base-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.988611</td>\n",
       "      <td>0.909217</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18/08/2023 17:50:32</td>\n",
       "      <td>xlm-r-base</td>\n",
       "      <td>xlm-r-base-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.988572</td>\n",
       "      <td>0.903684</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.91891891891891...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18/08/2023 17:59:35</td>\n",
       "      <td>bertic</td>\n",
       "      <td>bertic-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.989744</td>\n",
       "      <td>0.918056</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18/08/2023 18:08:33</td>\n",
       "      <td>bertic</td>\n",
       "      <td>bertic-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.989822</td>\n",
       "      <td>0.918230</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.97222222222222...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18/08/2023 19:32:40</td>\n",
       "      <td>xlmrl_bcms_48000</td>\n",
       "      <td>xlmrl_bcms_48000-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.087815</td>\n",
       "      <td>0.024446</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18/08/2023 19:33:45</td>\n",
       "      <td>xlmrl_bcms_48000</td>\n",
       "      <td>xlmrl_bcms_48000-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.101135</td>\n",
       "      <td>0.030964</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.00056203456512...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18/08/2023 20:04:34</td>\n",
       "      <td>xlm-r-large</td>\n",
       "      <td>xlm-r-large-0</td>\n",
       "      <td>datasets/reldi-normtagner-hr.conllup_extracted...</td>\n",
       "      <td>0.981122</td>\n",
       "      <td>0.734734</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18/08/2023 20:09:30</td>\n",
       "      <td>xlm-r-large</td>\n",
       "      <td>xlm-r-large-1</td>\n",
       "      <td>datasets/reldi-normtagner-hr.conllup_extracted...</td>\n",
       "      <td>0.982015</td>\n",
       "      <td>0.747264</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18/08/2023 20:12:33</td>\n",
       "      <td>sloberta</td>\n",
       "      <td>sloberta-0</td>\n",
       "      <td>datasets/reldi-normtagner-hr.conllup_extracted...</td>\n",
       "      <td>0.966153</td>\n",
       "      <td>0.497966</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18/08/2023 20:15:25</td>\n",
       "      <td>sloberta</td>\n",
       "      <td>sloberta-1</td>\n",
       "      <td>datasets/reldi-normtagner-hr.conllup_extracted...</td>\n",
       "      <td>0.969839</td>\n",
       "      <td>0.551132</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18/08/2023 20:18:33</td>\n",
       "      <td>csebert</td>\n",
       "      <td>csebert-0</td>\n",
       "      <td>datasets/reldi-normtagner-hr.conllup_extracted...</td>\n",
       "      <td>0.980340</td>\n",
       "      <td>0.786478</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.66666666666666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18/08/2023 20:21:42</td>\n",
       "      <td>csebert</td>\n",
       "      <td>csebert-1</td>\n",
       "      <td>datasets/reldi-normtagner-hr.conllup_extracted...</td>\n",
       "      <td>0.980451</td>\n",
       "      <td>0.788275</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.5, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18/08/2023 20:25:18</td>\n",
       "      <td>xlm-r-base</td>\n",
       "      <td>xlm-r-base-0</td>\n",
       "      <td>datasets/reldi-normtagner-hr.conllup_extracted...</td>\n",
       "      <td>0.977547</td>\n",
       "      <td>0.715933</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18/08/2023 20:28:53</td>\n",
       "      <td>xlm-r-base</td>\n",
       "      <td>xlm-r-base-1</td>\n",
       "      <td>datasets/reldi-normtagner-hr.conllup_extracted...</td>\n",
       "      <td>0.976095</td>\n",
       "      <td>0.701065</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>18/08/2023 20:32:02</td>\n",
       "      <td>bertic</td>\n",
       "      <td>bertic-0</td>\n",
       "      <td>datasets/reldi-normtagner-hr.conllup_extracted...</td>\n",
       "      <td>0.980004</td>\n",
       "      <td>0.624263</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>18/08/2023 20:35:11</td>\n",
       "      <td>bertic</td>\n",
       "      <td>bertic-1</td>\n",
       "      <td>datasets/reldi-normtagner-hr.conllup_extracted...</td>\n",
       "      <td>0.978664</td>\n",
       "      <td>0.616882</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>18/08/2023 21:44:22</td>\n",
       "      <td>xlm-r-large</td>\n",
       "      <td>xlm-r-large-0</td>\n",
       "      <td>datasets/reldi-normtagner-sr.conllup_extracted...</td>\n",
       "      <td>0.985858</td>\n",
       "      <td>0.719509</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>18/08/2023 21:48:55</td>\n",
       "      <td>xlm-r-large</td>\n",
       "      <td>xlm-r-large-1</td>\n",
       "      <td>datasets/reldi-normtagner-sr.conllup_extracted...</td>\n",
       "      <td>0.985639</td>\n",
       "      <td>0.667666</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>18/08/2023 21:51:28</td>\n",
       "      <td>sloberta</td>\n",
       "      <td>sloberta-0</td>\n",
       "      <td>datasets/reldi-normtagner-sr.conllup_extracted...</td>\n",
       "      <td>0.978842</td>\n",
       "      <td>0.435915</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>18/08/2023 21:54:01</td>\n",
       "      <td>sloberta</td>\n",
       "      <td>sloberta-1</td>\n",
       "      <td>datasets/reldi-normtagner-sr.conllup_extracted...</td>\n",
       "      <td>0.979390</td>\n",
       "      <td>0.440261</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>18/08/2023 21:56:46</td>\n",
       "      <td>csebert</td>\n",
       "      <td>csebert-0</td>\n",
       "      <td>datasets/reldi-normtagner-sr.conllup_extracted...</td>\n",
       "      <td>0.984433</td>\n",
       "      <td>0.666519</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>18/08/2023 21:59:32</td>\n",
       "      <td>csebert</td>\n",
       "      <td>csebert-1</td>\n",
       "      <td>datasets/reldi-normtagner-sr.conllup_extracted...</td>\n",
       "      <td>0.984762</td>\n",
       "      <td>0.663830</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>18/08/2023 22:02:41</td>\n",
       "      <td>xlm-r-base</td>\n",
       "      <td>xlm-r-base-0</td>\n",
       "      <td>datasets/reldi-normtagner-sr.conllup_extracted...</td>\n",
       "      <td>0.982460</td>\n",
       "      <td>0.567848</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>18/08/2023 22:05:48</td>\n",
       "      <td>xlm-r-base</td>\n",
       "      <td>xlm-r-base-1</td>\n",
       "      <td>datasets/reldi-normtagner-sr.conllup_extracted...</td>\n",
       "      <td>0.981912</td>\n",
       "      <td>0.605271</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>18/08/2023 22:08:33</td>\n",
       "      <td>bertic</td>\n",
       "      <td>bertic-0</td>\n",
       "      <td>datasets/reldi-normtagner-sr.conllup_extracted...</td>\n",
       "      <td>0.983666</td>\n",
       "      <td>0.508073</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>18/08/2023 22:11:18</td>\n",
       "      <td>bertic</td>\n",
       "      <td>bertic-1</td>\n",
       "      <td>datasets/reldi-normtagner-sr.conllup_extracted...</td>\n",
       "      <td>0.982898</td>\n",
       "      <td>0.481422</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Date             Model                 Run  \\\n",
       "0   18/08/2023 16:39:46       xlm-r-large       xlm-r-large-0   \n",
       "1   18/08/2023 16:54:08       xlm-r-large       xlm-r-large-1   \n",
       "2   18/08/2023 17:02:56          sloberta          sloberta-0   \n",
       "3   18/08/2023 17:11:46          sloberta          sloberta-1   \n",
       "4   18/08/2023 17:20:49           csebert           csebert-0   \n",
       "5   18/08/2023 17:29:55           csebert           csebert-1   \n",
       "6   18/08/2023 17:40:13        xlm-r-base        xlm-r-base-0   \n",
       "7   18/08/2023 17:50:32        xlm-r-base        xlm-r-base-1   \n",
       "8   18/08/2023 17:59:35            bertic            bertic-0   \n",
       "9   18/08/2023 18:08:33            bertic            bertic-1   \n",
       "10  18/08/2023 19:32:40  xlmrl_bcms_48000  xlmrl_bcms_48000-0   \n",
       "11  18/08/2023 19:33:45  xlmrl_bcms_48000  xlmrl_bcms_48000-1   \n",
       "12  18/08/2023 20:04:34       xlm-r-large       xlm-r-large-0   \n",
       "13  18/08/2023 20:09:30       xlm-r-large       xlm-r-large-1   \n",
       "14  18/08/2023 20:12:33          sloberta          sloberta-0   \n",
       "15  18/08/2023 20:15:25          sloberta          sloberta-1   \n",
       "16  18/08/2023 20:18:33           csebert           csebert-0   \n",
       "17  18/08/2023 20:21:42           csebert           csebert-1   \n",
       "18  18/08/2023 20:25:18        xlm-r-base        xlm-r-base-0   \n",
       "19  18/08/2023 20:28:53        xlm-r-base        xlm-r-base-1   \n",
       "20  18/08/2023 20:32:02            bertic            bertic-0   \n",
       "21  18/08/2023 20:35:11            bertic            bertic-1   \n",
       "22  18/08/2023 21:44:22       xlm-r-large       xlm-r-large-0   \n",
       "23  18/08/2023 21:48:55       xlm-r-large       xlm-r-large-1   \n",
       "24  18/08/2023 21:51:28          sloberta          sloberta-0   \n",
       "25  18/08/2023 21:54:01          sloberta          sloberta-1   \n",
       "26  18/08/2023 21:56:46           csebert           csebert-0   \n",
       "27  18/08/2023 21:59:32           csebert           csebert-1   \n",
       "28  18/08/2023 22:02:41        xlm-r-base        xlm-r-base-0   \n",
       "29  18/08/2023 22:05:48        xlm-r-base        xlm-r-base-1   \n",
       "30  18/08/2023 22:08:33            bertic            bertic-0   \n",
       "31  18/08/2023 22:11:18            bertic            bertic-1   \n",
       "\n",
       "                                              Dataset  Micro F1  Macro F1  \\\n",
       "0              datasets/hr500k.conllup_extracted.json  0.990291  0.918266   \n",
       "1              datasets/hr500k.conllup_extracted.json  0.990350  0.920143   \n",
       "2              datasets/hr500k.conllup_extracted.json  0.986618  0.889416   \n",
       "3              datasets/hr500k.conllup_extracted.json  0.985681  0.884556   \n",
       "4              datasets/hr500k.conllup_extracted.json  0.989861  0.913822   \n",
       "5              datasets/hr500k.conllup_extracted.json  0.990174  0.912708   \n",
       "6              datasets/hr500k.conllup_extracted.json  0.988611  0.909217   \n",
       "7              datasets/hr500k.conllup_extracted.json  0.988572  0.903684   \n",
       "8              datasets/hr500k.conllup_extracted.json  0.989744  0.918056   \n",
       "9              datasets/hr500k.conllup_extracted.json  0.989822  0.918230   \n",
       "10             datasets/hr500k.conllup_extracted.json  0.087815  0.024446   \n",
       "11             datasets/hr500k.conllup_extracted.json  0.101135  0.030964   \n",
       "12  datasets/reldi-normtagner-hr.conllup_extracted...  0.981122  0.734734   \n",
       "13  datasets/reldi-normtagner-hr.conllup_extracted...  0.982015  0.747264   \n",
       "14  datasets/reldi-normtagner-hr.conllup_extracted...  0.966153  0.497966   \n",
       "15  datasets/reldi-normtagner-hr.conllup_extracted...  0.969839  0.551132   \n",
       "16  datasets/reldi-normtagner-hr.conllup_extracted...  0.980340  0.786478   \n",
       "17  datasets/reldi-normtagner-hr.conllup_extracted...  0.980451  0.788275   \n",
       "18  datasets/reldi-normtagner-hr.conllup_extracted...  0.977547  0.715933   \n",
       "19  datasets/reldi-normtagner-hr.conllup_extracted...  0.976095  0.701065   \n",
       "20  datasets/reldi-normtagner-hr.conllup_extracted...  0.980004  0.624263   \n",
       "21  datasets/reldi-normtagner-hr.conllup_extracted...  0.978664  0.616882   \n",
       "22  datasets/reldi-normtagner-sr.conllup_extracted...  0.985858  0.719509   \n",
       "23  datasets/reldi-normtagner-sr.conllup_extracted...  0.985639  0.667666   \n",
       "24  datasets/reldi-normtagner-sr.conllup_extracted...  0.978842  0.435915   \n",
       "25  datasets/reldi-normtagner-sr.conllup_extracted...  0.979390  0.440261   \n",
       "26  datasets/reldi-normtagner-sr.conllup_extracted...  0.984433  0.666519   \n",
       "27  datasets/reldi-normtagner-sr.conllup_extracted...  0.984762  0.663830   \n",
       "28  datasets/reldi-normtagner-sr.conllup_extracted...  0.982460  0.567848   \n",
       "29  datasets/reldi-normtagner-sr.conllup_extracted...  0.981912  0.605271   \n",
       "30  datasets/reldi-normtagner-sr.conllup_extracted...  0.983666  0.508073   \n",
       "31  datasets/reldi-normtagner-sr.conllup_extracted...  0.982898  0.481422   \n",
       "\n",
       "                                         Label Report  \n",
       "0   {'B-deriv-per': {'precision': 0.92105263157894...  \n",
       "1   {'B-deriv-per': {'precision': 0.92307692307692...  \n",
       "2   {'B-deriv-per': {'precision': 0.91666666666666...  \n",
       "3   {'B-deriv-per': {'precision': 0.91666666666666...  \n",
       "4   {'B-deriv-per': {'precision': 0.94444444444444...  \n",
       "5   {'B-deriv-per': {'precision': 0.91666666666666...  \n",
       "6   {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "7   {'B-deriv-per': {'precision': 0.91891891891891...  \n",
       "8   {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "9   {'B-deriv-per': {'precision': 0.97222222222222...  \n",
       "10  {'B-deriv-per': {'precision': 0.0, 'recall': 0...  \n",
       "11  {'B-deriv-per': {'precision': 0.00056203456512...  \n",
       "12  {'B-deriv-per': {'precision': 0.0, 'recall': 0...  \n",
       "13  {'B-deriv-per': {'precision': 0.0, 'recall': 0...  \n",
       "14  {'B-deriv-per': {'precision': 0.0, 'recall': 0...  \n",
       "15  {'B-deriv-per': {'precision': 0.0, 'recall': 0...  \n",
       "16  {'B-deriv-per': {'precision': 0.66666666666666...  \n",
       "17  {'B-deriv-per': {'precision': 0.5, 'recall': 0...  \n",
       "18  {'B-deriv-per': {'precision': 0.0, 'recall': 0...  \n",
       "19  {'B-deriv-per': {'precision': 0.0, 'recall': 0...  \n",
       "20  {'B-deriv-per': {'precision': 0.0, 'recall': 0...  \n",
       "21  {'B-deriv-per': {'precision': 0.0, 'recall': 0...  \n",
       "22  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "23  {'B-deriv-per': {'precision': 0.0, 'recall': 0...  \n",
       "24  {'B-deriv-per': {'precision': 0.0, 'recall': 0...  \n",
       "25  {'B-deriv-per': {'precision': 0.0, 'recall': 0...  \n",
       "26  {'B-deriv-per': {'precision': 1.0, 'recall': 1...  \n",
       "27  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "28  {'B-deriv-per': {'precision': 0.0, 'recall': 0...  \n",
       "29  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "30  {'B-deriv-per': {'precision': 0.0, 'recall': 0...  \n",
       "31  {'B-deriv-per': {'precision': 0.0, 'recall': 0...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the txt with results\n",
    "import pandas as pd\n",
    "\n",
    "results = pd.read_csv(\"ner-results.txt\", sep=\"\\t\")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['datasets/hr500k.conllup_extracted.json',\n",
       "       'datasets/reldi-normtagner-hr.conllup_extracted.json',\n",
       "       'datasets/reldi-normtagner-sr.conllup_extracted.json'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.Dataset.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Model'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAGwCAYAAACzXI8XAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABLWklEQVR4nO3dd3hUVf7H8fckpENCTwADUTpICWBC6EIwWFi7uOqCKCiKorJrwQJ29qeirBVFEVcsrIIdaVF670iVjkLoJCRA2pzfHweikZaEJDc3+byeZx5m7tzynQxz5zP3nnuOxxhjEBEREXEhH6cLEBERESkoBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXGtck4XkBder5ddu3ZRoUIFPB6P0+WIiIhIHhhjOHLkCDVr1sTHp2iOnbgiyOzatYvIyEinyxAREZEC2LlzJxdccEGRrNsVQaZChQqA/UOEhoY6XI2IiIjkRUpKCpGRkTnf40XBFUHm5Omk0NBQBRkRERGXKcpmIWrsKyIiIq6lICMiIiKule8gM2vWLHr27EnNmjXxeDx8/fXX51xmxowZtGrVioCAAOrVq8fYsWMLUKqIiIhIbvkOMmlpabRo0YK33norT/Nv3bqVK6+8kksvvZQVK1bw4IMP0q9fP6ZMmZLvYkVERET+LN+NfS+//HIuv/zyPM8/atQoLrzwQkaMGAFA48aNmTNnDq+99hoJCQmnXSY9PZ309PScxykpKfktU0RERMqAIm8jM3/+fOLj43NNS0hIYP78+WdcZvjw4YSFheXc1IeMiIiInE6RB5mkpCTCw8NzTQsPDyclJYVjx46ddpkhQ4aQnJycc9u5c2dRlykiIiIuVCL7kQkICCAgIMDpMkRERKSEK/IjMhEREezZsyfXtD179hAaGkpQUFBRb15ERERKsSIPMnFxcSQmJuaaNm3aNOLi4op60yIiIlLK5TvIpKamsmLFClasWAHYy6tXrFjBjh07ANu+pXfv3jnzDxgwgC1btvDII4+wfv163n77bf73v//x0EMPFc4rEBERkTIr30FmyZIlREdHEx0dDcDgwYOJjo5m6NChAOzevTsn1ABceOGF/PDDD0ybNo0WLVowYsQI3n///TNeei0iIiKSVx5jjHG6iHNJSUkhLCyM5ORkDRopIiJSAMZAdjZkZp7+VrMmBAYW7jaL4/u7RF61JIXDGPB67e3P9/98O9P0gizj1HRfX/vhCwiw/57p/l+nldP/fhE5B2PO/MVflLesrKJZ79ksXAgxMcXzdy1MZXpXPnw4bN5c+F+sJeXLXs6uoAGoMOcNCIAiHN1epNid61d/SftiP9etLOxLy5UDPz/3vtYyHWS++w7O0sFwmeTjk/vm8Zw67UzT8zNvYU33eOxOMz0djh+3t5P3/zrt2LHcH9TsbEhLszcnnQw0ToQpHZ0qHsbYL+KTt5NfzHl5XNDnins9ef3VXxr4+tovfj+/P0JAUd2Kcv3lytmb239Mlend1913Q8+e7vjCLo5a3P6fOS+yss4cdM4VhM5n3r9O+7P0dHtzckgxX9+iPfJ0ruf//EXvxi/xc82bne3ce1sSeDzOf2EX5rp8irzjEsmPMh1k+vRxugIpbid/gYSEOFeDMZCRcX5BqDBCVVbWHzVlZ8PRo/Ymxefk/8eTX7Rneny250rSvGe6+fo6/ZeW0qxMBxkRJ3g8f5xOclJeT8kVZag6fjx3TScP2Rf3F7ET2/T1LRtHQUWKmoKMSBnl6wvBwfbmlJNXhPj46ItdRApGQUZEHOPxgL+/01WIiJupyZKIiIi4loKMiIiIuJaCjIiIiLiWgoyIiIi4loKMiIiIuJaCjIiIiLiWgoyIiIi4loKMiIiIuJaCjIiIiLiWgoyIiIi4loKMiIiIuJaCjIiIiLiWgoyIiIi4loKMiIiIuJaCjIiIiLiWgoyIiIi4loKMiIiIuJaCjIiIiLiWgoyIiIi4loKMiIiIuJaCjIiIiLiWgoyIiIi4loKMiIiIuJaCjIiIiLiWgoyIiIi4loKMiIiIuJaCjIiIiLiWgoyIiIi4loKMiIiIuJaCjIiIiLiWgoyIiIi4loKMiIiIuJaCjIiIiLiWgoyIiIi4loKMiIiIuJaCjIiIiLiWgoyIiIi4loKMiIiIuJaCjIiIiLiWgoyIiIi4loKMiIiIuJaCjIiIiLhWgYLMW2+9RVRUFIGBgcTGxrJo0aIzzpuZmcmzzz5L3bp1CQwMpEWLFkyePLnABYuIiIiclO8gM378eAYPHsywYcNYtmwZLVq0ICEhgb179552/ieffJJ3332XN954g7Vr1zJgwACuvfZali9fft7Fi4iISNnmMcaY/CwQGxvLJZdcwptvvgmA1+slMjKS+++/n8cee+yU+WvWrMkTTzzBwIEDc6Zdf/31BAUFMW7cuDxtMyUlhbCwMJKTkwkNDc1PuSIiIuKQ4vj+ztcRmYyMDJYuXUp8fPwfK/DxIT4+nvnz5592mfT0dAIDA3NNCwoKYs6cOWfcTnp6OikpKbluIiIiIn+VryCzf/9+srOzCQ8PzzU9PDycpKSk0y6TkJDAq6++yq+//orX62XatGlMnDiR3bt3n3E7w4cPJywsLOcWGRmZnzJFRESkjCjyq5b+85//UL9+fRo1aoS/vz/33Xcfffv2xcfnzJseMmQIycnJObedO3cWdZkiIiLiQvkKMlWrVsXX15c9e/bkmr5nzx4iIiJOu0y1atX4+uuvSUtLY/v27axfv57y5ctz0UUXnXE7AQEBhIaG5rqJiIiI/FW+goy/vz+tW7cmMTExZ5rX6yUxMZG4uLizLhsYGEitWrXIyspiwoQJXH311QWrWEREROSEcvldYPDgwfTp04c2bdoQExPDyJEjSUtLo2/fvgD07t2bWrVqMXz4cAAWLlzI77//TsuWLfn99995+umn8Xq9PPLII4X7SkRERKTMyXeQ6dWrF/v27WPo0KEkJSXRsmVLJk+enNMAeMeOHbnavxw/fpwnn3ySLVu2UL58ea644go+/vhjKlasWGgvQkRERMqmfPcj4wT1IyMiIuI+Ja4fGREREZGSREFGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXKtAQeatt94iKiqKwMBAYmNjWbRo0VnnHzlyJA0bNiQoKIjIyEgeeughjh8/XqCCRURERE7Kd5AZP348gwcPZtiwYSxbtowWLVqQkJDA3r17Tzv/p59+ymOPPcawYcNYt24dH3zwAePHj+fxxx8/7+JFRESkbMt3kHn11Vfp378/ffv2pUmTJowaNYrg4GDGjBlz2vnnzZtH+/btueWWW4iKiuKyyy7j73//+zmP4oiIiIicS76CTEZGBkuXLiU+Pv6PFfj4EB8fz/z580+7TLt27Vi6dGlOcNmyZQuTJk3iiiuuOON20tPTSUlJyXUTERER+aty+Zl5//79ZGdnEx4enmt6eHg469evP+0yt9xyC/v376dDhw4YY8jKymLAgAFnPbU0fPhwnnnmmfyUJiIiImVQkV+1NGPGDF588UXefvttli1bxsSJE/nhhx947rnnzrjMkCFDSE5Ozrnt3LmzqMsUERERF8rXEZmqVavi6+vLnj17ck3fs2cPERERp13mqaee4h//+Af9+vUDoFmzZqSlpXHXXXfxxBNP4ONzapYKCAggICAgP6WJiIhIGZSvIzL+/v60bt2axMTEnGler5fExETi4uJOu8zRo0dPCSu+vr4AGGPyW6+IiIhIjnwdkQEYPHgwffr0oU2bNsTExDBy5EjS0tLo27cvAL1796ZWrVoMHz4cgJ49e/Lqq68SHR1NbGwsmzZt4qmnnqJnz545gUZERESkIPIdZHr16sW+ffsYOnQoSUlJtGzZksmTJ+c0AN6xY0euIzBPPvkkHo+HJ598kt9//51q1arRs2dPXnjhhcJ7FSIiIlImeYwLzu+kpKQQFhZGcnIyoaGhTpcjIiIieVAc398aa0lERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFxLQUZERERcS0FGREREXEtBRkRERFyrQEHmrbfeIioqisDAQGJjY1m0aNEZ5+3SpQsej+eU25VXXlngokVERESgAEFm/PjxDB48mGHDhrFs2TJatGhBQkICe/fuPe38EydOZPfu3Tm3X375BV9fX2688cbzLl5ERETKtnwHmVdffZX+/fvTt29fmjRpwqhRowgODmbMmDGnnb9y5cpERETk3KZNm0ZwcPBZg0x6ejopKSm5biIiIiJ/la8gk5GRwdKlS4mPj/9jBT4+xMfHM3/+/Dyt44MPPuDmm28mJCTkjPMMHz6csLCwnFtkZGR+yhQREZEyIl9BZv/+/WRnZxMeHp5renh4OElJSedcftGiRfzyyy/069fvrPMNGTKE5OTknNvOnTvzU6aIiIiUEeWKc2MffPABzZo1IyYm5qzzBQQEEBAQUExViYiIlHHH90NgVaerKJB8HZGpWrUqvr6+7NmzJ9f0PXv2EBERcdZl09LS+Pzzz7nzzjvzX6WIiIgUvqO/wdxb4IdGkH7Q6WoKJF9Bxt/fn9atW5OYmJgzzev1kpiYSFxc3FmX/eKLL0hPT+e2224rWKUiIiJSOLKOwS/Pw3cNYftnNsTsnuJ0VQWS71NLgwcPpk+fPrRp04aYmBhGjhxJWloaffv2BaB3797UqlWL4cOH51rugw8+4JprrqFKlSqFU7mIiIjkjzHw21ew7J+Qts1Oq9YeWr8OlVs5WlpB5TvI9OrVi3379jF06FCSkpJo2bIlkydPzmkAvGPHDnx8ch/o2bBhA3PmzGHq1KmFU7WIiIjkz+FfYOkDsOcn+zioFkS/DHVuBo/H2drOg8cYY5wu4lxSUlIICwsjOTmZ0NBQp8sRERFxj/SDsHoY/PoOmGzwCYDGD0PTx6DcmbtCKQzF8f1drFctiYiISDHxZsPm92DVU5B+wE674FpoNQLKX+hsbYVIQUZERKS02TsLlgyCwyvt47Cm0Po/ENHN2bqKgIKMiIhIaZG2A5Y/DDv+Zx/7VYTmz0L9e8CndH7ll85XJSIiUpZkHYN1L8Ha/4PsY+Dxgbp3QfPnXNvRXV4pyIiIiLiVMbBzgr2c+ugOO616J3saqVJLR0srLgoyIiIibnRolb2ceu8M+zg40l5OXfsmV19OnV8KMiIiIm6SfgBWDYVNo8B4wTcQGj8CTR6FcsFOV1fsFGRERETcwJsFm961ISbjxLhIkTfYozDloxwtzUkKMiIiIiXdnp/taaTDq+3jis1sO5jwS52tqwRQkBERESmp0rbDsn/Bzi/tY//K9kqkeneV2sup80t/BRERkZIm66i9lHrdS5B93F5OXW+A7RMmQIMv/5mCjIiISElhjO3MbvnDcHSnnVa9y4nLqZs7WlpJpSAj7rZvvv2lUjXW6UpERM7PoRUnLqeeZR8H17bjIkVeX6Yup84vBRlxr/WvwbLBNsh0mQw1ujtdkYhI/h3fbwd23Pzeicupg6DJY3aE6nJBTldX4inIiPsYYz/0a1448dgLc3tBwmKoUNfZ2kRE8sqbBb++Yy+nzjxsp9XuBdEvQUhtR0tzEx+nCxDJF+OFJQP/CDHNnoYqsZBxCGZdA5mpTlYnIpI3SYnwY0tYOsiGmIotoNsM6PC5Qkw+KciIe2RnwLxb7S8YPHDJ29BsGHScCEE1IPkXWNDHhh0RkZIodSvMug5+iofkNfYKpEvegR5LIbyz09W5koKMuEPWUXvEZfvn4CkH7T61w9IDBNe0YcbHH3ZOhF9ecLRUEZFTZKXByqfg+8bw21fg8YUG98NVG6H+APDxdbpC11KQkZIv4zD8fBns/tE2guv8LUTdnHueqm3trxqA1UPht2+KvUwRkVMYA9s+g+8bwZrnwZsO4V3h8hXQ5nUIqOx0ha6nICMl27EkmN4F9s0FvzDoOg1qXn76eeveAQ3us/fn3QbJa4utTBGRUxxcDtM7wbxb4OhvEBJljx53nQ4VL3a6ulJDQUZKrtStMK0DHF4JgeEQPxOqtT/7Mq1etZ1HZaXCzKttI2ARkeJ0fB8svAsmt4Z9c8A32A4rcOVaiLxWfcIUMgUZKZkOr7EhJnWz/RXTfQ5UanHu5Xz8oMP/IKQOpG6CubeAN7vIyxURwZsJ60fCd/Vh82jAQJ2/Q88NcPGT6hOmiCjISMmzf6E9HHtsF4Q1tSGmQr28Lx9YDTp9bdvT7J4MKx8vslJFRADYPQ0mtYBlD0FmMlSKhvjZ0P5TCL7A6epKNQUZKVmSpsNP3SDjoO0fJn4WBNfK/3oqtYS2H9r7616yje1ERArbkc32isqfL4OUdRBQFWLesx10Vu/gdHVlgnr2lZJjxwTbKM6bARHx0PEr8Ctf8PXV6WXHLln7b1h4J4Q2gsrRhVauiJRhmamw5kVYP8Luszy+9mKDZsPAv5LT1ZUpOiIjJcPmD2DuTXaHEHk9dP7+/ELMSc2fhxqXQ/Yx+6vp+N7zX6eIlF3GwNZx8H1DWDv8xA+v7nDFKmg9UiHGAQoy4ry1L8PCfrZH3rp3Qvvx4BtQOOv28bXnqCs0gKM7YM6NtkGeiEh+HVgC09rD/H/YNnzlL7Lt8S6dAmFNnK6uzFKQEecYAyuGwIpH7OPGj0DM6MLv4dK/ot3ZlKsAe2fB0gcLd/0iUrod32t/bE2Jgf3zoVwItHgRrlwDF1yty6kdpiAjzvBmw+IBtv0KQMt/Q/T/Fd0OIawxtPsE8MCvb8Om94tmOyJSemRnwLpXT1xO/QFgIOo2uGoDNB0CvoFOVygoyIgTsjNg3t9h03uAx7bwb/Jo0W/3gp7Q/Fl7f8m9sG9e0W9TRNxp12T4sTks/ydkpkDl1tB9LrT7uGBXUkqRUZCR4pWVBjN7wo4vTnReNx7q9S++7Td9AiJvsO1kZl8PR38vvm2LSMl3ZBPM6AkzLoeUDRBYHWLfh4RFUK2d09XJaejyayk+6Qdh5lX2HLNvMHT6CmpcVrw1eDy2f5kjG+Dwaph1LXSfpUPEImVd5hH45XnY8Jr9oeMpBw0HwcVDwT/M6erkLHRERorHsd0wvbMNMf6V7KBpxR1iTvIrD52+Af/KcHAxLBpgGx6LSNljvLDlv/BdA9t5pjcTavSAK1ZDqxEKMS6gICNF78hmmNoekn+BoBq2t95qcc7WVP5COyaTxxe2fgQb/uNsPSJS/A4shqntYEEfOJ4E5etC5++gyyQIa+R0dZJHCjJStA6vtoM/pm21fS50n1Nyhq+P6AbRr9j7y/8FSYnO1iMixeNYEizoay+nPrAQypW3V05euQZqXaXLqV1GQUaKzr75MK2T/aVTsZkNMeUvcrqq3Bo+ABf2AZMNc26C1C1OVyQiRSU7A9a9Yk8jbRlrp13YG3putFdOFlZHnFKs1NhXisbuqbYhbfZRqBoHXX4omV13ezwQMwqS19r2MrOuge7zCmd4BBEpOX6fZEemPrLRPq58CbR5Haq2dbYuOW86IiOFb8cX9uqk7KNQIwG6TiuZIeYk30DoNBECw+2psAV91fhXpLRI2QgzroSZV9oQExhur1xMWKAQU0ooyEjh2jQa5vSyLf9r94JO39ruvEu64Aug40Tbt83OL+2otiLiXpkpsPxhmHQx7JpkP9uNH7ankS66HTz6+ist9E5K4Vn7f7DoLsBAvbvtkAC+/k5XlXfV2kGbt+39VU/Bb985W4+I5J/x2vYv3zWw7WG8mVDzCrjiF4h+CfxCna5QCpmCjJw/Y2D5I7DiMfu46eNwyTuFP/hjcajXD+rfCxiYdyskr3O6IhHJq/0LYWqcPT18fI8d9b7zD7aNXmgDp6uTIqIgI+fHmw2L+sO6l+3j6FegxQvuvnyx9Uio3gmyjsCsqyHjsNMVicjZHNsN8/vA1LZwYJEd6T76ZdupXa0rnK5OipiCjBRcdjrM7WVHhfX4QOwH0PifTld1/nz8oMMXEBwJR36FubfYwCYiJUt2uj2l/V0D2PpfO+2ivrYdTON/uevUthSYgowUTGaqvTJp5wTw8bdf/HXvcLqqwhNYHTp9Db5BsPtHWPWk0xWJyEnG2DZsP1xsT2lnpUKVWLhsIbQdA0ERTlcoxUhBRvIv/QD8FA9J0+0VSV0mQeR1TldV+Cq3skeZANb+G7aPd7YeEYHk9TDjCpj1N0jdBIER0PYjuGweVI1xujpxgDrEk/w5+jv8fJntQM6/MnT5sXTvPKL+DodW2MHkFvSF0IZQqaXTVYmUPRnJ8MuzsOF1MFn2SHCjh6DpE+BXwenqxEEKMpJ3RzbBT90hbRsE1YKuUyGsidNVFb0WL8LhVbB7su35N2ExBFZzuiqRssF4YcuHsPJxOL7XTqvVE1q9ChXqOVublAg6tSR5c2jlicEft0H5enbcpLIQYsBeRt7+U/u607bDnBtt3xQiUrT2zbMDOy7sZ0NMaEN7FLjztwoxkkNBRs5t31yY3tn2y1Cp5YnBH6Ocrqp4+VeCzt/YUXL3zoRlg52uSKT0Ovo7zLsNprWHg0ttJ3bRI+DyVVCzh9PVSQmjICNnt+tHezopMxmqdYBuP0NQuNNVOSOsCbQbZ+9vfBM2j3G2HpHSJvs4rBkO3zeEbZ8AHqh7J1y1ERoP1uXUcloFCjJvvfUWUVFRBAYGEhsby6JFi846/+HDhxk4cCA1atQgICCABg0aMGnSpAIVLMVo22cw82+Qfcx28X3pFPCv6HRVzrrgamj2jL2/+B7Yv8DZekRKA2Pgt2/gh6a2LUxWGlSNgx6LIfb9svvjSfIk30Fm/PjxDB48mGHDhrFs2TJatGhBQkICe/fuPe38GRkZdO/enW3btvHll1+yYcMGRo8eTa1atc67eClCv75ju+g3WVDnFtunSrlgp6sqGS5+Ei64FrwZMPs6OLrL6YpE3Ct5LfycYBvSp26BoJoQNw66z4XKrZ2uTlzAY4wx+VkgNjaWSy65hDfffBMAr9dLZGQk999/P4899tgp848aNYqXX36Z9evX4+fnV6AiU1JSCAsLIzk5mdBQDfhVpIyxIz+f7ACu/kBo87pGiv2rzCN2TJfkNbYjrvgZ4BvodFUi7pFxGFY/bU/Tmmx7OXXjf0GTIeBX3unqpJAUx/d3vr6dMjIyWLp0KfHx8X+swMeH+Ph45s+ff9plvv32W+Li4hg4cCDh4eFcfPHFvPjii2Rnn7nL9/T0dFJSUnLdpBgYLyz75x8h5uKnoM0bCjGn41cBOn1jGwEfWAiL77UhUETOzpsNm96D7+rDhv/YEHPB1XDlWjtOm0KM5FO+vqH2799PdnY24eG5z1eGh4eTlJR02mW2bNnCl19+SXZ2NpMmTeKpp55ixIgRPP/882fczvDhwwkLC8u5RUZG5qdMKQhvFiy8Eza8Zh+3eg2aP+vuwR+LWoW60OF/Nuht+dD+shSRM9s7B6ZcAovuhvT9ENoYLp1qT11XqOt0deJSRf5T2+v1Ur16dd577z1at25Nr169eOKJJxg1atQZlxkyZAjJyck5t507dxZ1mWVb9nHbN8qWseDxtd19N3rQ6arcISIeWp4Y+XvZQ5D0k7P1iJRER3+zg69O7wiHloNfGLQaCVeshBrdna5OXC5fPftWrVoVX19f9uzZk2v6nj17iIg4/SBdNWrUwM/PD19f35xpjRs3JikpiYyMDPz9T72cLiAggICAgPyUJgWVeQRmXQ17fgafAHuE4YK/OV2VuzR6yO6ct42DuTfZnn/LX+h0VSLOyz4O616xl1RnHwU8UK8/NH9evWNLocnXERl/f39at25NYmJizjSv10tiYiJxcXGnXaZ9+/Zs2rQJr9ebM23jxo3UqFHjtCFGitHx/ZDY1YaYchXg0skKMQXh8UDMe1C5jR1Qc9Y19vJRkbLKGNj5FXzfGFY9ZUNMtQ7QYwnEvKsQI4Uq36eWBg8ezOjRo/noo49Yt24d99xzD2lpafTt2xeA3r17M2TIkJz577nnHg4ePMgDDzzAxo0b+eGHH3jxxRcZOHBg4b0Kyb+0nfYw78ElEFAV4n+G8C5OV+Ve5YKg40QIrG7HZVrQV41/pWw6vMZ2ojn7uj/GZWv3GcTPsiPKixSyfA8a2atXL/bt28fQoUNJSkqiZcuWTJ48OacB8I4dO/Dx+SMfRUZGMmXKFB566CGaN29OrVq1eOCBB3j00UcL71VI/qRstDuaozsg+AK4dBqENXK6KvcLiYQOE+CnrrDjC6gUDU2HnHs5kdIg4xCsGga/vn3icuoAaPwwNH0MyoU4XZ2UYvnuR8YJ6kemEB1cBj/3gPR9UKEBdJ0GIbWdrqp02fSevSoDD3T+Dmpd6XRFIkXHmw2bR9tuG9IP2GmR10H0K2orJiWvHxlxub2zIPFSG2IqtYLusxViikK9u6DeAMDAvFsgZYPTFYkUjfQDMKOHHa4j/QCENYWu06HjBIUYKTYKMmXF79/bbsAzU6B6Z9smJrC601WVXq3/Yxs3ZqbYq8Iykp2uSKRwHV4Nky+BpOn21FHr1+HyFRDRzenKpIxRkCkLtn5ir6TJPg61ekKXH8FPp+iKlK8/dPjStkFK2WDHrfKeuTdrEVfZMcEO0ZG2FUIuhMvmQ8P7wSffzS5FzpuCTGm34Q2Yf5ttfBf1D3vIt1yQ01WVDUHhtsdS30DY9QOsHup0RSLnx3hh5VMw5wbbxUB4NztCdcVmTlcmZZiCTGllDKx+BpYOso8bDIK4seBTsIE7pYAqt4aY9+39NS/aq5lE3CgzxR7ZXXNieJlGg23fUwFVHC1LREGmNDJeWPqgHVkWoNkz0HqkBn90yoW3QqN/2vvzb4dDKx0tRyTfUjbAlFj4/Tt7WXXcf6HVCJ1KkhJB32yljTcT5veBja/bx63fgGZDNfij01r+GyK62x5OZ11je1UWcYPfJ8GUGEhZb9t8dZ8DF/7D6apEcijIlCZZx2D29XbMH48vxI2Dhvc5XZWA/eXa/nMoX9f2djr3Jhs6RUoqY+wYSTOvsqeVqrWHhCVQpY3TlYnkoiBTWmQk2/4cfv/ONi7t9LU9pSElR0Bl6PQNlCtvx7da9i+nKxI5vaw0mHszrHwcMFDvbuj6k23ALlLCKMiUBsf32o7u9s6yl1VfOgVqXeV0VXI6FZtC3Mf2/sbXYfOHztYj8lep22Bqe9jxP3txwCWjIGaU7VJApARSkHG7tB0wrSMcWg4B1aDbDKjeyemq5Gwir4GLh9n7iwfA/oWOliOSI+knmNIGDq+EwHB7FKb+3U5XJXJWCjJulrweprWHIxshuLZthFc52umqJC+aDYULrgFvhh0l+NhupyuSsswYWP8f+PkyO9RA5TbQYwlU7+B0ZSLnpCDjVgeWwPSOcPQ3CG0El82F0AZOVyV55fGxl7CGNYFju2DWdZCd7nRVUhZlH4cFfWHZg390nBk/y16hJOICCjJutOfnE4M/7re/nOJna6fjRn4VbONfv4pwYAEsGWh/GYsUl6O/w/TOsPUjG65bvQpxH6n3b3EVBRm3+e0b+PlyyEqF8K7Q7ScIrOp0VVJQFerZy7I9PrD5A/j1bacrkrJi3zyY3AYOLAL/yvYigUYPqc8pcR0FGTfZ8pHtJ8abbttXdPnB/qoXd6uZAC3/z95f+gDsmeFoOVIGbHofErvA8SQ7TlKPxRAR73RVIgWiIOMW60fCgtvtOeyLbocOX9j+YqR0aPRPiLrVvr9zboS07U5XJKVRdgYsHgiL+tsOGSOvh+7zoPxFTlcmUmAKMiWdMXa02WUP2ceNBkPsBxrjpLTxeCBmNFRqZds+zboGso46XZWUJsf3wk/xJ05feqD58/YHkV95pysTOS8KMiWZ8cKS+/4YbbbFCxD9igZ/LK3KBUGnr2x/QIdWwII71PhXCsfBZbY9zL7ZUO5EI/OLn1B7GCkV9I1YUnkzYd5tf/x6uuRtaPq4djylXUht6DgBPOVgx3hY95LTFYnbbfvU9jd1dCdUaAAJi+CCnk5XJVJoFGRKoqwTIyRv/8x+obX7FOrf43RVUlyqd4Q2J0YvXzEEdv3obD3iTt5sWP4wzLvV9hVT8wpIWAhhjZyuTKRQKciUNBmH4ecE2DUJfIOg87cQdbPTVUlxqzcA6vYHDMz9O6RsdLoicZP0gzDjClj3in3c9HHo9C34V3S0LJGioCBTkhzbA9O7wL454BcGXadBzcudrkqc4PFAmzehWnvITIZZV0NmitNViRsc/gWmxEDSVPANhvbjbfs6H1+nKxMpEgoyJUXqNpjW4Y/B2uJn2i8xKbt8/aHDlxBUC1LW2zZTxut0VVKS7fwKpraF1M0QEgWXzYM6NzldlUiRUpApCZLX2sZ4qZvszqf7HKjUwumqpCQIioBOX4NPAPz+Hawa5nRFUhIZL6x62g5AmpVme/1OWKz9iJQJCjJO278IpnW0AweGNbUhpkI9p6uSkqRKG4gdbe+veR52THC2HilZMlNsgPnlGfu44QN2uAENXSJlhIKMk5Kmw09dIeMgVIk9MeJsLaerkpLown9AwxOdIi7oA4dXO1uPlAwpv8KUtnYMNp8AaDsWWo9Uh5lSpijIOGXnRJhxpT0MHBEPXadDQGWnq5KSLPol+38lKw1mXg3pB5yuSJy0azJMuQRS1kFQTftD6KI+TlclUuwUZJyweYwdT8ebYcc66fy9ugmXc/MpZ0fKDrkQ0rbCnF7gzXK6KiluxsDal+zl1ZnJUDUOeiyBqjFOVybiCAWZ4rbuFVh4p22cV/dOe2mkb4DTVYlbBFSBzt9AuRDYkwjLH3G6IilOWUdtB3crHgWM7Wuo288QVMPpykQcoyBTXIyBFY/bnjYBGj9iBwlU3w6SXxWbQdx/7f0Nr8GW/zpbjxSPtO326saTPX5f8jbEvKsfQlLmKcgUB282LL4H1g63j1v+G6L/T+MmScFFXgcXP2XvL7rLXv0mpdeeGXbQx0Mr7KCi3RLtsCXah4goyBS57AyYdwtsehfwQMx70ORRp6uS0qDZ01Drb+BNt5ffHktyuiIpbMbAhjfhp3hI3w+VWtn2MNU7OV2ZSImhIFOUstJg1t9gx//Axw86jId6/Z2uSkoLjw+0+xhCG8Ox32H29ZCd7nRVUliy02FhP1h6P5hsqHMLdJ9tR0gXkRwKMkUl4xD81B12T7HjnXT+Hmrf6HRVUtr4hdqef/3CYP88WHK//RUv7nZ0F0zvDFvG2MAa/Qq0Gwflgp2uTKTEUZApCsd2253Q/vngX8n2EVPjMqerktIqtIG9LBsPbB4Nm0Y5XZGcj/0LYEobOLDQ7j+6/AiN/6n2MCJnoCBT2FK3nBj8cbW9JDJ+FlSLc7oqKe1q9oCWJxqTLxkEe2c5W48UzOYx9kfQsd12yJKExfoRJHIOCjKF6fBqG2JSt0D5i+y4SRUvdroqKSsaPwJ1bgaTBbNvgLQdTlckeeXNtKcFF95pO8q84Fq4bD5UqOt0ZSIlnoJMYdk3H6Z1sr+kKjazIab8RU5XJWWJxwOxH0ClaEjfB7OusR2oScl2fJ9tT7fxTfu42TPQ8Uvwq+BsXSIuoSBTGHZPtZdHZh623YXHz1RPm+KMcsHQ6SsIqAqHlturXtT4t+Q6tML2D7N3JpQrbxtuNxtqG/iKSJ7o03K+dnwBM6+C7KNQIwG6TrMN9EScElIHOnxpe3/d/pkdFkNKnm2fw9R2cHQHVKgPCQvhgqudrkrEdRRkzsem0ScG7suE2r2g07d2DBwRp4V3htYj7f2Vj8GuKY6WI3/izYblj8K8v0P2MajRAxIWQVgTpysTcSUFmYJa+3+2a3gM1Lsb2n0Cvv5OVyXyh/r32oFJjRfm3gxHNjldkWQcskdw171kHzd51PYx5V/R0bJE3ExBJr+MsSMOr3jMPm76OFzyjgZ/lJLH44E2b9l2W5mHYdbVkHnE6arKruS1MDkGdk8G3yBo95kdd037DpHzoiCTH95sWNQf1r1sH0e/Ai1eUEdVUnL5BkDHCRBU036Rzv+HPUIjxeu3b2BKLKRuguDa0H0uRN3sdFUipYKCTF5lp8PcXrD5A3tFQewHtrdNkZIuqAZ0/Ap8AuwX6upnnK6o7DBeWP3siUvhU6F6FzvoY+VopysTKTUUZPIiM9We1945AXz8ocMXUPcOp6sSybuqMRDzrr3/y7Owc6Kz9ZQFmUdsx4Srh9nHDe6HrlMhsJqzdYmUMgoy55J+wPYRkzTdXpHUZRJEXud0VSL5d1EfaPiAvT+/Nxz+xdl6SrMjm2BqHPz2lf3xEzsG2rwOPn5OVyZS6ijInM3JEWgPLAT/ytD1J4jo5nRVIgUX/QqEd4WsNNv4N/2g0xWVPrunwuRLIHnNifHWZkLdvk5XJVJqKcicyZFNMK39iZ1RLeg+2x6eF3Ezn3LQfjyERNkxwebeDN4sp6sqHYyxnQ/OuNxeJValLSQsgaptna5MpFQrUJB56623iIqKIjAwkNjYWBYtWnTGeceOHYvH48l1CwwMLHDBxeLQKjv4Y9o2KF/PjpukzqqktAisCp2+Ad9gSJr2R1cCUnBZx+wVYcsftg18L7oD4mdAcE2nKxMp9fIdZMaPH8/gwYMZNmwYy5Yto0WLFiQkJLB3794zLhMaGsru3btzbtu3bz+voovUvrkwvRMc3wOVWp4Y/DHK6apEClel5hA31t5fPwK2jnO0HFdL22F/+Gz7xA4L0eZNiH3fXvouIkUu30Hm1VdfpX///vTt25cmTZowatQogoODGTNmzBmX8Xg8RERE5NzCw8PPq+gis2uyHYU2MxmqdYBuP0NQCa1V5HzVvhGaPmHvL+wHB5Y4W48b7Z1lB308tMwO1Nl1GjQYqL6lRIpRvoJMRkYGS5cuJT4+/o8V+PgQHx/P/Pnzz7hcamoqderUITIykquvvpo1a9acdTvp6emkpKTkuhW5bZ/DzJ527JOaV8ClU9RtuJR+zZ+FmleBNx1mXwvH9jhdkTsYAxvfhsRukL7PHr3tsQTCuzhdmUiZk68gs3//frKzs085ohIeHk5SUtJpl2nYsCFjxozhm2++Ydy4cXi9Xtq1a8dvv/12xu0MHz6csLCwnFtkZGR+ysy/X0fBvFvAZEGdW6DT11AuuGi3KVISeHyg3TgIbQhHf4M510N2htNVlWzZ6XactSUDT+wzbrY99YbUcboykTKpyK9aiouLo3fv3rRs2ZLOnTszceJEqlWrxrvvvnvGZYYMGUJycnLObefOnUVTnDGw5kVYfA9goP5AaPex+nqQssU/zDb+9Qu1bcSWDnK6opLr2G5I7Aqb3wc80PL/oN2n+uEj4qBy+Zm5atWq+Pr6smdP7sPPe/bsISIiIk/r8PPzIzo6mk2bzjwSb0BAAAEBRdxQzhhY/i9Y/6p9fPFT0OwZnduWsim0oR3EcOZVsOldqBQN9e92uqqSZf+iE6ffdoFfRWj/GdTs4XRVImVevo7I+Pv707p1axITE3Omeb1eEhMTiYuLy9M6srOzWb16NTVq1MhfpYUt+xjsnW3vt3rNthVQiJGyrNYVdhBUgCX3wd45ztZTkmz5yF7NeGwXhDaGhEUKMSIlRL6OyAAMHjyYPn360KZNG2JiYhg5ciRpaWn07Wt7ruzduze1atVi+PDhADz77LO0bduWevXqcfjwYV5++WW2b99Ov379CveV5Fe5YDvcwN4ZUPsGZ2sRKSmaPAaHVsCO/9n2MglLIKSI26iVZN5MWPYv2Pi6fVzrb/b0s1+os3WJSI58B5levXqxb98+hg4dSlJSEi1btmTy5Mk5DYB37NiBj88fB3oOHTpE//79SUpKolKlSrRu3Zp58+bRpEkJ6GAusKpCjMifeTzQdgykbIDDK+2ozd3nQLkgpysrfsf3w9ybYM/P9vHFw6DZUNtAWkRKDI8xxjhdxLmkpKQQFhZGcnIyoaH6JSRS5FK3wZRLIH0/RN0KcR+XrVOvh06EuLRtUK48xP0XIq91uioR1ymO72/9tBCRU5WPgg5fgMfX9lh7slF8WbD9fzC13YkhSurCZQsUYkRKMAUZETm98C62ITzAikfsqM6lmTcbVjwOc3tB9lGIuMw26q3Y1OnKROQsFGRE5Mwa3AcX9bUDIc69GY5sdrqiopFxGGb9DdbaixRo/C/o8gMEVHa0LBE5NwUZETkzjwcueQeqxELGIZh1NWQecbqqwpW8DqbEwq5J4BsIceMg+mXwyfe1ECLiAAUZETk73wDoOBGCakDyGpjfxx6hKQ1++86GmCMbITjSDjVw4a1OVyUi+aAgIyLnFlzThhkff/jtK/jlOacrOj/GwC/P2yNMWUegeic76GPlVk5XJiL5pCAjInlTtS1cMsreX/007PzayWoKLjMV5twIq57CjrF2L3SdDoHVna5MRApAQUZE8q5uX2hwv70//x9weI2z9eRX6haY1g52TrCDw8aMhkve0kCxIi6mICMi+dNqBIRfClmpttO4jENOV5Q3SdNhchs4vBoCI6DbDKjn8FApInLeFGREJH98/KD9/yCkDqRugjk32z5YSipjYP1r8HOCDV1VYmx7mGrtnK5MRAqBgoyI5F9gVej0NfgGQdJUWDnE6YpOL+uYvcpq2WB7pdVFt0P8TAiu5XRlIlJIFGREpGAqtYS2H9r7616GbZ86Ws4p0nbC9E6w7WM71ELr/0DsGNtXjIiUGgoyIlJwdXpBk8fs/YV3wsGlztZz0t45MKUNHFwCAVXg0qnQcFDZGvhSpIxQkBGR89P8eahxOWQfh1nXwvG9ztbz67vwU1dbR8XmkLAYIro6W5OIFBkFGRE5Pz6+0P5TqNAAju6E2TdAdkbx15GdAYsGwOIB4M2E2jfBZfOg/IXFX4uIFBsFGRE5f/4VodM34BcK+2bDsgeLd/vH9sBP3WDTu4AHWgyH9p9DuZDirUNEip2CjIgUjrBG0O4TwAO/vgObRhfPdg8sgcmtYd8c8AuDzt9D08fUHkakjFCQEZHCU+sqaH5iHKYlA2Hf3KLd3taPYVoHOPY7hDaChEVQ64qi3aaIlCgKMiJSuJo+DpE32HYqs6+Ho78V/ja8WbB0MMzvDd50qNUTLlsAoQ0Kf1siUqIpyIhI4fJ4bP8yFZvB8T32SqasY4W3/vQD8HMP2PCafdz0Sds5n39Y4W1DRFxDQUZECp9fedv417+y7ctl0d12qIDzdXg1TL4E9iTahrwdvoQWz4FHuzKRskqffhEpGuUvhA7/s73qbvsYNow8v/XtmABT4yBtK5S/CC6bD7WvL5RSRcS9FGREpOhEdIPoEfb+8n/ZEajzy3hh5ZMw5wbISoOIeNvJXcVmhVuriLiSgoyIFK2Gg+DCPjaQzOkFqVvyvmxGMsy8Gta8YB83GgxdfoSAykVTq4i4joKMiBQtjwdiRkGVGMg4aINJZuq5l0vZAFNjYdf34BMAcf+FViPAp1zR1ywirqEgIyJFzzcQOk6EwAhI/gUW3H72xr+/T4IpMTbMBF8A3efAhf8otnJFxD0UZESkeATXgo4TwMcPdk7443TRnxkDa4bDzKsgMwWqdYCEJVClTfHXKyKuoCAjIsWnWjto87a9v+op+O3bP57LSoO5vWDl44CBegOgayIEhTtSqoi4g4KMiBSvev2g/r32/rzbIHkdpG6Fqe1gxxf2iM0loyDmHfD1d7ZWESnx1GpORIpf65G2rczeWTDjSshKsT32BobbTu6qd3C6QhFxCR2REZHi5+NnA0twbdvBXfoBqNwGeixRiBGRfFGQERFnBFaDzt9AaGOodxfEz7JXKImI5INOLYmIcyq1hKvWOl2FiLiYjsiIiIiIaynIiIiIiGspyIiIiIhrKciIiIiIaynIiIiIiGspyIiIiIhrKciIiIiIaynIiIiIiGspyIiIiIhrKciIiIiIaynIiIiIiGspyIiIiIhrKciIiIiIaynIiIiIiGuVc7qAvDDGAJCSkuJwJSIiIpJXJ7+3T36PFwVXBJkjR44AEBkZ6XAlIiIikl9HjhwhLCysSNbtMUUZkwqJ1+tl165dVKhQAY/HU2jrTUlJITIykp07dxIaGlpo6y1JSvtr1Otzv9L+GvX63K+0v8aifH3GGI4cOULNmjXx8Sma1iyuOCLj4+PDBRdcUGTrDw0NLZX/Of+stL9GvT73K+2vUa/P/Ur7ayyq11dUR2JOUmNfERERcS0FGREREXGtMh1kAgICGDZsGAEBAU6XUmRK+2vU63O/0v4a9frcr7S/Rre/Plc09hURERE5nTJ9REZERETcTUFGREREXEtBRkRERFzLlUGmS5cuPPjgg8WyrW3btuHxeFixYkWxbE/y7umnn6Zly5ZOl1Hm3H777VxzzTV5nn/GjBl4PB4OHz5cZDVJbk5/Npzevts5/fdzevv55cogU1ROt4OOjIxk9+7dXHzxxc4UJY4YO3YsFStWdLoMOQf90BARBRkgOzsbr9d72ud8fX2JiIigXDlXdIIshSAzM9PpEiQPMjIynC6hzDPGkJWV5XQZUkBF+f4V537UtUEmKyuL++67j7CwMKpWrcpTTz2VM7pmeno6//rXv6hVqxYhISHExsYyY8aMnGVP/tr+9ttvadKkCQEBAdxxxx189NFHfPPNN3g8HjweDzNmzDjtL741a9Zw1VVXERoaSoUKFejYsSObN28u5r+Ae3i9Xl566SXq1atHQEAAtWvX5oUXXiAjI4P77ruPGjVqEBgYSJ06dRg+fHjOcocPH6Zfv35Uq1aN0NBQunbtysqVK09Z/7vvvktkZCTBwcHcdNNNJCcn53r+/fffp3HjxgQGBtKoUSPefvvtnOdOvr/jx4+nc+fOBAYG8sknn9C3b1+Sk5Nz/i88/fTTRfb3Kam+/PJLmjVrRlBQEFWqVCE+Pp60tLRT5ktPT2fQoEFUr16dwMBAOnTowOLFi0+Zb+7cuTRv3pzAwEDatm3LL7/8kuv5OXPm0LFjR4KCgoiMjGTQoEG5thcVFcVzzz1H7969CQ0N5a677uLCCy8EIDo6Go/HQ5cuXQBYvHgx3bt3p2rVqoSFhdG5c2eWLVtWiH8dZ+3bt4+IiAhefPHFnGnz5s3D39+fxMTEU+Y/ebT5xRdfJDw8nIoVK/Lss8+SlZXFww8/TOXKlbngggv48MMPz7rdk6cJf/zxR1q3bk1AQABz5sw54/xn+2ye6z0yxvD0009Tu3ZtAgICqFmzJoMGDcp5/lz7+ZLMLe/fSXn5PHk8Ht555x3+9re/ERISwgsvvADA888/T/Xq1alQoQL9+vXjscceO+W01dn20XliXKhz586mfPny5oEHHjDr168348aNM8HBwea9994zxhjTr18/065dOzNr1iyzadMm8/LLL5uAgACzceNGY4wxH374ofHz8zPt2rUzc+fONevXrzfJycnmpptuMj169DC7d+82u3fvNunp6Wbr1q0GMMuXLzfGGPPbb7+ZypUrm+uuu84sXrzYbNiwwYwZM8asX7/eqT9HiffII4+YSpUqmbFjx5pNmzaZ2bNnm9GjR5uXX37ZREZGmlmzZplt27aZ2bNnm08//TRnufj4eNOzZ0+zePFis3HjRvPPf/7TVKlSxRw4cMAYY8ywYcNMSEiI6dq1q1m+fLmZOXOmqVevnrnlllty1jFu3DhTo0YNM2HCBLNlyxYzYcIEU7lyZTN27FhjjMl5f6OionLm2bZtmxk5cqQJDQ3N+b9w5MiR4v2jOWzXrl2mXLly5tVXXzVbt241q1atMm+99ZY5cuSI6dOnj7n66qtz5h00aJCpWbOmmTRpklmzZo3p06ePqVSpUs779PPPPxvANG7c2EydOtWsWrXKXHXVVSYqKspkZGQYY4zZtGmTCQkJMa+99prZuHGjmTt3romOjja33357znbq1KljQkNDzSuvvGI2bdpkNm3aZBYtWmQAM336dLN79+6cbSYmJpqPP/7YrFu3zqxdu9bceeedJjw83KSkpBTfH7GI/fDDD8bPz88sXrzYpKSkmIsuusg89NBDxhj72WjRokXOvH369DEVKlQwAwcONOvXrzcffPCBAUxCQoJ54YUXzMaNG81zzz1n/Pz8zM6dO8+4zZPvZfPmzc3UqVPNpk2bcv7mf5aXz+a53qMvvvjChIaGmkmTJpnt27ebhQsX5uzjjTn3fr6kK+nv35+3n5fPE2CqV69uxowZYzZv3my2b99uxo0bZwIDA82YMWPMhg0bzDPPPGNCQ0Nzrftc++i8cG2Qady4sfF6vTnTHn30UdO4cWOzfft24+vra37//fdcy3Tr1s0MGTLEGGODDGBWrFiRa56/7qCNMacEmSFDhpgLL7wwZwcsZ5eSkmICAgLM6NGjT3nu/vvvN127ds31Pp40e/ZsExoaao4fP55ret26dc27775rjLEfNl9fX/Pbb7/lPP/jjz8aHx8fs3v37pz5/xyOjDHmueeeM3FxccaYP97fkSNH5prnww8/NGFhYfl/waXE0qVLDWC2bdt2ynN//pykpqYaPz8/88knn+Q8n5GRYWrWrGleeuklY8wfO8/PP/88Z54DBw6YoKAgM378eGOMMXfeeae56667cm1n9uzZxsfHxxw7dswYY4PMNddck2uev34+zyQ7O9tUqFDBfPfdd3n7A7jEvffeaxo0aGBuueUW06xZs5zPy+m+COvUqWOys7NzpjVs2NB07Ngx53FWVpYJCQkxn3322Rm3d/K9/Prrr89aV14+m3/11/doxIgRpkGDBqfd1+ZlP+8GJfn9+/P2/+p0nyfAPPjgg7nmi42NNQMHDsw1rX379rnWfa59dF649tRS27Zt8Xg8OY/j4uL49ddfWb16NdnZ2TRo0IDy5cvn3GbOnJnr9I+/vz/NmzfP93ZXrFhBx44d8fPzK5TXUdqtW7eO9PR0unXrdspzt99+OytWrKBhw4YMGjSIqVOn5jy3cuVKUlNTqVKlSq73cevWrbnex9q1a1OrVq2cx3FxcXi9XjZs2EBaWhqbN2/mzjvvzLWO559//pRTgW3atCmCV+9eLVq0oFu3bjRr1owbb7yR0aNHc+jQoVPm27x5M5mZmbRv3z5nmp+fHzExMaxbty7XvHFxcTn3K1euTMOGDXPmWblyJWPHjs31PiUkJOD1etm6dWvOcnl9n/bs2UP//v2pX78+YWFhhIaGkpqayo4dO/L1dyjpXnnlFbKysvjiiy/45JNPztrFfNOmTfHx+WOXHx4eTrNmzXIe+/r6UqVKFfbu3QvA5ZdfnvNeNG3aNNe6/vw+/Pk9GzBgQM70s3024dzv0Y033sixY8e46KKL6N+/P1999VVOe4687udLupL8/v1ZXj9Pf/18btiwgZiYmFzT/vw4P/vosyl1LVhTU1Px9fVl6dKl+Pr65nqufPnyOfeDgoJyBaG8CgoKOu8ay5Kz/b1atWrF1q1b+fHHH5k+fTo33XQT8fHxfPnll6SmplKjRo3TnvPO69VEqampAIwePZrY2Nhcz/31/0ZISEie1llW+Pr6Mm3aNObNm8fUqVN54403eOKJJ1i4cGGRbC81NZW77747VxuIk2rXrp1zP6/vU58+fThw4AD/+c9/qFOnDgEBAcTFxZW6BsKbN29m165deL1etm3bluuL7a/++uPL4/GcdtrJCx/ef/99jh07dtpl//w+/Ln9YGhoaJ5rP9d7FBkZyYYNG5g+fTrTpk3j3nvv5eWXX2bmzJl53s+XdG55//L6ecrvfjQ/++izcW2Q+esOdcGCBdSvX5/o6Giys7PZu3cvHTt2zNc6/f39yc7OPus8zZs356OPPiIzM1NHZfKgfv36BAUFkZiYSL9+/U55PjQ0lF69etGrVy9uuOEGevTowcGDB2nVqhVJSUmUK1eOqKioM65/x44d7Nq1i5o1awL2/4GPjw8NGzYkPDycmjVrsmXLFm699dZ81Z2X/wulncfjoX379rRv356hQ4dSp04dvvrqq1zz1K1bF39/f+bOnUudOnUAe7XC4sWLT+nracGCBTmh5NChQ2zcuJHGjRsDNtSuXbuWevXq5atGf39/gFPeq7lz5/L2229zxRVXALBz507279+fr3WXdBkZGdx222306tWLhg0b0q9fP1avXk316tULZf1/PppyNmd6z8722YS8vUdBQUH07NmTnj17MnDgQBo1asTq1avPaz9fUpT09+/PCvp5atiwIYsXL6Z379450/58IcD57KP/zLVBZseOHQwePJi7776bZcuW8cYbbzBixAgaNGjArbfeSu/evRkxYgTR0dHs27ePxMREmjdvzpVXXnnGdUZFRTFlyhQ2bNhAlSpVCAsLO2We++67jzfeeIObb76ZIUOGEBYWxoIFC4iJicn5gMofAgMDefTRR3nkkUfw9/enffv27Nu3jzVr1pCcnEyNGjWIjo7Gx8eHL774goiICCpWrEh8fDxxcXFcc801vPTSSzRo0IBdu3bxww8/cO211+YcwgwMDKRPnz688sorpKSkMGjQIG666SYiIiIAeOaZZxg0aBBhYWH06NGD9PR0lixZwqFDhxg8ePAZ646KiiI1NZXExERatGhBcHAwwcHBxfI3KwkWLlxIYmIil112GdWrV2fhwoXs27ePxo0bs2rVqpz5QkJCuOeee3KunKhduzYvvfQSR48e5c4778y1zmeffZYqVaoQHh7OE088QdWqVXP6bXr00Udp27Yt9913H/369SMkJIS1a9cybdo03nzzzTPWWb16dYKCgpg8eTIXXHABgYGBhIWFUb9+fT7++GPatGlDSkoKDz/8cKk7mvrEE0+QnJzM66+/Tvny5Zk0aRJ33HEH33//vdOlAef+bJ7rPRo7dizZ2dnExsYSHBzMuHHjCAoKok6dOlSpUqXA+/mSoqS/f39W0M/T/fffT//+/WnTpg3t2rVj/PjxrFq1iosuuihnnoLuo3PJc2uaEqRz587m3nvvNQMGDDChoaGmUqVK5vHHH89pNJqRkWGGDh1qoqKijJ+fn6lRo4a59tprzapVq4wxZ27IuXfvXtO9e3dTvnx5A5iff/75tI0JV65caS677DITHBxsKlSoYDp27Gg2b95cHC/dlbKzs83zzz9v6tSpY/z8/Ezt2rXNiy++aN577z3TsmVLExISYkJDQ023bt3MsmXLcpZLSUkx999/v6lZs6bx8/MzkZGR5tZbbzU7duwwxvzRIO3tt982NWvWNIGBgeaGG24wBw8ezLX9Tz75xLRs2dL4+/ubSpUqmU6dOpmJEycaY87eWHTAgAGmSpUqBjDDhg0rsr9PSbR27VqTkJBgqlWrZgICAkyDBg3MG2+8YYw5tVH8sWPHzP3332+qVq1qAgICTPv27c2iRYtynj/ZwPC7774zTZs2Nf7+/iYmJsasXLky1zYXLVqU8/kLCQkxzZs3Ny+88ELO83Xq1DGvvfbaKbWOHj3aREZGGh8fH9O5c2djjDHLli0zbdq0MYGBgaZ+/frmiy++OOPybvTzzz+bcuXKmdmzZ+dM27p1qwkNDTVvv/32aRuL/vVChs6dO5sHHngg17Rz/Y1OvpeHDh06a315+Wye6z366quvTGxsrAkNDTUhISGmbdu2Zvr06TnLn2s/X5K55f07KS+fJ8B89dVXp6zr2WefNVWrVjXly5c3d9xxhxk0aJBp27ZtrnnOto/OC8+JAkRERESKVPfu3YmIiODjjz8utHW69tSSiIiIlFxHjx5l1KhRJCQk4Ovry2effZbTeLsw6YiMiIiIFLpjx47Rs2dPli9fzvHjx2nYsCFPPvkk1113XaFuR0FGREREXMu1HeKJiIiIKMiIiIiIaynIiIiIiGspyIiIiIhrKciIiIiIaynIiEiJM2PGDDweD4cPH87zMlFRUYwcObLIahKRkklBRkTy7fbbb8fj8TBgwIBTnhs4cCAej4fbb7+9+AsTkTJHQUZECiQyMpLPP/+cY8eO5Uw7fvw4n376ac4o1yIiRU1BRkQKpFWrVkRGRjJx4sScaRMnTqR27dpER0fnTEtPT2fQoEFUr16dwMBAOnTowOLFi3Ota9KkSTRo0ICgoCAuvfRStm3bdsr25syZQ8eOHQkKCiIyMpJBgwaRlpZWZK9PRNxBQUZECuyOO+7gww8/zHk8ZswY+vbtm2ueRx55hAkTJvDRRx+xbNky6tWrR0JCAgcPHgRg586dXHfddfTs2ZMVK1bQr18/HnvssVzr2Lx5Mz169OD6669n1apVjB8/njlz5nDfffcV/YsUkRJNQUZECuy2225jzpw5bN++ne3btzN37lxuu+22nOfT0tJ45513ePnll7n88stp0qQJo0ePJigoiA8++ACAd955h7p16zJixAgaNmzIrbfeekr7muHDh3Prrbfy4IMPUr9+fdq1a8frr7/Of//7X44fP16cL1lEShiNfi0iBVatWjWuvPJKxo4dizGGK6+8kqpVq+Y8v3nzZjIzM2nfvn3OND8/P2JiYli3bh0A69atIzY2Ntd64+Licj1euXIlq1at4pNPPsmZZozB6/WydetWGjduXBQvT0RcQEFGRM7LHXfckXOK56233iqSbaSmpnL33XczaNCgU55Tw2KRsk1BRkTOS48ePcjIyMDj8ZCQkJDrubp16+Lv78/cuXOpU6cOAJmZmSxevJgHH3wQgMaNG/Ptt9/mWm7BggW5Hrdq1Yq1a9dSr169onshIuJKaiMjIufF19eXdevWsXbtWnx9fXM9FxISwj333MPDDz/M5MmTWbt2Lf379+fo0aPceeedAAwYMIBff/2Vhx9+mA0bNvDpp58yduzYXOt59NFHmTdvHvfddx8rVqzg119/5ZtvvlFjXxFRkBGR8xcaGkpoaOhpn/v3v//N9ddfzz/+8Q9atWrFpk2bmDJlCpUqVQLsqaEJEybw9ddf06JFC0aNGsWLL76Yax3Nmzdn5syZbNy4kY4dOxIdHc3QoUOpWbNmkb82ESnZPMYY43QRIiIiIgWhIzIiIiLiWgoyIiIi4loKMiIiIuJaCjIiIiLiWgoyIiIi4loKMiIiIuJaCjIiIiLiWgoyIiIi4loKMiIiIuJaCjIiIiLiWgoyIiIi4lr/DzpRuB4lstrnAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get average micro and macro F1\n",
    "dataset = \"datasets/reldi-normtagner-sr.conllup_extracted.json\"\n",
    "\n",
    "# Define the dataset to inspect\n",
    "import matplotlib as plt\n",
    "results[results[\"Dataset\"] == dataset].groupby(\"Model\")[\"Micro F1\"].mean().plot(kind=\"line\", color=\"blue\")\n",
    "results[results[\"Dataset\"] == dataset].groupby(\"Model\")[\"Macro F1\"].mean().plot(kind=\"line\",color=\"orange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run</th>\n",
       "      <th>datasets/hr500k.conllup_extracted.json</th>\n",
       "      <th>datasets/reldi-normtagner-hr.conllup_extracted.json</th>\n",
       "      <th>datasets/reldi-normtagner-sr.conllup_extracted.json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bertic-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bertic-1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>csebert-0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>csebert-1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sloberta-0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sloberta-1</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xlm-r-base-0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xlm-r-base-1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xlm-r-large-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xlm-r-large-1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>xlmrl_bcms_48000-0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>xlmrl_bcms_48000-1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Run  datasets/hr500k.conllup_extracted.json  \\\n",
       "0             bertic-0                                    0.92   \n",
       "1             bertic-1                                    0.92   \n",
       "2            csebert-0                                    0.91   \n",
       "3            csebert-1                                    0.91   \n",
       "4           sloberta-0                                    0.89   \n",
       "5           sloberta-1                                    0.88   \n",
       "6         xlm-r-base-0                                    0.91   \n",
       "7         xlm-r-base-1                                    0.90   \n",
       "8        xlm-r-large-0                                    0.92   \n",
       "9        xlm-r-large-1                                    0.92   \n",
       "10  xlmrl_bcms_48000-0                                    0.02   \n",
       "11  xlmrl_bcms_48000-1                                    0.03   \n",
       "\n",
       "    datasets/reldi-normtagner-hr.conllup_extracted.json  \\\n",
       "0                                                0.62     \n",
       "1                                                0.62     \n",
       "2                                                0.79     \n",
       "3                                                0.79     \n",
       "4                                                0.50     \n",
       "5                                                0.55     \n",
       "6                                                0.72     \n",
       "7                                                0.70     \n",
       "8                                                0.73     \n",
       "9                                                0.75     \n",
       "10                                                NaN     \n",
       "11                                                NaN     \n",
       "\n",
       "    datasets/reldi-normtagner-sr.conllup_extracted.json  \n",
       "0                                                0.51    \n",
       "1                                                0.48    \n",
       "2                                                0.67    \n",
       "3                                                0.66    \n",
       "4                                                0.44    \n",
       "5                                                0.44    \n",
       "6                                                0.57    \n",
       "7                                                0.61    \n",
       "8                                                0.72    \n",
       "9                                                0.67    \n",
       "10                                                NaN    \n",
       "11                                                NaN    "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results[\"Dataset\"] == dataset].groupby(\"Model\")[\"Macro F1\"].mean().round(2)\n",
    "\n",
    "results[\"Macro F1\"] = results[\"Macro F1\"].round(2)\n",
    "\n",
    "# Pivot the DataFrame to rearrange columns into rows\n",
    "pivot_df = results.pivot(index='Run', columns='Dataset', values='Macro F1')\n",
    "\n",
    "# Rename the columns\n",
    "pivot_df.columns = list(results.Dataset.unique())\n",
    "\n",
    "# Reset the index to have 'Model' as a column\n",
    "pivot_df.reset_index(inplace=True)\n",
    "\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "match\n",
       "yes    50693\n",
       "no       497\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's analyze the df with all the predictions\n",
    "import numpy as np\n",
    "\n",
    "pred_df = pd.read_csv(\"datasets/hr500k.conllup_extracted.json-test_df-with-predictions.csv\", index_col = 0)\n",
    "\n",
    "# Analyze instances where models are wrong\n",
    "pred_df[\"match\"] = np.where(pred_df[\"labels\"] != pred_df[\"y_pred_xlm-r-large_0\"], \"no\", \"yes\")\n",
    "pred_df.match.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>words</th>\n",
       "      <th>labels</th>\n",
       "      <th>y_pred_xlm-r-large_0</th>\n",
       "      <th>y_pred_xlm-r-large_1</th>\n",
       "      <th>y_pred_sloberta_0</th>\n",
       "      <th>y_pred_sloberta_1</th>\n",
       "      <th>y_pred_csebert_0</th>\n",
       "      <th>y_pred_csebert_1</th>\n",
       "      <th>y_pred_xlm-r-base_0</th>\n",
       "      <th>y_pred_xlm-r-base_1</th>\n",
       "      <th>y_pred_bertic_0</th>\n",
       "      <th>y_pred_bertic_1</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9433</th>\n",
       "      <td>30</td>\n",
       "      <td>11.</td>\n",
       "      <td>O</td>\n",
       "      <td>B-misc</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9434</th>\n",
       "      <td>30</td>\n",
       "      <td>9.</td>\n",
       "      <td>O</td>\n",
       "      <td>I-misc</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9454</th>\n",
       "      <td>30</td>\n",
       "      <td>rujna</td>\n",
       "      <td>O</td>\n",
       "      <td>I-misc</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9769</th>\n",
       "      <td>42</td>\n",
       "      <td>11.</td>\n",
       "      <td>O</td>\n",
       "      <td>B-misc</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9881</th>\n",
       "      <td>45</td>\n",
       "      <td>de</td>\n",
       "      <td>O</td>\n",
       "      <td>B-per</td>\n",
       "      <td>B-per</td>\n",
       "      <td>B-per</td>\n",
       "      <td>B-per</td>\n",
       "      <td>B-per</td>\n",
       "      <td>B-per</td>\n",
       "      <td>B-per</td>\n",
       "      <td>B-per</td>\n",
       "      <td>B-per</td>\n",
       "      <td>B-per</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491595</th>\n",
       "      <td>2452</td>\n",
       "      <td>Domu</td>\n",
       "      <td>O</td>\n",
       "      <td>B-org</td>\n",
       "      <td>B-org</td>\n",
       "      <td>B-org</td>\n",
       "      <td>B-org</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-org</td>\n",
       "      <td>B-org</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491958</th>\n",
       "      <td>2472</td>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "      <td>B-misc</td>\n",
       "      <td>B-org</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-misc</td>\n",
       "      <td>B-misc</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491959</th>\n",
       "      <td>2472</td>\n",
       "      <td>Mile</td>\n",
       "      <td>B-org</td>\n",
       "      <td>I-misc</td>\n",
       "      <td>I-org</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-misc</td>\n",
       "      <td>O</td>\n",
       "      <td>I-org</td>\n",
       "      <td>I-misc</td>\n",
       "      <td>B-misc</td>\n",
       "      <td>B-misc</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491977</th>\n",
       "      <td>2473</td>\n",
       "      <td>Domu</td>\n",
       "      <td>O</td>\n",
       "      <td>B-org</td>\n",
       "      <td>B-org</td>\n",
       "      <td>B-org</td>\n",
       "      <td>B-org</td>\n",
       "      <td>B-org</td>\n",
       "      <td>B-org</td>\n",
       "      <td>B-org</td>\n",
       "      <td>B-org</td>\n",
       "      <td>B-org</td>\n",
       "      <td>O</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491978</th>\n",
       "      <td>2473</td>\n",
       "      <td>zdravlja</td>\n",
       "      <td>O</td>\n",
       "      <td>I-org</td>\n",
       "      <td>I-org</td>\n",
       "      <td>I-org</td>\n",
       "      <td>O</td>\n",
       "      <td>I-org</td>\n",
       "      <td>I-org</td>\n",
       "      <td>I-org</td>\n",
       "      <td>I-org</td>\n",
       "      <td>O</td>\n",
       "      <td>I-org</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>497 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_id     words labels y_pred_xlm-r-large_0  \\\n",
       "9433             30       11.      O               B-misc   \n",
       "9434             30        9.      O               I-misc   \n",
       "9454             30     rujna      O               I-misc   \n",
       "9769             42       11.      O               B-misc   \n",
       "9881             45        de      O                B-per   \n",
       "...             ...       ...    ...                  ...   \n",
       "491595         2452      Domu      O                B-org   \n",
       "491958         2472         2      O               B-misc   \n",
       "491959         2472      Mile  B-org               I-misc   \n",
       "491977         2473      Domu      O                B-org   \n",
       "491978         2473  zdravlja      O                I-org   \n",
       "\n",
       "       y_pred_xlm-r-large_1 y_pred_sloberta_0 y_pred_sloberta_1  \\\n",
       "9433                      O                 O                 O   \n",
       "9434                      O                 O                 O   \n",
       "9454                      O                 O                 O   \n",
       "9769                      O                 O                 O   \n",
       "9881                  B-per             B-per             B-per   \n",
       "...                     ...               ...               ...   \n",
       "491595                B-org             B-org             B-org   \n",
       "491958                B-org                 O                 O   \n",
       "491959                I-org                 O                 O   \n",
       "491977                B-org             B-org             B-org   \n",
       "491978                I-org             I-org                 O   \n",
       "\n",
       "       y_pred_csebert_0 y_pred_csebert_1 y_pred_xlm-r-base_0  \\\n",
       "9433                  O                O                   O   \n",
       "9434                  O                O                   O   \n",
       "9454                  O                O                   O   \n",
       "9769                  O                O                   O   \n",
       "9881              B-per            B-per               B-per   \n",
       "...                 ...              ...                 ...   \n",
       "491595                O                O               B-org   \n",
       "491958                O                O              B-misc   \n",
       "491959           B-misc                O               I-org   \n",
       "491977            B-org            B-org               B-org   \n",
       "491978            I-org            I-org               I-org   \n",
       "\n",
       "       y_pred_xlm-r-base_1 y_pred_bertic_0 y_pred_bertic_1 match  \n",
       "9433                     O               O               O    no  \n",
       "9434                     O               O               O    no  \n",
       "9454                     O               O               O    no  \n",
       "9769                     O               O               O    no  \n",
       "9881                 B-per           B-per           B-per    no  \n",
       "...                    ...             ...             ...   ...  \n",
       "491595               B-org               O               O    no  \n",
       "491958              B-misc               O               O    no  \n",
       "491959              I-misc          B-misc          B-misc    no  \n",
       "491977               B-org           B-org               O    no  \n",
       "491978               I-org               O           I-org    no  \n",
       "\n",
       "[497 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df[pred_df[\"match\"] == \"no\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
