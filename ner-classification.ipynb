{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each dataset (2 HR, 2 SR, 4 SLO):\n",
    "\n",
    "    - For each model (XLM-R-base, XLM-R-large, CSEBert, SloBERTa, BERTić, multiple versions of XLM-R-BERTić and XLM-R-SloBERTić):\n",
    "\n",
    "\n",
    "        - fine-tune the model and evaluate it - 5 times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Dataset Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "# Define the gpu on the gpu machine\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=2\n",
    "\n",
    "import evaluate\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from simpletransformers.ner import NERModel, NERArgs\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tqdm.autonotebook import tqdm as notebook_tqdm\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import logging\n",
    "import sklearn\n",
    "from numba import cuda\n",
    "import argparse\n",
    "import gc\n",
    "import torch\n",
    "import time\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B-loc', 'B-org', 'B-per', 'I-per', 'B-deriv-per', 'I-org', 'I-loc', 'B-misc', 'I-misc', 'I-deriv-per']\n",
      "(398681, 3) (51190, 3) (49764, 3)\n",
      "     sentence_id      words labels\n",
      "717            0      Kazna      O\n",
      "718            0  medijskom      O\n",
      "719            0     mogulu      O\n",
      "720            0   obnovila      O\n",
      "721            0   raspravu      O\n"
     ]
    }
   ],
   "source": [
    "# Import the dataset\n",
    "\n",
    "# Code for python script\n",
    "\"\"\"\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"dataset\", help=\"path to the dataset in JSON format\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "# Define the path to the dataset\n",
    "dataset_path = args.dataset\n",
    "\"\"\"\n",
    "# Define the path to the dataset\n",
    "dataset_path = \"datasets/hr500k.conllup_extracted.json\"\n",
    "\n",
    "# Load the json file\n",
    "with open(dataset_path, \"r\") as file:\n",
    "    json_dict = json.load(file)\n",
    "\n",
    "# Open the train, eval and test dictionaries as DataFrames\n",
    "train_df = pd.DataFrame(json_dict[\"train\"])\n",
    "test_df = pd.DataFrame(json_dict[\"test\"])\n",
    "dev_df = pd.DataFrame(json_dict[\"dev\"])\n",
    "\n",
    "# Change the sentence_ids to numbers\n",
    "test_df['sentence_id'] = pd.factorize(test_df['sentence_id'])[0]\n",
    "train_df['sentence_id'] = pd.factorize(train_df['sentence_id'])[0]\n",
    "dev_df['sentence_id'] = pd.factorize(dev_df['sentence_id'])[0]\n",
    "\n",
    "# Define the labels\n",
    "LABELS = json_dict[\"labels\"]\n",
    "print(LABELS)\n",
    "\n",
    "print(train_df.shape, test_df.shape, dev_df.shape)\n",
    "print(train_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(model, train_df, test_df, dataset_path, LABELS):\n",
    "\n",
    "    # Define the model\n",
    "\n",
    "    # Define the model arguments - use the same one as for XLM-R-large if model is based on it,\n",
    "    # if the model is of same size as XLM-R-base, use its optimal hyperparameters (I searched for them before)\n",
    "    xlm_r_large_args = {\"overwrite_output_dir\": True,\n",
    "                \"num_train_epochs\": 5,\n",
    "                \"labels_list\": LABELS,\n",
    "                \"learning_rate\": 1e-5,\n",
    "                \"train_batch_size\": 32,\n",
    "                # Comment out no_cache and no_save if you want to save the model\n",
    "                \"no_cache\": True,\n",
    "                \"no_save\": True,\n",
    "                \"max_seq_length\": 256,\n",
    "                \"save_steps\": -1,\n",
    "                \"silent\": True,\n",
    "                }\n",
    "\n",
    "    xlm_r_base_args = {\"overwrite_output_dir\": True,\n",
    "             \"num_train_epochs\": 9,\n",
    "             \"labels_list\": LABELS,\n",
    "             \"learning_rate\": 1e-5,\n",
    "             \"train_batch_size\": 32,\n",
    "             # Comment out no_cache and no_save if you want to save the model\n",
    "             \"no_cache\": True,\n",
    "             \"no_save\": True,\n",
    "             \"max_seq_length\": 256,\n",
    "             \"save_steps\": -1,\n",
    "            \"silent\": True,\n",
    "             }\n",
    "\n",
    "\n",
    "    # Model type - a dictionary of type and model name.\n",
    "    # To refer to our own models, use the path to the model directory as the model name.\n",
    "    model_type_dict = {\n",
    "        \"sloberta\": [\"camembert\", \"EMBEDDIA/sloberta\", xlm_r_base_args],\n",
    "        \"csebert\": [\"bert\", \"EMBEDDIA/crosloengual-bert\", xlm_r_base_args],\n",
    "        \"xlm-r-base\": [\"xlmroberta\", \"xlm-roberta-base\", xlm_r_base_args],\n",
    "        \"xlm-r-large\": [\"xlmroberta\", \"xlm-roberta-large\", xlm_r_large_args],\n",
    "        \"bertic\": [\"electra\", \"classla/bcms-bertic\", xlm_r_base_args],\n",
    "        \"xlmrb_bcms_12\": [\"xlmroberta\", \"models/xlmrb_bcms_12\", xlm_r_base_args],\n",
    "        \"xlmrl_bcms_48000\": [\"xlmroberta\", \"output\", xlm_r_large_args]\n",
    "    }\n",
    "\n",
    "    # Update the hyperparameters accordingly to the model\n",
    "    model_args = model_type_dict[model][2]\n",
    "\n",
    "    if \"bcms\" in model:\n",
    "        model_path = model_type_dict[model][1]\n",
    "        model_args[\"output_dir\"] = \"models/{}/\".format(model)\n",
    "        model_args[\"no_save\"] = False\n",
    "        model_args[\"num_train_epoch\"] = 1\n",
    "\n",
    "    # Define the model\n",
    "    current_model = NERModel(\n",
    "    model_type_dict[model][0],\n",
    "    model_type_dict[model][1],\n",
    "    labels = LABELS,\n",
    "    use_cuda=True,\n",
    "    args = model_args)\n",
    "\n",
    "    print(\"Training started. Current model: {}\".format(model))\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Fine-tune the model\n",
    "    current_model.train_model(train_df)\n",
    "\n",
    "    print(\"Training completed.\")\n",
    "\n",
    "    training_time = round((time.time() - start_time)/60,2)\n",
    "\n",
    "    print(\"It took {} minutes for {} instances.\".format(training_time, train_df.shape[0]))\n",
    "\n",
    "    # Clean cache\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    start_evaluation_time = time.time()\n",
    "\n",
    "    # Evaluate the model\n",
    "    results = current_model.eval_model(test_df)\n",
    "\n",
    "    print(\"Evaluation completed.\")\n",
    "\n",
    "    evaluation_time = round((time.time() - start_evaluation_time)/60,2)\n",
    "\n",
    "    print(\"It took {} minutes for {} instances.\".format(evaluation_time, test_df.shape[0]))\n",
    "\n",
    "    # Get predictions\n",
    "    preds = results[1]\n",
    "\n",
    "    # Create a list with predictions\n",
    "    preds_list = []\n",
    "\n",
    "    for sentence in preds:\n",
    "        for word in sentence:\n",
    "            current_word = []\n",
    "            for element in word:\n",
    "                # Find prediction with the highest value\n",
    "                highest_index = element.index(max(element))\n",
    "                # Transform the index to label\n",
    "                current_pred = current_model.config.id2label[highest_index]\n",
    "                # Append to the list\n",
    "                current_word.append(current_pred)\n",
    "            # Segmentation can result in multiple predictions for one word - use the first prediction only\n",
    "            preds_list.append(current_word[0])\n",
    "    \n",
    "    # Get y_true\n",
    "    y_true = list(test_df.labels)\n",
    "\n",
    "    run_name = \"{}-{}\".format(dataset_path, model)\n",
    "\n",
    "    # Evaluate predictions\n",
    "    metrics = evaluate.testing(y_true, preds_list, list(test_df.labels.unique()), run_name, show_matrix=True)\n",
    "\n",
    "    # Add y_pred and y_true to the metrics dict\n",
    "    metrics[\"y_true\"] = y_true\n",
    "    metrics[\"y_pred\"] = preds_list\n",
    "\n",
    "    # Let's also add entire results\n",
    "    metrics[\"results_output\"] = results    \n",
    "    \n",
    "    # The function returns a dict with accuracy, micro f1, macro f1, y_true and y_pred\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/cache/nikolal/xlmrl_bcms_exp/checkpoint-6000',\n",
       " '/cache/nikolal/xlmrl_bcms_exp/checkpoint-12000',\n",
       " '/cache/nikolal/xlmrl_bcms_exp/checkpoint-18000',\n",
       " '/cache/nikolal/xlmrl_bcms_exp/checkpoint-24000',\n",
       " '/cache/nikolal/xlmrl_bcms_exp/checkpoint-30000',\n",
       " '/cache/nikolal/xlmrl_bcms_exp/checkpoint-36000',\n",
       " '/cache/nikolal/xlmrl_bcms_exp/checkpoint-42000',\n",
       " '/cache/nikolal/xlmrl_bcms_exp/checkpoint-48000',\n",
       " '/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-6000',\n",
       " '/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-12000',\n",
       " '/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-18000',\n",
       " '/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-24000',\n",
       " '/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-30000',\n",
       " '/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-42000',\n",
       " '/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-48000']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create lists of all needed models for the task\n",
    "base_dict = {\"/cache/nikolal/xlmrb_bcms_exp/checkpoint-12000\": \"xlmrb_bcms-12\", \"/cache/nikolal/xlmrb_bcms_exp/checkpoint-24000\": \"xlmrb_bcms-24\", \"/cache/nikolal/xlmrb_bcms_exp/checkpoint-36000\": \"xlmrb_bcms-36\", \"/cache/nikolal/xlmrb_bcms_exp/checkpoint-48000\": \"xlmrb_bcms-48\", \"/cache/nikolal/xlmrb_bcms_exp/checkpoint-60000\": \"xlmrb_bcms-60\", \"/cache/nikolal/xlmrb_bcms_exp/checkpoint-72000\": \"xlmrb_bcms-72\", \"/cache/nikolal/xlmrb_bcms_exp/checkpoint-84000\": \"xlmrb_bcms-84\", \"/cache/nikolal/xlmrb_bcms_exp/checkpoint-96000\": \"xlmrb_bcms-96\"}\n",
    "large_dict = {\"/cache/nikolal/xlmrl_bcms_exp/checkpoint-6000\": \"xlmrl_bcms-6\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-12000\":\"xlmrl_bcms-12\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-18000\": \"xlmrl_bcms-18\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-24000\": \"xlmrl_bcms-24\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-30000\": \"xlmrl_bcms-30\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-36000\": \"xlmrl_bcms-36\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-42000\": \"xlmrl_bcms-42\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-48000\": \"xlmrl_bcms-48\", \"/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-6000\": \"xlmrl_sl-bcms-6\", \"/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-12000\": \"xlmrl_sl-bcms-12\", \"/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-18000\": \"xlmrl_sl-bcms-18\", \"/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-24000\": \"xlmrl_sl-bcms-24\", \"/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-30000\": \"xlmrl_sl-bcms-30\", \"/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-42000\": \"xlmrl_sl-bcms-42\", \"/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-48000\": \"xlmrl_sl-bcms-48\"}\n",
    "\n",
    "base_list = list(base_dict.keys())\n",
    "large_list = list(large_dict.keys())\n",
    "large_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xlmrl_bcms-6', 'xlmrl_bcms-12', 'xlmrl_bcms-18', 'xlmrl_bcms-24', 'xlmrl_bcms-30', 'xlmrl_bcms-36', 'xlmrl_bcms-42', 'xlmrl_bcms-48', 'xlmrl_sl-bcms-6', 'xlmrl_sl-bcms-12', 'xlmrl_sl-bcms-18', 'xlmrl_sl-bcms-24', 'xlmrl_sl-bcms-30', 'xlmrl_sl-bcms-42', 'xlmrl_sl-bcms-48']\n",
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "print(list(large_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_checkpoint(model_path, model_size, train_df, test_df, dataset_path, LABELS):\n",
    "\t# When fine-tuning our custom models that we pre-trained, and using them from checkpoints, the process is a bit different than with publicly available models: first, we need to fine-tune a model from the original checkpoint, so that we save the model and overwrite its original settings which force pretraining from a specific step (and disable fine-tuning by that). Then we take that new model and fine-tune it, as we did with the models before. \n",
    "\n",
    "\t# Create lists of all needed models for the task\n",
    "\tpath_list = {\"/cache/nikolal/xlmrb_bcms_exp/checkpoint-12000\": \"xlmrb_bcms-12\", \"/cache/nikolal/xlmrb_bcms_exp/checkpoint-24000\": \"xlmrb_bcms-24\", \"/cache/nikolal/xlmrb_bcms_exp/checkpoint-36000\": \"xlmrb_bcms-36\", \"/cache/nikolal/xlmrb_bcms_exp/checkpoint-48000\": \"xlmrb_bcms-48\", \"/cache/nikolal/xlmrb_bcms_exp/checkpoint-60000\": \"xlmrb_bcms-60\", \"/cache/nikolal/xlmrb_bcms_exp/checkpoint-72000\": \"xlmrb_bcms-72\", \"/cache/nikolal/xlmrb_bcms_exp/checkpoint-84000\": \"xlmrb_bcms-84\", \"/cache/nikolal/xlmrb_bcms_exp/checkpoint-96000\": \"xlmrb_bcms-96\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-6000\": \"xlmrl_bcms-6\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-12000\":\"xlmrl_bcms-12\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-18000\": \"xlmrl_bcms-18\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-24000\": \"xlmrl_bcms-24\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-30000\": \"xlmrl_bcms-30\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-36000\": \"xlmrl_bcms-36\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-42000\": \"xlmrl_bcms-42\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-48000\": \"xlmrl_bcms-48\", \"/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-6000\": \"xlmrl_sl-bcms-6\", \"/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-12000\": \"xlmrl_sl-bcms-12\", \"/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-18000\": \"xlmrl_sl-bcms-18\", \"/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-24000\": \"xlmrl_sl-bcms-24\", \"/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-30000\": \"xlmrl_sl-bcms-30\", \"/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-42000\": \"xlmrl_sl-bcms-42\", \"/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-48000\": \"xlmrl_sl-bcms-48\"}\n",
    "\n",
    "\t# Define the model arguments - use the same one as for XLM-R-large if model is based on it,\n",
    "\t# if the model is of same size as XLM-R-base, use its optimal hyperparameters (I searched for them before)\n",
    "\txlm_r_large_args = {\"overwrite_output_dir\": True,\n",
    "\t\t\t\"num_train_epochs\": 5,\n",
    "\t\t\t\"labels_list\": LABELS,\n",
    "\t\t\t\"learning_rate\": 1e-5,\n",
    "\t\t\t\"train_batch_size\": 32,\n",
    "\t\t\t# Comment out no_cache and no_save if you want to save the model\n",
    "\t\t\t\"no_cache\": True,\n",
    "\t\t\t\"no_save\": True,\n",
    "\t\t\t\"max_seq_length\": 256,\n",
    "\t\t\t\"save_steps\": -1,\n",
    "\t\t\t\"silent\": True,\n",
    "\t\t\t}\n",
    "\n",
    "\txlm_r_base_args = {\"overwrite_output_dir\": True,\n",
    "\t\t\t\"num_train_epochs\": 9,\n",
    "\t\t\t\"labels_list\": LABELS,\n",
    "\t\t\t\"learning_rate\": 1e-5,\n",
    "\t\t\t\"train_batch_size\": 32,\n",
    "\t\t\t# Comment out no_cache and no_save if you want to save the model\n",
    "\t\t\t\"no_cache\": True,\n",
    "\t\t\t\"no_save\": True,\n",
    "\t\t\t\"max_seq_length\": 256,\n",
    "\t\t\t\"save_steps\": -1,\n",
    "\t\t\t\"silent\": True,\n",
    "\t\t\t}\n",
    "\t\n",
    "\tif model_size == \"base\":\n",
    "\t\t# Update the hyperparameters accordingly to the model\n",
    "\t\tmodel_args = xlm_r_base_args\n",
    "\telif model_size == \"large\":\n",
    "\t\tmodel_args = xlm_r_large_args\n",
    "\n",
    "\t# Add additional arguments, specific for our own models\n",
    "\t# Specify the folder where we want to save the models\n",
    "\tnew_model_path = path_list[model_path]\n",
    "\tmodel_args[\"output_dir\"] = \"models/{}/\".format(new_model_path)\n",
    "\tmodel_args[\"no_save\"] = False\n",
    "\tmodel_args[\"num_train_epoch\"] = 1\n",
    "\n",
    "\t# Define the model\n",
    "\tcurrent_model = NERModel(\n",
    "\t\"xlmroberta\",\n",
    "\tmodel_path,\n",
    "\tlabels = LABELS,\n",
    "\tuse_cuda=True,\n",
    "\targs = model_args)\n",
    "\n",
    "\tprint(\"Training started. Current model: {}\".format(model))\n",
    "\tstart_time = time.time()\n",
    "\n",
    "\t# Fine-tune the model\n",
    "\tcurrent_model.train_model(train_df)\n",
    "\n",
    "\tprint(\"Training completed.\")\n",
    "\n",
    "\tprint(\"Model saved as models/{}/\".format(new_model_path))\n",
    "\n",
    "\t# Clean cache\n",
    "\tgc.collect()\n",
    "\ttorch.cuda.empty_cache()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\t#start_evaluation_time = time.time()\n",
    "\n",
    "\t# Evaluate the model\n",
    "\t#results = current_model.eval_model(test_df)\n",
    "\n",
    "\t#print(\"Evaluation completed.\")\n",
    "\n",
    "\t#evaluation_time = round((time.time() - start_evaluation_time)/60,2)\n",
    "\n",
    "\t#print(\"It took {} minutes for {} instances.\".format(evaluation_time, test_df.shape[0]))\n",
    "\n",
    "\t# Get predictions\n",
    "\t#preds = results[1]\n",
    "\n",
    "\t# Create a list with predictions\n",
    "\t#preds_list = []\n",
    "\n",
    "\tfor sentence in preds:\n",
    "\t\tfor word in sentence:\n",
    "\t\t\tcurrent_word = []\n",
    "\t\t\tfor element in word:\n",
    "\t\t\t\t# Find prediction with the highest value\n",
    "\t\t\t\thighest_index = element.index(max(element))\n",
    "\t\t\t\t# Transform the index to label\n",
    "\t\t\t\tcurrent_pred = current_model.config.id2label[highest_index]\n",
    "\t\t\t\t# Append to the list\n",
    "\t\t\t\tcurrent_word.append(current_pred)\n",
    "\t\t\t# Segmentation can result in multiple predictions for one word - use the first prediction only\n",
    "\t\t\tpreds_list.append(current_word[0])\n",
    "\n",
    "\t# Get y_true\n",
    "\ty_true = list(test_df.labels)\n",
    "\n",
    "\trun_name = \"{}-{}\".format(dataset_path, model)\n",
    "\n",
    "\t# Evaluate predictions\n",
    "\tmetrics = evaluate.testing(y_true, preds_list, list(test_df.labels.unique()), run_name, show_matrix=True)\n",
    "\n",
    "\t# Add y_pred and y_true to the metrics dict\n",
    "\tmetrics[\"y_true\"] = y_true\n",
    "\tmetrics[\"y_pred\"] = preds_list\n",
    "\n",
    "\t# Let's also add entire results\n",
    "\tmetrics[\"results_output\"] = results    \n",
    "\n",
    "\t# The function returns a dict with accuracy, micro f1, macro f1, y_true and y_pred\n",
    "\treturn metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started. Current model: xlmrb_bcms_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.ner.ner_model: Converting to features started.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "995f89ec217e4b598352ce9c4b935df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5e375baa1c41a6914a68c9acf68c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.ner.ner_model:   Starting fine-tuning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c57dc8df9ea469bb5f1c5c995522f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 9:   0%|          | 0/619 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tajak/NER-recognition/ner/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633c386a1f91472aafd1c3b09f805678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 9:   0%|          | 0/619 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m model_list \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mxlmrb_bcms_12\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m model_list:\n\u001b[0;32m----> 5\u001b[0m \tcurrent_results_dict \u001b[39m=\u001b[39m train_and_test(model, train_df, test_df, dataset_path, LABELS)\n\u001b[1;32m      7\u001b[0m \t\u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mRun finished.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[19], line 70\u001b[0m, in \u001b[0;36mtrain_and_test\u001b[0;34m(model, train_df, test_df, dataset_path, LABELS)\u001b[0m\n\u001b[1;32m     67\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     69\u001b[0m \u001b[39m# Fine-tune the model\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m current_model\u001b[39m.\u001b[39;49mtrain_model(train_df)\n\u001b[1;32m     72\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTraining completed.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     74\u001b[0m training_time \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m((time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time)\u001b[39m/\u001b[39m\u001b[39m60\u001b[39m,\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/NER-recognition/ner/lib/python3.8/site-packages/simpletransformers/ner/ner_model.py:513\u001b[0m, in \u001b[0;36mNERModel.train_model\u001b[0;34m(self, train_data, output_dir, show_running_loss, args, eval_data, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m train_dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_and_cache_examples(train_data)\n\u001b[1;32m    511\u001b[0m os\u001b[39m.\u001b[39mmakedirs(output_dir, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 513\u001b[0m global_step, training_details \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m    514\u001b[0m     train_dataset,\n\u001b[1;32m    515\u001b[0m     output_dir,\n\u001b[1;32m    516\u001b[0m     show_running_loss\u001b[39m=\u001b[39;49mshow_running_loss,\n\u001b[1;32m    517\u001b[0m     eval_data\u001b[39m=\u001b[39;49meval_data,\n\u001b[1;32m    518\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    519\u001b[0m )\n\u001b[1;32m    521\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_model(model\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel)\n\u001b[1;32m    523\u001b[0m logger\u001b[39m.\u001b[39minfo(\n\u001b[1;32m    524\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m Training of \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m model complete. Saved to \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    525\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mmodel_type, output_dir\n\u001b[1;32m    526\u001b[0m     )\n\u001b[1;32m    527\u001b[0m )\n",
      "File \u001b[0;32m~/NER-recognition/ner/lib/python3.8/site-packages/simpletransformers/ner/ner_model.py:804\u001b[0m, in \u001b[0;36mNERModel.train\u001b[0;34m(self, train_dataset, output_dir, show_running_loss, eval_data, test_data, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    800\u001b[0m     loss \u001b[39m=\u001b[39m (\n\u001b[1;32m    801\u001b[0m         loss\u001b[39m.\u001b[39mmean()\n\u001b[1;32m    802\u001b[0m     )  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n\u001b[0;32m--> 804\u001b[0m current_loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m    806\u001b[0m \u001b[39mif\u001b[39;00m show_running_loss:\n\u001b[1;32m    807\u001b[0m     batch_iterator\u001b[39m.\u001b[39mset_description(\n\u001b[1;32m    808\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpochs \u001b[39m\u001b[39m{\u001b[39;00mepoch_number\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00margs\u001b[39m.\u001b[39mnum_train_epochs\u001b[39m}\u001b[39;00m\u001b[39m. Running Loss: \u001b[39m\u001b[39m{\u001b[39;00mcurrent_loss\u001b[39m:\u001b[39;00m\u001b[39m9.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    809\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Testing the models if they work as expected\n",
    "model_list = [\"xlmrb_bcms_12\"]\n",
    "\n",
    "for model in model_list:\n",
    "\tcurrent_results_dict = train_and_test(model, train_df, test_df, dataset_path, LABELS)\n",
    "\n",
    "\tprint(\"Run finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_list = dir(NERArgs)\n",
    "\n",
    "import torch\n",
    "\n",
    "optimizer_state = torch.load(\"model/checkpoint-48000/training_args.bin\")\n",
    "\n",
    "attributes = list(dir(optimizer_state))\n",
    "\n",
    "\n",
    "# Find the intersection of the sets\n",
    "common_elements = list(set(attributes).intersection(set(ner_list)))\n",
    "\n",
    "print(common_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimizer_state.resume_from_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_state.warmup_ratio = 0.06\n",
    "optimizer_state.learning_rate = 1e-5\n",
    "optimizer_state.fp16 = True\n",
    "optimizer_state.logging_steps = 50\n",
    "#optimizer_state.n_gpu = 1\n",
    "optimizer_state.gradient_accumulation_steps = 1\n",
    "optimizer_state.output_dir = \"outputs/\"\n",
    "optimizer_state.num_train_epochs = 1\n",
    "optimizer_state.resume_from_checkpoint = True\n",
    "optimizer_state.ignore_data_skip = True\n",
    "\n",
    "\n",
    "# Save arguments with new attributes\n",
    "torch.save(optimizer_state, \"model/checkpoint-48000/training_args.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new file for results\n",
    "#with open(\"ner-results-our-models.txt\", \"w\") as file:\n",
    "#    file.write(\"Date\\tModel\\tRun\\tDataset\\tMicro F1\\tMacro F1\\tLabel Report\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the models if they work as expected\n",
    "# models: [\"xlm-r-large\", \"sloberta\", \"csebert\", \"xlm-r-base\", \"bertic\"]\n",
    "model = \"xlmrl-bcms-48\"\n",
    "run = \"test\"\n",
    "\n",
    "current_results_dict = train_and_test(model, train_df, test_df, dataset_path)\n",
    "\n",
    "# Add to the dict model name, dataset name and run\n",
    "current_results_dict[\"model\"] = model\n",
    "current_results_dict[\"run\"] = \"{}-{}\".format(model, run)\n",
    "current_results_dict[\"dataset\"] = dataset_path\n",
    "\n",
    "# Add to the file with results all important information\n",
    "#with open(\"ner-results-testing.txt\", \"a\") as file:\n",
    "#    file.write(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n\".format(datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"), current_results_dict[\"model\"], current_results_dict[\"run\"], current_results_dict[\"dataset\"], current_results_dict[\"micro F1\"], current_results_dict[\"macro F1\"], current_results_dict[\"Micro F1 Nikola\"], current_results_dict[\"Macro F1 Nikola\"], current_results_dict[\"label-report\"]))\n",
    "\n",
    "# Add to the original test_df y_preds\n",
    "#test_df[\"y_pred_{}_{}\".format(model, run)] = current_results_dict[\"y_pred\"]\n",
    "\n",
    "# Save entire dict just in case\n",
    "#with open(\"{}-{}-{}-backlog.json\".format(dataset_path,model,run), \"w\") as backlog:\n",
    "#    json.dump(current_results_dict, backlog, indent=2)\n",
    "\n",
    "print(\"Run {} finished.\".format(run))\n",
    "\n",
    "# At the end, save the test_df with all predictions\n",
    "#test_df.to_csv(\"{}-test_df-with-predictions.csv\".format(dataset_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Model</th>\n",
       "      <th>Run</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Label Report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18/08/2023 16:39:46</td>\n",
       "      <td>xlm-r-large</td>\n",
       "      <td>xlm-r-large-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.918266</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.92105263157894...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18/08/2023 16:54:08</td>\n",
       "      <td>xlm-r-large</td>\n",
       "      <td>xlm-r-large-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990350</td>\n",
       "      <td>0.920143</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.92307692307692...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18/08/2023 17:40:13</td>\n",
       "      <td>xlm-r-base</td>\n",
       "      <td>xlm-r-base-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.988611</td>\n",
       "      <td>0.909217</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18/08/2023 17:50:32</td>\n",
       "      <td>xlm-r-base</td>\n",
       "      <td>xlm-r-base-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.988572</td>\n",
       "      <td>0.903684</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.91891891891891...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19/08/2023 08:51:35</td>\n",
       "      <td>xlm-r-base</td>\n",
       "      <td>xlm-r-base-0</td>\n",
       "      <td>datasets/set.sr.plus.conllup_extracted.json</td>\n",
       "      <td>0.988355</td>\n",
       "      <td>0.886370</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19/08/2023 08:53:43</td>\n",
       "      <td>xlm-r-base</td>\n",
       "      <td>xlm-r-base-1</td>\n",
       "      <td>datasets/set.sr.plus.conllup_extracted.json</td>\n",
       "      <td>0.988005</td>\n",
       "      <td>0.855162</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22/08/2023 09:38:41</td>\n",
       "      <td>xlmrb_bcms-12</td>\n",
       "      <td>xlmrb_bcms-12-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.989627</td>\n",
       "      <td>0.914450</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22/08/2023 09:49:10</td>\n",
       "      <td>xlmrb_bcms-12</td>\n",
       "      <td>xlmrb_bcms-12-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.989646</td>\n",
       "      <td>0.913838</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22/08/2023 10:00:03</td>\n",
       "      <td>xlmrb_bcms-24</td>\n",
       "      <td>xlmrb_bcms-24-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.989666</td>\n",
       "      <td>0.916545</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22/08/2023 10:10:20</td>\n",
       "      <td>xlmrb_bcms-24</td>\n",
       "      <td>xlmrb_bcms-24-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.989549</td>\n",
       "      <td>0.915471</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22/08/2023 10:21:08</td>\n",
       "      <td>xlmrb_bcms-36</td>\n",
       "      <td>xlmrb_bcms-36-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990018</td>\n",
       "      <td>0.919903</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>22/08/2023 10:31:23</td>\n",
       "      <td>xlmrb_bcms-36</td>\n",
       "      <td>xlmrb_bcms-36-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.989529</td>\n",
       "      <td>0.916001</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>22/08/2023 10:42:14</td>\n",
       "      <td>xlmrb_bcms-48</td>\n",
       "      <td>xlmrb_bcms-48-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.989646</td>\n",
       "      <td>0.916643</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>22/08/2023 10:52:33</td>\n",
       "      <td>xlmrb_bcms-48</td>\n",
       "      <td>xlmrb_bcms-48-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.989373</td>\n",
       "      <td>0.914822</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>22/08/2023 11:03:24</td>\n",
       "      <td>xlmrb_bcms-60</td>\n",
       "      <td>xlmrb_bcms-60-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.989861</td>\n",
       "      <td>0.917058</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>22/08/2023 11:13:42</td>\n",
       "      <td>xlmrb_bcms-60</td>\n",
       "      <td>xlmrb_bcms-60-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990154</td>\n",
       "      <td>0.919994</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>22/08/2023 11:24:33</td>\n",
       "      <td>xlmrb_bcms-72</td>\n",
       "      <td>xlmrb_bcms-72-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990135</td>\n",
       "      <td>0.915926</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.97058823529411...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>22/08/2023 11:34:52</td>\n",
       "      <td>xlmrb_bcms-72</td>\n",
       "      <td>xlmrb_bcms-72-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990408</td>\n",
       "      <td>0.918613</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.97142857142857...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>22/08/2023 11:45:49</td>\n",
       "      <td>xlmrb_bcms-84</td>\n",
       "      <td>xlmrb_bcms-84-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.918406</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>22/08/2023 11:56:12</td>\n",
       "      <td>xlmrb_bcms-84</td>\n",
       "      <td>xlmrb_bcms-84-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.989900</td>\n",
       "      <td>0.915626</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22/08/2023 12:07:06</td>\n",
       "      <td>xlmrb_bcms-96</td>\n",
       "      <td>xlmrb_bcms-96-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990252</td>\n",
       "      <td>0.919868</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.97297297297297...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22/08/2023 12:17:27</td>\n",
       "      <td>xlmrb_bcms-96</td>\n",
       "      <td>xlmrb_bcms-96-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990096</td>\n",
       "      <td>0.920258</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22/08/2023 14:00:54</td>\n",
       "      <td>xlmrl_bcms-6</td>\n",
       "      <td>xlmrl_bcms-6-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.989783</td>\n",
       "      <td>0.918359</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.97222222222222...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22/08/2023 14:15:39</td>\n",
       "      <td>xlmrl_bcms-6</td>\n",
       "      <td>xlmrl_bcms-6-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990604</td>\n",
       "      <td>0.923328</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>22/08/2023 14:31:09</td>\n",
       "      <td>xlmrl_bcms-12</td>\n",
       "      <td>xlmrl_bcms-12-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990936</td>\n",
       "      <td>0.927423</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.97297297297297...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>22/08/2023 14:46:01</td>\n",
       "      <td>xlmrl_bcms-12</td>\n",
       "      <td>xlmrl_bcms-12-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990955</td>\n",
       "      <td>0.923719</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.94736842105263...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>22/08/2023 15:01:28</td>\n",
       "      <td>xlmrl_bcms-18</td>\n",
       "      <td>xlmrl_bcms-18-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990076</td>\n",
       "      <td>0.921555</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.97297297297297...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>22/08/2023 15:16:07</td>\n",
       "      <td>xlmrl_bcms-18</td>\n",
       "      <td>xlmrl_bcms-18-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990369</td>\n",
       "      <td>0.925960</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>22/08/2023 15:31:25</td>\n",
       "      <td>xlmrl_bcms-24</td>\n",
       "      <td>xlmrl_bcms-24-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990369</td>\n",
       "      <td>0.924769</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>22/08/2023 15:46:10</td>\n",
       "      <td>xlmrl_bcms-24</td>\n",
       "      <td>xlmrl_bcms-24-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990428</td>\n",
       "      <td>0.925571</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>22/08/2023 16:01:31</td>\n",
       "      <td>xlmrl_bcms-30</td>\n",
       "      <td>xlmrl_bcms-30-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990545</td>\n",
       "      <td>0.926278</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>22/08/2023 16:16:16</td>\n",
       "      <td>xlmrl_bcms-30</td>\n",
       "      <td>xlmrl_bcms-30-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990525</td>\n",
       "      <td>0.924645</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>22/08/2023 16:31:41</td>\n",
       "      <td>xlmrl_bcms-36</td>\n",
       "      <td>xlmrl_bcms-36-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990604</td>\n",
       "      <td>0.925598</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>22/08/2023 16:46:26</td>\n",
       "      <td>xlmrl_bcms-36</td>\n",
       "      <td>xlmrl_bcms-36-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.991268</td>\n",
       "      <td>0.931216</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>22/08/2023 17:01:59</td>\n",
       "      <td>xlmrl_bcms-42</td>\n",
       "      <td>xlmrl_bcms-42-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.991483</td>\n",
       "      <td>0.933128</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>22/08/2023 17:16:48</td>\n",
       "      <td>xlmrl_bcms-42</td>\n",
       "      <td>xlmrl_bcms-42-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990779</td>\n",
       "      <td>0.929324</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>22/08/2023 17:32:21</td>\n",
       "      <td>xlmrl_bcms-48</td>\n",
       "      <td>xlmrl_bcms-48-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.991014</td>\n",
       "      <td>0.930483</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>22/08/2023 17:47:14</td>\n",
       "      <td>xlmrl_bcms-48</td>\n",
       "      <td>xlmrl_bcms-48-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990643</td>\n",
       "      <td>0.927061</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>22/08/2023 18:02:46</td>\n",
       "      <td>xlmrl_sl-bcms-6</td>\n",
       "      <td>xlmrl_sl-bcms-6-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990623</td>\n",
       "      <td>0.923533</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.97297297297297...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>22/08/2023 18:17:37</td>\n",
       "      <td>xlmrl_sl-bcms-6</td>\n",
       "      <td>xlmrl_sl-bcms-6-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.991033</td>\n",
       "      <td>0.925028</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.97222222222222...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>22/08/2023 18:33:15</td>\n",
       "      <td>xlmrl_sl-bcms-12</td>\n",
       "      <td>xlmrl_sl-bcms-12-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990779</td>\n",
       "      <td>0.924877</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.97297297297297...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>22/08/2023 18:48:10</td>\n",
       "      <td>xlmrl_sl-bcms-12</td>\n",
       "      <td>xlmrl_sl-bcms-12-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990838</td>\n",
       "      <td>0.925026</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.97222222222222...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>22/08/2023 19:03:51</td>\n",
       "      <td>xlmrl_sl-bcms-18</td>\n",
       "      <td>xlmrl_sl-bcms-18-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990525</td>\n",
       "      <td>0.923415</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>22/08/2023 19:18:51</td>\n",
       "      <td>xlmrl_sl-bcms-18</td>\n",
       "      <td>xlmrl_sl-bcms-18-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.991170</td>\n",
       "      <td>0.926078</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.97142857142857...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>22/08/2023 19:34:25</td>\n",
       "      <td>xlmrl_sl-bcms-24</td>\n",
       "      <td>xlmrl_sl-bcms-24-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.991229</td>\n",
       "      <td>0.926528</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>22/08/2023 19:49:15</td>\n",
       "      <td>xlmrl_sl-bcms-24</td>\n",
       "      <td>xlmrl_sl-bcms-24-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990858</td>\n",
       "      <td>0.926993</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>22/08/2023 20:04:50</td>\n",
       "      <td>xlmrl_sl-bcms-30</td>\n",
       "      <td>xlmrl_sl-bcms-30-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.991151</td>\n",
       "      <td>0.928688</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>22/08/2023 20:19:49</td>\n",
       "      <td>xlmrl_sl-bcms-30</td>\n",
       "      <td>xlmrl_sl-bcms-30-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990604</td>\n",
       "      <td>0.927286</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>22/08/2023 20:35:35</td>\n",
       "      <td>xlmrl_sl-bcms-42</td>\n",
       "      <td>xlmrl_sl-bcms-42-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990760</td>\n",
       "      <td>0.927222</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>22/08/2023 20:50:27</td>\n",
       "      <td>xlmrl_sl-bcms-42</td>\n",
       "      <td>xlmrl_sl-bcms-42-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990565</td>\n",
       "      <td>0.924664</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>22/08/2023 21:06:04</td>\n",
       "      <td>xlmrl_sl-bcms-48</td>\n",
       "      <td>xlmrl_sl-bcms-48-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990311</td>\n",
       "      <td>0.923591</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>22/08/2023 21:20:54</td>\n",
       "      <td>xlmrl_sl-bcms-48</td>\n",
       "      <td>xlmrl_sl-bcms-48-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.991092</td>\n",
       "      <td>0.930768</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Date             Model                 Run  \\\n",
       "0   18/08/2023 16:39:46       xlm-r-large       xlm-r-large-0   \n",
       "1   18/08/2023 16:54:08       xlm-r-large       xlm-r-large-1   \n",
       "2   18/08/2023 17:40:13        xlm-r-base        xlm-r-base-0   \n",
       "3   18/08/2023 17:50:32        xlm-r-base        xlm-r-base-1   \n",
       "4   19/08/2023 08:51:35        xlm-r-base        xlm-r-base-0   \n",
       "5   19/08/2023 08:53:43        xlm-r-base        xlm-r-base-1   \n",
       "6   22/08/2023 09:38:41     xlmrb_bcms-12     xlmrb_bcms-12-0   \n",
       "7   22/08/2023 09:49:10     xlmrb_bcms-12     xlmrb_bcms-12-1   \n",
       "8   22/08/2023 10:00:03     xlmrb_bcms-24     xlmrb_bcms-24-0   \n",
       "9   22/08/2023 10:10:20     xlmrb_bcms-24     xlmrb_bcms-24-1   \n",
       "10  22/08/2023 10:21:08     xlmrb_bcms-36     xlmrb_bcms-36-0   \n",
       "11  22/08/2023 10:31:23     xlmrb_bcms-36     xlmrb_bcms-36-1   \n",
       "12  22/08/2023 10:42:14     xlmrb_bcms-48     xlmrb_bcms-48-0   \n",
       "13  22/08/2023 10:52:33     xlmrb_bcms-48     xlmrb_bcms-48-1   \n",
       "14  22/08/2023 11:03:24     xlmrb_bcms-60     xlmrb_bcms-60-0   \n",
       "15  22/08/2023 11:13:42     xlmrb_bcms-60     xlmrb_bcms-60-1   \n",
       "16  22/08/2023 11:24:33     xlmrb_bcms-72     xlmrb_bcms-72-0   \n",
       "17  22/08/2023 11:34:52     xlmrb_bcms-72     xlmrb_bcms-72-1   \n",
       "18  22/08/2023 11:45:49     xlmrb_bcms-84     xlmrb_bcms-84-0   \n",
       "19  22/08/2023 11:56:12     xlmrb_bcms-84     xlmrb_bcms-84-1   \n",
       "20  22/08/2023 12:07:06     xlmrb_bcms-96     xlmrb_bcms-96-0   \n",
       "21  22/08/2023 12:17:27     xlmrb_bcms-96     xlmrb_bcms-96-1   \n",
       "22  22/08/2023 14:00:54      xlmrl_bcms-6      xlmrl_bcms-6-0   \n",
       "23  22/08/2023 14:15:39      xlmrl_bcms-6      xlmrl_bcms-6-1   \n",
       "24  22/08/2023 14:31:09     xlmrl_bcms-12     xlmrl_bcms-12-0   \n",
       "25  22/08/2023 14:46:01     xlmrl_bcms-12     xlmrl_bcms-12-1   \n",
       "26  22/08/2023 15:01:28     xlmrl_bcms-18     xlmrl_bcms-18-0   \n",
       "27  22/08/2023 15:16:07     xlmrl_bcms-18     xlmrl_bcms-18-1   \n",
       "28  22/08/2023 15:31:25     xlmrl_bcms-24     xlmrl_bcms-24-0   \n",
       "29  22/08/2023 15:46:10     xlmrl_bcms-24     xlmrl_bcms-24-1   \n",
       "30  22/08/2023 16:01:31     xlmrl_bcms-30     xlmrl_bcms-30-0   \n",
       "31  22/08/2023 16:16:16     xlmrl_bcms-30     xlmrl_bcms-30-1   \n",
       "32  22/08/2023 16:31:41     xlmrl_bcms-36     xlmrl_bcms-36-0   \n",
       "33  22/08/2023 16:46:26     xlmrl_bcms-36     xlmrl_bcms-36-1   \n",
       "34  22/08/2023 17:01:59     xlmrl_bcms-42     xlmrl_bcms-42-0   \n",
       "35  22/08/2023 17:16:48     xlmrl_bcms-42     xlmrl_bcms-42-1   \n",
       "36  22/08/2023 17:32:21     xlmrl_bcms-48     xlmrl_bcms-48-0   \n",
       "37  22/08/2023 17:47:14     xlmrl_bcms-48     xlmrl_bcms-48-1   \n",
       "38  22/08/2023 18:02:46   xlmrl_sl-bcms-6   xlmrl_sl-bcms-6-0   \n",
       "39  22/08/2023 18:17:37   xlmrl_sl-bcms-6   xlmrl_sl-bcms-6-1   \n",
       "40  22/08/2023 18:33:15  xlmrl_sl-bcms-12  xlmrl_sl-bcms-12-0   \n",
       "41  22/08/2023 18:48:10  xlmrl_sl-bcms-12  xlmrl_sl-bcms-12-1   \n",
       "42  22/08/2023 19:03:51  xlmrl_sl-bcms-18  xlmrl_sl-bcms-18-0   \n",
       "43  22/08/2023 19:18:51  xlmrl_sl-bcms-18  xlmrl_sl-bcms-18-1   \n",
       "44  22/08/2023 19:34:25  xlmrl_sl-bcms-24  xlmrl_sl-bcms-24-0   \n",
       "45  22/08/2023 19:49:15  xlmrl_sl-bcms-24  xlmrl_sl-bcms-24-1   \n",
       "46  22/08/2023 20:04:50  xlmrl_sl-bcms-30  xlmrl_sl-bcms-30-0   \n",
       "47  22/08/2023 20:19:49  xlmrl_sl-bcms-30  xlmrl_sl-bcms-30-1   \n",
       "48  22/08/2023 20:35:35  xlmrl_sl-bcms-42  xlmrl_sl-bcms-42-0   \n",
       "49  22/08/2023 20:50:27  xlmrl_sl-bcms-42  xlmrl_sl-bcms-42-1   \n",
       "50  22/08/2023 21:06:04  xlmrl_sl-bcms-48  xlmrl_sl-bcms-48-0   \n",
       "51  22/08/2023 21:20:54  xlmrl_sl-bcms-48  xlmrl_sl-bcms-48-1   \n",
       "\n",
       "                                        Dataset  Micro F1  Macro F1  \\\n",
       "0        datasets/hr500k.conllup_extracted.json  0.990291  0.918266   \n",
       "1        datasets/hr500k.conllup_extracted.json  0.990350  0.920143   \n",
       "2        datasets/hr500k.conllup_extracted.json  0.988611  0.909217   \n",
       "3        datasets/hr500k.conllup_extracted.json  0.988572  0.903684   \n",
       "4   datasets/set.sr.plus.conllup_extracted.json  0.988355  0.886370   \n",
       "5   datasets/set.sr.plus.conllup_extracted.json  0.988005  0.855162   \n",
       "6        datasets/hr500k.conllup_extracted.json  0.989627  0.914450   \n",
       "7        datasets/hr500k.conllup_extracted.json  0.989646  0.913838   \n",
       "8        datasets/hr500k.conllup_extracted.json  0.989666  0.916545   \n",
       "9        datasets/hr500k.conllup_extracted.json  0.989549  0.915471   \n",
       "10       datasets/hr500k.conllup_extracted.json  0.990018  0.919903   \n",
       "11       datasets/hr500k.conllup_extracted.json  0.989529  0.916001   \n",
       "12       datasets/hr500k.conllup_extracted.json  0.989646  0.916643   \n",
       "13       datasets/hr500k.conllup_extracted.json  0.989373  0.914822   \n",
       "14       datasets/hr500k.conllup_extracted.json  0.989861  0.917058   \n",
       "15       datasets/hr500k.conllup_extracted.json  0.990154  0.919994   \n",
       "16       datasets/hr500k.conllup_extracted.json  0.990135  0.915926   \n",
       "17       datasets/hr500k.conllup_extracted.json  0.990408  0.918613   \n",
       "18       datasets/hr500k.conllup_extracted.json  0.990291  0.918406   \n",
       "19       datasets/hr500k.conllup_extracted.json  0.989900  0.915626   \n",
       "20       datasets/hr500k.conllup_extracted.json  0.990252  0.919868   \n",
       "21       datasets/hr500k.conllup_extracted.json  0.990096  0.920258   \n",
       "22       datasets/hr500k.conllup_extracted.json  0.989783  0.918359   \n",
       "23       datasets/hr500k.conllup_extracted.json  0.990604  0.923328   \n",
       "24       datasets/hr500k.conllup_extracted.json  0.990936  0.927423   \n",
       "25       datasets/hr500k.conllup_extracted.json  0.990955  0.923719   \n",
       "26       datasets/hr500k.conllup_extracted.json  0.990076  0.921555   \n",
       "27       datasets/hr500k.conllup_extracted.json  0.990369  0.925960   \n",
       "28       datasets/hr500k.conllup_extracted.json  0.990369  0.924769   \n",
       "29       datasets/hr500k.conllup_extracted.json  0.990428  0.925571   \n",
       "30       datasets/hr500k.conllup_extracted.json  0.990545  0.926278   \n",
       "31       datasets/hr500k.conllup_extracted.json  0.990525  0.924645   \n",
       "32       datasets/hr500k.conllup_extracted.json  0.990604  0.925598   \n",
       "33       datasets/hr500k.conllup_extracted.json  0.991268  0.931216   \n",
       "34       datasets/hr500k.conllup_extracted.json  0.991483  0.933128   \n",
       "35       datasets/hr500k.conllup_extracted.json  0.990779  0.929324   \n",
       "36       datasets/hr500k.conllup_extracted.json  0.991014  0.930483   \n",
       "37       datasets/hr500k.conllup_extracted.json  0.990643  0.927061   \n",
       "38       datasets/hr500k.conllup_extracted.json  0.990623  0.923533   \n",
       "39       datasets/hr500k.conllup_extracted.json  0.991033  0.925028   \n",
       "40       datasets/hr500k.conllup_extracted.json  0.990779  0.924877   \n",
       "41       datasets/hr500k.conllup_extracted.json  0.990838  0.925026   \n",
       "42       datasets/hr500k.conllup_extracted.json  0.990525  0.923415   \n",
       "43       datasets/hr500k.conllup_extracted.json  0.991170  0.926078   \n",
       "44       datasets/hr500k.conllup_extracted.json  0.991229  0.926528   \n",
       "45       datasets/hr500k.conllup_extracted.json  0.990858  0.926993   \n",
       "46       datasets/hr500k.conllup_extracted.json  0.991151  0.928688   \n",
       "47       datasets/hr500k.conllup_extracted.json  0.990604  0.927286   \n",
       "48       datasets/hr500k.conllup_extracted.json  0.990760  0.927222   \n",
       "49       datasets/hr500k.conllup_extracted.json  0.990565  0.924664   \n",
       "50       datasets/hr500k.conllup_extracted.json  0.990311  0.923591   \n",
       "51       datasets/hr500k.conllup_extracted.json  0.991092  0.930768   \n",
       "\n",
       "                                         Label Report  \n",
       "0   {'B-deriv-per': {'precision': 0.92105263157894...  \n",
       "1   {'B-deriv-per': {'precision': 0.92307692307692...  \n",
       "2   {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "3   {'B-deriv-per': {'precision': 0.91891891891891...  \n",
       "4   {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "5   {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "6   {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "7   {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "8   {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "9   {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "10  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "11  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "12  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "13  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "14  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "15  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "16  {'B-deriv-per': {'precision': 0.97058823529411...  \n",
       "17  {'B-deriv-per': {'precision': 0.97142857142857...  \n",
       "18  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "19  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "20  {'B-deriv-per': {'precision': 0.97297297297297...  \n",
       "21  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "22  {'B-deriv-per': {'precision': 0.97222222222222...  \n",
       "23  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "24  {'B-deriv-per': {'precision': 0.97297297297297...  \n",
       "25  {'B-deriv-per': {'precision': 0.94736842105263...  \n",
       "26  {'B-deriv-per': {'precision': 0.97297297297297...  \n",
       "27  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "28  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "29  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "30  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "31  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "32  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "33  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "34  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "35  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "36  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "37  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "38  {'B-deriv-per': {'precision': 0.97297297297297...  \n",
       "39  {'B-deriv-per': {'precision': 0.97222222222222...  \n",
       "40  {'B-deriv-per': {'precision': 0.97297297297297...  \n",
       "41  {'B-deriv-per': {'precision': 0.97222222222222...  \n",
       "42  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "43  {'B-deriv-per': {'precision': 0.97142857142857...  \n",
       "44  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "45  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "46  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "47  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "48  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "49  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "50  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "51  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the txt with results\n",
    "import pandas as pd\n",
    "\n",
    "results = pd.read_csv(\"ner-results.txt\", sep=\"\\t\")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Model'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get average micro and macro F1\n",
    "dataset = \"datasets/hr500k.conllup_extracted.json\"\n",
    "\n",
    "# Define the dataset to inspect\n",
    "import matplotlib as plt\n",
    "results[results[\"Dataset\"] == dataset].groupby(\"Model\")[\"Micro F1\"].mean().plot(kind=\"line\", color=\"blue\")\n",
    "results[results[\"Dataset\"] == dataset].groupby(\"Model\")[\"Macro F1\"].mean().plot(kind=\"line\",color=\"orange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataset</th>\n",
       "      <th>Run</th>\n",
       "      <th>datasets/hr500k.conllup_extracted.json</th>\n",
       "      <th>datasets/set.sr.plus.conllup_extracted.json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xlm-r-base-0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xlm-r-base-1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xlm-r-large-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xlm-r-large-1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xlmrb_bcms-12-0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xlmrb_bcms-12-1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xlmrb_bcms-24-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xlmrb_bcms-24-1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xlmrb_bcms-36-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xlmrb_bcms-36-1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>xlmrb_bcms-48-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>xlmrb_bcms-48-1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xlmrb_bcms-60-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>xlmrb_bcms-60-1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>xlmrb_bcms-72-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>xlmrb_bcms-72-1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>xlmrb_bcms-84-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>xlmrb_bcms-84-1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>xlmrb_bcms-96-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>xlmrb_bcms-96-1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>xlmrl_bcms-12-0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>xlmrl_bcms-12-1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>xlmrl_bcms-18-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>xlmrl_bcms-18-1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>xlmrl_bcms-24-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>xlmrl_bcms-24-1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>xlmrl_bcms-30-0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>xlmrl_bcms-30-1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>xlmrl_bcms-36-0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>xlmrl_bcms-36-1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>xlmrl_bcms-42-0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>xlmrl_bcms-42-1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>xlmrl_bcms-48-0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>xlmrl_bcms-48-1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>xlmrl_bcms-6-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>xlmrl_bcms-6-1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>xlmrl_sl-bcms-12-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>xlmrl_sl-bcms-12-1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>xlmrl_sl-bcms-18-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>xlmrl_sl-bcms-18-1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>xlmrl_sl-bcms-24-0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>xlmrl_sl-bcms-24-1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>xlmrl_sl-bcms-30-0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>xlmrl_sl-bcms-30-1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>xlmrl_sl-bcms-42-0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>xlmrl_sl-bcms-42-1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>xlmrl_sl-bcms-48-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>xlmrl_sl-bcms-48-1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>xlmrl_sl-bcms-6-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>xlmrl_sl-bcms-6-1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset                 Run  datasets/hr500k.conllup_extracted.json  \\\n",
       "0              xlm-r-base-0                                    0.91   \n",
       "1              xlm-r-base-1                                    0.90   \n",
       "2             xlm-r-large-0                                    0.92   \n",
       "3             xlm-r-large-1                                    0.92   \n",
       "4           xlmrb_bcms-12-0                                    0.91   \n",
       "5           xlmrb_bcms-12-1                                    0.91   \n",
       "6           xlmrb_bcms-24-0                                    0.92   \n",
       "7           xlmrb_bcms-24-1                                    0.92   \n",
       "8           xlmrb_bcms-36-0                                    0.92   \n",
       "9           xlmrb_bcms-36-1                                    0.92   \n",
       "10          xlmrb_bcms-48-0                                    0.92   \n",
       "11          xlmrb_bcms-48-1                                    0.91   \n",
       "12          xlmrb_bcms-60-0                                    0.92   \n",
       "13          xlmrb_bcms-60-1                                    0.92   \n",
       "14          xlmrb_bcms-72-0                                    0.92   \n",
       "15          xlmrb_bcms-72-1                                    0.92   \n",
       "16          xlmrb_bcms-84-0                                    0.92   \n",
       "17          xlmrb_bcms-84-1                                    0.92   \n",
       "18          xlmrb_bcms-96-0                                    0.92   \n",
       "19          xlmrb_bcms-96-1                                    0.92   \n",
       "20          xlmrl_bcms-12-0                                    0.93   \n",
       "21          xlmrl_bcms-12-1                                    0.92   \n",
       "22          xlmrl_bcms-18-0                                    0.92   \n",
       "23          xlmrl_bcms-18-1                                    0.93   \n",
       "24          xlmrl_bcms-24-0                                    0.92   \n",
       "25          xlmrl_bcms-24-1                                    0.93   \n",
       "26          xlmrl_bcms-30-0                                    0.93   \n",
       "27          xlmrl_bcms-30-1                                    0.92   \n",
       "28          xlmrl_bcms-36-0                                    0.93   \n",
       "29          xlmrl_bcms-36-1                                    0.93   \n",
       "30          xlmrl_bcms-42-0                                    0.93   \n",
       "31          xlmrl_bcms-42-1                                    0.93   \n",
       "32          xlmrl_bcms-48-0                                    0.93   \n",
       "33          xlmrl_bcms-48-1                                    0.93   \n",
       "34           xlmrl_bcms-6-0                                    0.92   \n",
       "35           xlmrl_bcms-6-1                                    0.92   \n",
       "36       xlmrl_sl-bcms-12-0                                    0.92   \n",
       "37       xlmrl_sl-bcms-12-1                                    0.93   \n",
       "38       xlmrl_sl-bcms-18-0                                    0.92   \n",
       "39       xlmrl_sl-bcms-18-1                                    0.93   \n",
       "40       xlmrl_sl-bcms-24-0                                    0.93   \n",
       "41       xlmrl_sl-bcms-24-1                                    0.93   \n",
       "42       xlmrl_sl-bcms-30-0                                    0.93   \n",
       "43       xlmrl_sl-bcms-30-1                                    0.93   \n",
       "44       xlmrl_sl-bcms-42-0                                    0.93   \n",
       "45       xlmrl_sl-bcms-42-1                                    0.92   \n",
       "46       xlmrl_sl-bcms-48-0                                    0.92   \n",
       "47       xlmrl_sl-bcms-48-1                                    0.93   \n",
       "48        xlmrl_sl-bcms-6-0                                    0.92   \n",
       "49        xlmrl_sl-bcms-6-1                                    0.93   \n",
       "\n",
       "Dataset  datasets/set.sr.plus.conllup_extracted.json  \n",
       "0                                               0.89  \n",
       "1                                               0.86  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4                                                NaN  \n",
       "5                                                NaN  \n",
       "6                                                NaN  \n",
       "7                                                NaN  \n",
       "8                                                NaN  \n",
       "9                                                NaN  \n",
       "10                                               NaN  \n",
       "11                                               NaN  \n",
       "12                                               NaN  \n",
       "13                                               NaN  \n",
       "14                                               NaN  \n",
       "15                                               NaN  \n",
       "16                                               NaN  \n",
       "17                                               NaN  \n",
       "18                                               NaN  \n",
       "19                                               NaN  \n",
       "20                                               NaN  \n",
       "21                                               NaN  \n",
       "22                                               NaN  \n",
       "23                                               NaN  \n",
       "24                                               NaN  \n",
       "25                                               NaN  \n",
       "26                                               NaN  \n",
       "27                                               NaN  \n",
       "28                                               NaN  \n",
       "29                                               NaN  \n",
       "30                                               NaN  \n",
       "31                                               NaN  \n",
       "32                                               NaN  \n",
       "33                                               NaN  \n",
       "34                                               NaN  \n",
       "35                                               NaN  \n",
       "36                                               NaN  \n",
       "37                                               NaN  \n",
       "38                                               NaN  \n",
       "39                                               NaN  \n",
       "40                                               NaN  \n",
       "41                                               NaN  \n",
       "42                                               NaN  \n",
       "43                                               NaN  \n",
       "44                                               NaN  \n",
       "45                                               NaN  \n",
       "46                                               NaN  \n",
       "47                                               NaN  \n",
       "48                                               NaN  \n",
       "49                                               NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results[\"Dataset\"] == dataset].groupby(\"Model\")[\"Macro F1\"].mean().round(2)\n",
    "\n",
    "results[\"Macro F1\"] = results[\"Macro F1\"].round(2)\n",
    "\n",
    "# Pivot the DataFrame to rearrange columns into rows\n",
    "pivot_df = results.pivot(index='Run', columns='Dataset', values='Macro F1')\n",
    "\n",
    "# Reset the index to have 'Model' as a column\n",
    "pivot_df.reset_index(inplace=True)\n",
    "\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the DataFrame to rearrange columns into rows\n",
    "pivot_df.to_csv(\"ner-results-summary-table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's analyze the df with all the predictions\n",
    "import numpy as np\n",
    "\n",
    "pred_df = pd.read_csv(\"datasets/hr500k.conllup_extracted.json-test_df-with-predictions.csv\", index_col = 0)\n",
    "\n",
    "# Analyze instances where models are wrong\n",
    "pred_df[\"match\"] = np.where(pred_df[\"labels\"] != pred_df[\"y_pred_xlm-r-large_0\"], \"no\", \"yes\")\n",
    "pred_df.match.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df[pred_df[\"match\"] == \"no\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
