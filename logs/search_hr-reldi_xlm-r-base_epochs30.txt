wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForTokenClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']
- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/tajak/NER-recognition/ner/lib/python3.8/site-packages/simpletransformers/ner/ner_model.py:483: UserWarning: The eval_df parameter has been renamed to eval_data. Using eval_df will raise an error in a future version.
  warnings.warn(
INFO:simpletransformers.ner.ner_model: Converting to features started.
['B-per', 'O', 'B-org', 'B-loc', 'I-org', 'B-misc', 'I-misc', 'I-loc', 'B-deriv-per', 'I-per', 'I-deriv-per']
(71967, 3) (8952, 3) (8936, 3)
   sentence_id    words labels
0            0   Vakula  B-per
1            0    dragi      O
2            0  Drakula  B-per
3            0        ,      O
4            0     ki≈°a      O
wandb: Tracking run with wandb version 0.15.8
wandb: Run data is saved locally in /home/tajak/NER-recognition/wandb/run-20230823_110934-dgzrg8gv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-spaceship-102
wandb: ‚≠êÔ∏è View project at https://wandb.ai/tajak/NER
wandb: üöÄ View run at https://wandb.ai/tajak/NER/runs/dgzrg8gv
/home/tajak/NER-recognition/ner/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.21199268974363805, 'precision': 1.0, 'recall': 0.43169398907103823, 'f1_score': 0.6030534351145038}
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.15470947155728937, 'precision': 0.7311827956989247, 'recall': 0.6193078324225865, 'f1_score': 0.6706114398422091}
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.10892899515572935, 'precision': 0.7620751341681574, 'recall': 0.7759562841530054, 'f1_score': 0.7689530685920578}
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.10010211606626399, 'precision': 0.8113553113553114, 'recall': 0.8069216757741348, 'f1_score': 0.8091324200913242}
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.09759697798697743, 'precision': 0.7996515679442509, 'recall': 0.8360655737704918, 'f1_score': 0.8174532502226179}
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.10150358308921568, 'precision': 0.822141560798548, 'recall': 0.825136612021858, 'f1_score': 0.8236363636363637}
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.09767626029002713, 'precision': 0.8427787934186471, 'recall': 0.8397085610200364, 'f1_score': 0.8412408759124087}
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.11264545817233738, 'precision': 0.7918088737201365, 'recall': 0.8451730418943534, 'f1_score': 0.8176211453744493}
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.12055773110638256, 'precision': 0.8579654510556622, 'recall': 0.8142076502732241, 'f1_score': 0.8355140186915888}
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.11701682080165483, 'precision': 0.8235294117647058, 'recall': 0.8415300546448088, 'f1_score': 0.8324324324324324}
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.12113904570469458, 'precision': 0.8537037037037037, 'recall': 0.8397085610200364, 'f1_score': 0.8466483011937558}
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.12507842022678234, 'precision': 0.8288770053475936, 'recall': 0.8469945355191257, 'f1_score': 0.8378378378378378}
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.13221343547222206, 'precision': 0.8627819548872181, 'recall': 0.8360655737704918, 'f1_score': 0.8492136910268271}
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.1343526750158344, 'precision': 0.8243727598566308, 'recall': 0.8378870673952641, 'f1_score': 0.8310749774164408}
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.1337616693787277, 'precision': 0.8519195612431444, 'recall': 0.848816029143898, 'f1_score': 0.8503649635036497}
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.13705021632587885, 'precision': 0.8392857142857143, 'recall': 0.8561020036429873, 'f1_score': 0.8476104598737602}
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.14258723206487048, 'precision': 0.8390596745027125, 'recall': 0.8451730418943534, 'f1_score': 0.8421052631578947}
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.14474672250202275, 'precision': 0.8531598513011153, 'recall': 0.8360655737704918, 'f1_score': 0.8445262189512419}
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.1390643211779752, 'precision': 0.8153310104529616, 'recall': 0.8524590163934426, 'f1_score': 0.8334817453250222}
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.14824251725018256, 'precision': 0.8495412844036697, 'recall': 0.843351548269581, 'f1_score': 0.8464351005484461}
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.14773573253292852, 'precision': 0.8213660245183888, 'recall': 0.8542805100182149, 'f1_score': 0.8374999999999999}
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.14999130324897123, 'precision': 0.8321554770318021, 'recall': 0.8579234972677595, 'f1_score': 0.8448430493273543}
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.14929938859961112, 'precision': 0.8228070175438597, 'recall': 0.8542805100182149, 'f1_score': 0.8382484361036638}
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.15684621886714012, 'precision': 0.8303886925795053, 'recall': 0.8561020036429873, 'f1_score': 0.8430493273542602}
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.15803810280762265, 'precision': 0.8333333333333334, 'recall': 0.8561020036429873, 'f1_score': 0.844564240790656}
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.15736930396022217, 'precision': 0.8369175627240143, 'recall': 0.8506375227686703, 'f1_score': 0.8437217705510388}
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.16171611952660897, 'precision': 0.8469945355191257, 'recall': 0.8469945355191257, 'f1_score': 0.8469945355191257}
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.16135335313283578, 'precision': 0.8342245989304813, 'recall': 0.8524590163934426, 'f1_score': 0.8432432432432432}
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.16300187415079562, 'precision': 0.840867992766727, 'recall': 0.8469945355191257, 'f1_score': 0.8439201451905627}
INFO:simpletransformers.ner.ner_model: Converting to features started.
INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.16294368950519128, 'precision': 0.8381294964028777, 'recall': 0.848816029143898, 'f1_score': 0.8434389140271493}
INFO:simpletransformers.ner.ner_model: Training of xlmroberta model complete. Saved to outputs/.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: Training loss ‚ñà‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:     eval_loss ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      f1_score ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:   global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:            lr ‚ñÇ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:     precision ‚ñà‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:        recall ‚ñÅ‚ñÑ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:    train_loss ‚ñÅ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb: Training loss 0.00406
wandb:     eval_loss 0.16294
wandb:      f1_score 0.84344
wandb:   global_step 6000
wandb:            lr 0.0
wandb:     precision 0.83813
wandb:        recall 0.84882
wandb:    train_loss 0.00406
wandb: 
wandb: üöÄ View run solar-spaceship-102 at: https://wandb.ai/tajak/NER/runs/dgzrg8gv
wandb: Ô∏è‚ö° View job at https://wandb.ai/tajak/NER/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjkwODMzNTg1/version_details/v5
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230823_110934-dgzrg8gv/logs
