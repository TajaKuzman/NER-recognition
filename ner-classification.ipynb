{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each dataset (2 HR, 2 SR, 4 SLO):\n",
    "\n",
    "    - For each model (XLM-R-base, XLM-R-large, CSEBert, SloBERTa, BERTić, multiple versions of XLM-R-BERTić and XLM-R-SloBERTić):\n",
    "\n",
    "\n",
    "        - fine-tune the model and evaluate it - 5 times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Dataset Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "# Define the gpu on the gpu machine\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=3\n",
    "\n",
    "import evaluate\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from simpletransformers.ner import NERModel, NERArgs\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tqdm.autonotebook import tqdm as notebook_tqdm\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import logging\n",
    "import sklearn\n",
    "from numba import cuda\n",
    "import argparse\n",
    "import gc\n",
    "import torch\n",
    "import time\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B-loc', 'B-org', 'B-per', 'I-per', 'B-deriv-per', 'I-org', 'I-loc', 'B-misc', 'I-misc', 'I-deriv-per']\n",
      "(398681, 3) (51190, 3) (49764, 3)\n",
      "     sentence_id      words labels\n",
      "717            0      Kazna      O\n",
      "718            0  medijskom      O\n",
      "719            0     mogulu      O\n",
      "720            0   obnovila      O\n",
      "721            0   raspravu      O\n"
     ]
    }
   ],
   "source": [
    "# Import the dataset\n",
    "\n",
    "# Code for python script\n",
    "\"\"\"\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"dataset\", help=\"path to the dataset in JSON format\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "# Define the path to the dataset\n",
    "dataset_path = args.dataset\n",
    "\"\"\"\n",
    "# Define the path to the dataset\n",
    "dataset_path = \"datasets/hr500k.conllup_extracted.json\"\n",
    "\n",
    "# Load the json file\n",
    "with open(dataset_path, \"r\") as file:\n",
    "    json_dict = json.load(file)\n",
    "\n",
    "# Open the train, eval and test dictionaries as DataFrames\n",
    "train_df = pd.DataFrame(json_dict[\"train\"])\n",
    "test_df = pd.DataFrame(json_dict[\"test\"])\n",
    "dev_df = pd.DataFrame(json_dict[\"dev\"])\n",
    "\n",
    "# Change the sentence_ids to numbers\n",
    "test_df['sentence_id'] = pd.factorize(test_df['sentence_id'])[0]\n",
    "train_df['sentence_id'] = pd.factorize(train_df['sentence_id'])[0]\n",
    "dev_df['sentence_id'] = pd.factorize(dev_df['sentence_id'])[0]\n",
    "\n",
    "# Define the labels\n",
    "LABELS = json_dict[\"labels\"]\n",
    "print(LABELS)\n",
    "\n",
    "print(train_df.shape, test_df.shape, dev_df.shape)\n",
    "print(train_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(model, train_df, test_df, dataset_path, LABELS):\n",
    "\n",
    "    # Define the model\n",
    "\n",
    "    # Define the model arguments - use the same one as for XLM-R-large if model is based on it,\n",
    "    # if the model is of same size as XLM-R-base, use its optimal hyperparameters (I searched for them before)\n",
    "    xlm_r_large_args = {\"overwrite_output_dir\": True,\n",
    "                \"num_train_epochs\": 5,\n",
    "                \"labels_list\": LABELS,\n",
    "                \"learning_rate\": 1e-5,\n",
    "                \"train_batch_size\": 32,\n",
    "                # Comment out no_cache and no_save if you want to save the model\n",
    "                \"no_cache\": True,\n",
    "                \"no_save\": True,\n",
    "                \"max_seq_length\": 256,\n",
    "                \"save_steps\": -1,\n",
    "                \"silent\": True,\n",
    "                }\n",
    "\n",
    "    xlm_r_base_args = {\"overwrite_output_dir\": True,\n",
    "             \"num_train_epochs\": 9,\n",
    "             \"labels_list\": LABELS,\n",
    "             \"learning_rate\": 1e-5,\n",
    "             \"train_batch_size\": 32,\n",
    "             # Comment out no_cache and no_save if you want to save the model\n",
    "             \"no_cache\": True,\n",
    "             \"no_save\": True,\n",
    "             \"max_seq_length\": 256,\n",
    "             \"save_steps\": -1,\n",
    "            \"silent\": True,\n",
    "             }\n",
    "\n",
    "\n",
    "    # Model type - a dictionary of type and model name.\n",
    "    # To refer to our own models, use the path to the model directory as the model name.\n",
    "    model_type_dict = {\n",
    "        \"sloberta\": [\"camembert\", \"EMBEDDIA/sloberta\", xlm_r_base_args],\n",
    "        \"csebert\": [\"bert\", \"EMBEDDIA/crosloengual-bert\", xlm_r_base_args],\n",
    "        \"xlm-r-base\": [\"xlmroberta\", \"xlm-roberta-base\", xlm_r_base_args],\n",
    "        \"xlm-r-large\": [\"xlmroberta\", \"xlm-roberta-large\", xlm_r_large_args],\n",
    "        \"bertic\": [\"electra\", \"classla/bcms-bertic\", xlm_r_base_args],\n",
    "        \"xlmrb_bcms_12\": [\"xlmroberta\", \"models/xlmrb_bcms_12\", xlm_r_base_args],\n",
    "        \"xlmrl_bcms_48000\": [\"xlmroberta\", \"output\", xlm_r_large_args]\n",
    "    }\n",
    "\n",
    "    # Update the hyperparameters accordingly to the model\n",
    "    model_args = model_type_dict[model][2]\n",
    "\n",
    "    if \"bcms\" in model:\n",
    "        model_path = model_type_dict[model][1]\n",
    "        model_args[\"output_dir\"] = \"models/{}/\".format(model)\n",
    "        model_args[\"no_save\"] = False\n",
    "        model_args[\"num_train_epoch\"] = 1\n",
    "\n",
    "    # Define the model\n",
    "    current_model = NERModel(\n",
    "    model_type_dict[model][0],\n",
    "    model_type_dict[model][1],\n",
    "    labels = LABELS,\n",
    "    use_cuda=True,\n",
    "    args = model_args)\n",
    "\n",
    "    print(\"Training started. Current model: {}\".format(model))\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Fine-tune the model\n",
    "    current_model.train_model(train_df)\n",
    "\n",
    "    print(\"Training completed.\")\n",
    "\n",
    "    training_time = round((time.time() - start_time)/60,2)\n",
    "\n",
    "    print(\"It took {} minutes for {} instances.\".format(training_time, train_df.shape[0]))\n",
    "\n",
    "    # Clean cache\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    start_evaluation_time = time.time()\n",
    "\n",
    "    # Evaluate the model\n",
    "    results = current_model.eval_model(test_df)\n",
    "\n",
    "    print(\"Evaluation completed.\")\n",
    "\n",
    "    evaluation_time = round((time.time() - start_evaluation_time)/60,2)\n",
    "\n",
    "    print(\"It took {} minutes for {} instances.\".format(evaluation_time, test_df.shape[0]))\n",
    "\n",
    "    # Get predictions\n",
    "    preds = results[1]\n",
    "\n",
    "    # Create a list with predictions\n",
    "    preds_list = []\n",
    "\n",
    "    for sentence in preds:\n",
    "        for word in sentence:\n",
    "            current_word = []\n",
    "            for element in word:\n",
    "                # Find prediction with the highest value\n",
    "                highest_index = element.index(max(element))\n",
    "                # Transform the index to label\n",
    "                current_pred = current_model.config.id2label[highest_index]\n",
    "                # Append to the list\n",
    "                current_word.append(current_pred)\n",
    "            # Segmentation can result in multiple predictions for one word - use the first prediction only\n",
    "            preds_list.append(current_word[0])\n",
    "    \n",
    "    # Get y_true\n",
    "    y_true = list(test_df.labels)\n",
    "\n",
    "    run_name = \"{}-{}\".format(dataset_path, model)\n",
    "\n",
    "    # Evaluate predictions\n",
    "    metrics = evaluate.testing(y_true, preds_list, list(test_df.labels.unique()), run_name, show_matrix=True)\n",
    "\n",
    "    # Add y_pred and y_true to the metrics dict\n",
    "    metrics[\"y_true\"] = y_true\n",
    "    metrics[\"y_pred\"] = preds_list\n",
    "\n",
    "    # Let's also add entire results\n",
    "    metrics[\"results_output\"] = results    \n",
    "    \n",
    "    # The function returns a dict with accuracy, micro f1, macro f1, y_true and y_pred\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/cache/nikolal/xlmrl_bcms_exp/checkpoint-6000',\n",
       " '/cache/nikolal/xlmrl_bcms_exp/checkpoint-12000',\n",
       " '/cache/nikolal/xlmrl_bcms_exp/checkpoint-18000',\n",
       " '/cache/nikolal/xlmrl_bcms_exp/checkpoint-24000',\n",
       " '/cache/nikolal/xlmrl_bcms_exp/checkpoint-30000',\n",
       " '/cache/nikolal/xlmrl_bcms_exp/checkpoint-36000',\n",
       " '/cache/nikolal/xlmrl_bcms_exp/checkpoint-42000',\n",
       " '/cache/nikolal/xlmrl_bcms_exp/checkpoint-48000',\n",
       " '/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-6000',\n",
       " '/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-12000',\n",
       " '/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-18000',\n",
       " '/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-24000',\n",
       " '/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-30000',\n",
       " '/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-42000',\n",
       " '/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-48000']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create lists of all needed models for the task\n",
    "base_dict = {\"/cache/nikolal/xlmrb_bcms_exp/checkpoint-12000\": \"xlmrb_bcms-12\", \"/cache/nikolal/xlmrb_bcms_exp/checkpoint-24000\": \"xlmrb_bcms-24\", \"/cache/nikolal/xlmrb_bcms_exp/checkpoint-36000\": \"xlmrb_bcms-36\", \"/cache/nikolal/xlmrb_bcms_exp/checkpoint-48000\": \"xlmrb_bcms-48\", \"/cache/nikolal/xlmrb_bcms_exp/checkpoint-60000\": \"xlmrb_bcms-60\", \"/cache/nikolal/xlmrb_bcms_exp/checkpoint-72000\": \"xlmrb_bcms-72\", \"/cache/nikolal/xlmrb_bcms_exp/checkpoint-84000\": \"xlmrb_bcms-84\", \"/cache/nikolal/xlmrb_bcms_exp/checkpoint-96000\": \"xlmrb_bcms-96\"}\n",
    "large_dict = {\"/cache/nikolal/xlmrl_bcms_exp/checkpoint-6000\": \"xlmrl_bcms-6\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-12000\":\"xlmrl_bcms-12\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-18000\": \"xlmrl_bcms-18\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-24000\": \"xlmrl_bcms-24\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-30000\": \"xlmrl_bcms-30\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-36000\": \"xlmrl_bcms-36\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-42000\": \"xlmrl_bcms-42\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-48000\": \"xlmrl_bcms-48\", \"/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-6000\": \"xlmrl_sl-bcms-6\", \"/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-12000\": \"xlmrl_sl-bcms-12\", \"/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-18000\": \"xlmrl_sl-bcms-18\", \"/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-24000\": \"xlmrl_sl-bcms-24\", \"/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-30000\": \"xlmrl_sl-bcms-30\", \"/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-42000\": \"xlmrl_sl-bcms-42\", \"/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-48000\": \"xlmrl_sl-bcms-48\"}\n",
    "\n",
    "base_list = list(base_dict.keys())\n",
    "large_list = list(large_dict.keys())\n",
    "large_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xlmrl_bcms-6', 'xlmrl_bcms-12', 'xlmrl_bcms-18', 'xlmrl_bcms-24', 'xlmrl_bcms-30', 'xlmrl_bcms-36', 'xlmrl_bcms-42', 'xlmrl_bcms-48', 'xlmrl_sl-bcms-6', 'xlmrl_sl-bcms-12', 'xlmrl_sl-bcms-18', 'xlmrl_sl-bcms-24', 'xlmrl_sl-bcms-30', 'xlmrl_sl-bcms-42', 'xlmrl_sl-bcms-48']\n",
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "print(list(large_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_checkpoint(model_path, model_size, train_df, test_df, dataset_path, LABELS):\n",
    "\t# When fine-tuning our custom models that we pre-trained, and using them from checkpoints, the process is a bit different than with publicly available models: first, we need to fine-tune a model from the original checkpoint, so that we save the model and overwrite its original settings which force pretraining from a specific step (and disable fine-tuning by that). Then we take that new model and fine-tune it, as we did with the models before. \n",
    "\n",
    "\t# Create lists of all needed models for the task\n",
    "\tpath_list = {\"/cache/nikolal/xlmrb_bcms_exp/checkpoint-12000\": \"xlmrb_bcms-12\", \"/cache/nikolal/xlmrb_bcms_exp/checkpoint-24000\": \"xlmrb_bcms-24\", \"/cache/nikolal/xlmrb_bcms_exp/checkpoint-36000\": \"xlmrb_bcms-36\", \"/cache/nikolal/xlmrb_bcms_exp/checkpoint-48000\": \"xlmrb_bcms-48\", \"/cache/nikolal/xlmrb_bcms_exp/checkpoint-60000\": \"xlmrb_bcms-60\", \"/cache/nikolal/xlmrb_bcms_exp/checkpoint-72000\": \"xlmrb_bcms-72\", \"/cache/nikolal/xlmrb_bcms_exp/checkpoint-84000\": \"xlmrb_bcms-84\", \"/cache/nikolal/xlmrb_bcms_exp/checkpoint-96000\": \"xlmrb_bcms-96\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-6000\": \"xlmrl_bcms-6\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-12000\":\"xlmrl_bcms-12\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-18000\": \"xlmrl_bcms-18\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-24000\": \"xlmrl_bcms-24\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-30000\": \"xlmrl_bcms-30\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-36000\": \"xlmrl_bcms-36\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-42000\": \"xlmrl_bcms-42\", \"/cache/nikolal/xlmrl_bcms_exp/checkpoint-48000\": \"xlmrl_bcms-48\", \"/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-6000\": \"xlmrl_sl-bcms-6\", \"/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-12000\": \"xlmrl_sl-bcms-12\", \"/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-18000\": \"xlmrl_sl-bcms-18\", \"/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-24000\": \"xlmrl_sl-bcms-24\", \"/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-30000\": \"xlmrl_sl-bcms-30\", \"/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-42000\": \"xlmrl_sl-bcms-42\", \"/cache/nikolal/xlmrl_sl-bcms_exp/checkpoint-48000\": \"xlmrl_sl-bcms-48\"}\n",
    "\n",
    "\t# Define the model arguments - use the same one as for XLM-R-large if model is based on it,\n",
    "\t# if the model is of same size as XLM-R-base, use its optimal hyperparameters (I searched for them before)\n",
    "\txlm_r_large_args = {\"overwrite_output_dir\": True,\n",
    "\t\t\t\"num_train_epochs\": 5,\n",
    "\t\t\t\"labels_list\": LABELS,\n",
    "\t\t\t\"learning_rate\": 1e-5,\n",
    "\t\t\t\"train_batch_size\": 32,\n",
    "\t\t\t# Comment out no_cache and no_save if you want to save the model\n",
    "\t\t\t\"no_cache\": True,\n",
    "\t\t\t\"no_save\": True,\n",
    "\t\t\t\"max_seq_length\": 256,\n",
    "\t\t\t\"save_steps\": -1,\n",
    "\t\t\t\"silent\": True,\n",
    "\t\t\t}\n",
    "\n",
    "\txlm_r_base_args = {\"overwrite_output_dir\": True,\n",
    "\t\t\t\"num_train_epochs\": 9,\n",
    "\t\t\t\"labels_list\": LABELS,\n",
    "\t\t\t\"learning_rate\": 1e-5,\n",
    "\t\t\t\"train_batch_size\": 32,\n",
    "\t\t\t# Comment out no_cache and no_save if you want to save the model\n",
    "\t\t\t\"no_cache\": True,\n",
    "\t\t\t\"no_save\": True,\n",
    "\t\t\t\"max_seq_length\": 256,\n",
    "\t\t\t\"save_steps\": -1,\n",
    "\t\t\t\"silent\": True,\n",
    "\t\t\t}\n",
    "\t\n",
    "\tif model_size == \"base\":\n",
    "\t\t# Update the hyperparameters accordingly to the model\n",
    "\t\tmodel_args = xlm_r_base_args\n",
    "\telif model_size == \"large\":\n",
    "\t\tmodel_args = xlm_r_large_args\n",
    "\n",
    "\t# Add additional arguments, specific for our own models\n",
    "\t# Specify the folder where we want to save the models\n",
    "\tnew_model_path = path_list[model_path]\n",
    "\tmodel_args[\"output_dir\"] = \"models/{}/\".format(new_model_path)\n",
    "\tmodel_args[\"no_save\"] = False\n",
    "\tmodel_args[\"num_train_epoch\"] = 1\n",
    "\n",
    "\t# Define the model\n",
    "\tcurrent_model = NERModel(\n",
    "\t\"xlmroberta\",\n",
    "\tmodel_path,\n",
    "\tlabels = LABELS,\n",
    "\tuse_cuda=True,\n",
    "\targs = model_args)\n",
    "\n",
    "\tprint(\"Training started. Current model: {}\".format(model))\n",
    "\tstart_time = time.time()\n",
    "\n",
    "\t# Fine-tune the model\n",
    "\tcurrent_model.train_model(train_df)\n",
    "\n",
    "\tprint(\"Training completed.\")\n",
    "\n",
    "\tprint(\"Model saved as models/{}/\".format(new_model_path))\n",
    "\n",
    "\t# Clean cache\n",
    "\tgc.collect()\n",
    "\ttorch.cuda.empty_cache()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\t#start_evaluation_time = time.time()\n",
    "\n",
    "\t# Evaluate the model\n",
    "\t#results = current_model.eval_model(test_df)\n",
    "\n",
    "\t#print(\"Evaluation completed.\")\n",
    "\n",
    "\t#evaluation_time = round((time.time() - start_evaluation_time)/60,2)\n",
    "\n",
    "\t#print(\"It took {} minutes for {} instances.\".format(evaluation_time, test_df.shape[0]))\n",
    "\n",
    "\t# Get predictions\n",
    "\t#preds = results[1]\n",
    "\n",
    "\t# Create a list with predictions\n",
    "\t#preds_list = []\n",
    "\n",
    "\tfor sentence in preds:\n",
    "\t\tfor word in sentence:\n",
    "\t\t\tcurrent_word = []\n",
    "\t\t\tfor element in word:\n",
    "\t\t\t\t# Find prediction with the highest value\n",
    "\t\t\t\thighest_index = element.index(max(element))\n",
    "\t\t\t\t# Transform the index to label\n",
    "\t\t\t\tcurrent_pred = current_model.config.id2label[highest_index]\n",
    "\t\t\t\t# Append to the list\n",
    "\t\t\t\tcurrent_word.append(current_pred)\n",
    "\t\t\t# Segmentation can result in multiple predictions for one word - use the first prediction only\n",
    "\t\t\tpreds_list.append(current_word[0])\n",
    "\n",
    "\t# Get y_true\n",
    "\ty_true = list(test_df.labels)\n",
    "\n",
    "\trun_name = \"{}-{}\".format(dataset_path, model)\n",
    "\n",
    "\t# Evaluate predictions\n",
    "\tmetrics = evaluate.testing(y_true, preds_list, list(test_df.labels.unique()), run_name, show_matrix=True)\n",
    "\n",
    "\t# Add y_pred and y_true to the metrics dict\n",
    "\tmetrics[\"y_true\"] = y_true\n",
    "\tmetrics[\"y_pred\"] = preds_list\n",
    "\n",
    "\t# Let's also add entire results\n",
    "\tmetrics[\"results_output\"] = results    \n",
    "\n",
    "\t# The function returns a dict with accuracy, micro f1, macro f1, y_true and y_pred\n",
    "\treturn metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started. Current model: xlmrb_bcms_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.ner.ner_model: Converting to features started.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "995f89ec217e4b598352ce9c4b935df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5e375baa1c41a6914a68c9acf68c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.ner.ner_model:   Starting fine-tuning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c57dc8df9ea469bb5f1c5c995522f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 9:   0%|          | 0/619 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tajak/NER-recognition/ner/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633c386a1f91472aafd1c3b09f805678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 9:   0%|          | 0/619 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m model_list \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mxlmrb_bcms_12\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m model_list:\n\u001b[0;32m----> 5\u001b[0m \tcurrent_results_dict \u001b[39m=\u001b[39m train_and_test(model, train_df, test_df, dataset_path, LABELS)\n\u001b[1;32m      7\u001b[0m \t\u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mRun finished.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[19], line 70\u001b[0m, in \u001b[0;36mtrain_and_test\u001b[0;34m(model, train_df, test_df, dataset_path, LABELS)\u001b[0m\n\u001b[1;32m     67\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     69\u001b[0m \u001b[39m# Fine-tune the model\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m current_model\u001b[39m.\u001b[39;49mtrain_model(train_df)\n\u001b[1;32m     72\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTraining completed.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     74\u001b[0m training_time \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m((time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time)\u001b[39m/\u001b[39m\u001b[39m60\u001b[39m,\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/NER-recognition/ner/lib/python3.8/site-packages/simpletransformers/ner/ner_model.py:513\u001b[0m, in \u001b[0;36mNERModel.train_model\u001b[0;34m(self, train_data, output_dir, show_running_loss, args, eval_data, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m train_dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_and_cache_examples(train_data)\n\u001b[1;32m    511\u001b[0m os\u001b[39m.\u001b[39mmakedirs(output_dir, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 513\u001b[0m global_step, training_details \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m    514\u001b[0m     train_dataset,\n\u001b[1;32m    515\u001b[0m     output_dir,\n\u001b[1;32m    516\u001b[0m     show_running_loss\u001b[39m=\u001b[39;49mshow_running_loss,\n\u001b[1;32m    517\u001b[0m     eval_data\u001b[39m=\u001b[39;49meval_data,\n\u001b[1;32m    518\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    519\u001b[0m )\n\u001b[1;32m    521\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_model(model\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel)\n\u001b[1;32m    523\u001b[0m logger\u001b[39m.\u001b[39minfo(\n\u001b[1;32m    524\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m Training of \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m model complete. Saved to \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    525\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mmodel_type, output_dir\n\u001b[1;32m    526\u001b[0m     )\n\u001b[1;32m    527\u001b[0m )\n",
      "File \u001b[0;32m~/NER-recognition/ner/lib/python3.8/site-packages/simpletransformers/ner/ner_model.py:804\u001b[0m, in \u001b[0;36mNERModel.train\u001b[0;34m(self, train_dataset, output_dir, show_running_loss, eval_data, test_data, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    800\u001b[0m     loss \u001b[39m=\u001b[39m (\n\u001b[1;32m    801\u001b[0m         loss\u001b[39m.\u001b[39mmean()\n\u001b[1;32m    802\u001b[0m     )  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n\u001b[0;32m--> 804\u001b[0m current_loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m    806\u001b[0m \u001b[39mif\u001b[39;00m show_running_loss:\n\u001b[1;32m    807\u001b[0m     batch_iterator\u001b[39m.\u001b[39mset_description(\n\u001b[1;32m    808\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpochs \u001b[39m\u001b[39m{\u001b[39;00mepoch_number\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00margs\u001b[39m.\u001b[39mnum_train_epochs\u001b[39m}\u001b[39;00m\u001b[39m. Running Loss: \u001b[39m\u001b[39m{\u001b[39;00mcurrent_loss\u001b[39m:\u001b[39;00m\u001b[39m9.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    809\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Testing the models if they work as expected\n",
    "model_list = [\"xlmrb_bcms_12\"]\n",
    "\n",
    "for model in model_list:\n",
    "\tcurrent_results_dict = train_and_test(model, train_df, test_df, dataset_path, LABELS)\n",
    "\n",
    "\tprint(\"Run finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_list = dir(NERArgs)\n",
    "\n",
    "import torch\n",
    "\n",
    "optimizer_state = torch.load(\"model/checkpoint-48000/training_args.bin\")\n",
    "\n",
    "attributes = list(dir(optimizer_state))\n",
    "\n",
    "\n",
    "# Find the intersection of the sets\n",
    "common_elements = list(set(attributes).intersection(set(ner_list)))\n",
    "\n",
    "print(common_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimizer_state.resume_from_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_state.warmup_ratio = 0.06\n",
    "optimizer_state.learning_rate = 1e-5\n",
    "optimizer_state.fp16 = True\n",
    "optimizer_state.logging_steps = 50\n",
    "#optimizer_state.n_gpu = 1\n",
    "optimizer_state.gradient_accumulation_steps = 1\n",
    "optimizer_state.output_dir = \"outputs/\"\n",
    "optimizer_state.num_train_epochs = 1\n",
    "optimizer_state.resume_from_checkpoint = True\n",
    "optimizer_state.ignore_data_skip = True\n",
    "\n",
    "\n",
    "# Save arguments with new attributes\n",
    "torch.save(optimizer_state, \"model/checkpoint-48000/training_args.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new file for results\n",
    "#with open(\"ner-results-our-models.txt\", \"w\") as file:\n",
    "#    file.write(\"Date\\tModel\\tRun\\tDataset\\tMicro F1\\tMacro F1\\tLabel Report\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the models if they work as expected\n",
    "# models: [\"xlm-r-large\", \"sloberta\", \"csebert\", \"xlm-r-base\", \"bertic\"]\n",
    "model = \"xlmrl-bcms-48\"\n",
    "run = \"test\"\n",
    "\n",
    "current_results_dict = train_and_test(model, train_df, test_df, dataset_path)\n",
    "\n",
    "# Add to the dict model name, dataset name and run\n",
    "current_results_dict[\"model\"] = model\n",
    "current_results_dict[\"run\"] = \"{}-{}\".format(model, run)\n",
    "current_results_dict[\"dataset\"] = dataset_path\n",
    "\n",
    "# Add to the file with results all important information\n",
    "#with open(\"ner-results-testing.txt\", \"a\") as file:\n",
    "#    file.write(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n\".format(datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"), current_results_dict[\"model\"], current_results_dict[\"run\"], current_results_dict[\"dataset\"], current_results_dict[\"micro F1\"], current_results_dict[\"macro F1\"], current_results_dict[\"Micro F1 Nikola\"], current_results_dict[\"Macro F1 Nikola\"], current_results_dict[\"label-report\"]))\n",
    "\n",
    "# Add to the original test_df y_preds\n",
    "#test_df[\"y_pred_{}_{}\".format(model, run)] = current_results_dict[\"y_pred\"]\n",
    "\n",
    "# Save entire dict just in case\n",
    "#with open(\"{}-{}-{}-backlog.json\".format(dataset_path,model,run), \"w\") as backlog:\n",
    "#    json.dump(current_results_dict, backlog, indent=2)\n",
    "\n",
    "print(\"Run {} finished.\".format(run))\n",
    "\n",
    "# At the end, save the test_df with all predictions\n",
    "#test_df.to_csv(\"{}-test_df-with-predictions.csv\".format(dataset_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Analysis - Result list and creation of results summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Model</th>\n",
       "      <th>Run</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Label Report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18/08/2023 16:39:46</td>\n",
       "      <td>xlm-r-large</td>\n",
       "      <td>xlm-r-large-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.918266</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.92105263157894...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18/08/2023 16:54:08</td>\n",
       "      <td>xlm-r-large</td>\n",
       "      <td>xlm-r-large-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990350</td>\n",
       "      <td>0.920143</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.92307692307692...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18/08/2023 17:40:13</td>\n",
       "      <td>xlm-r-base</td>\n",
       "      <td>xlm-r-base-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.988611</td>\n",
       "      <td>0.909217</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18/08/2023 17:50:32</td>\n",
       "      <td>xlm-r-base</td>\n",
       "      <td>xlm-r-base-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.988572</td>\n",
       "      <td>0.903684</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.91891891891891...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22/08/2023 09:38:41</td>\n",
       "      <td>xlmrb_bcms-12</td>\n",
       "      <td>xlmrb_bcms-12-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.989627</td>\n",
       "      <td>0.914450</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>25/08/2023 08:25:06</td>\n",
       "      <td>xlmrb_bcms-72</td>\n",
       "      <td>xlmrb_bcms-72-1</td>\n",
       "      <td>datasets/set.sr.plus.conllup_extracted.json</td>\n",
       "      <td>0.990982</td>\n",
       "      <td>0.922962</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>25/08/2023 08:28:53</td>\n",
       "      <td>xlmrb_bcms-84</td>\n",
       "      <td>xlmrb_bcms-84-0</td>\n",
       "      <td>datasets/set.sr.plus.conllup_extracted.json</td>\n",
       "      <td>0.990719</td>\n",
       "      <td>0.929880</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>25/08/2023 08:32:19</td>\n",
       "      <td>xlmrb_bcms-84</td>\n",
       "      <td>xlmrb_bcms-84-1</td>\n",
       "      <td>datasets/set.sr.plus.conllup_extracted.json</td>\n",
       "      <td>0.990456</td>\n",
       "      <td>0.924627</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>25/08/2023 08:36:07</td>\n",
       "      <td>xlmrb_bcms-96</td>\n",
       "      <td>xlmrb_bcms-96-0</td>\n",
       "      <td>datasets/set.sr.plus.conllup_extracted.json</td>\n",
       "      <td>0.990719</td>\n",
       "      <td>0.923429</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>25/08/2023 08:39:32</td>\n",
       "      <td>xlmrb_bcms-96</td>\n",
       "      <td>xlmrb_bcms-96-1</td>\n",
       "      <td>datasets/set.sr.plus.conllup_extracted.json</td>\n",
       "      <td>0.991419</td>\n",
       "      <td>0.927826</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date          Model              Run  \\\n",
       "0    18/08/2023 16:39:46    xlm-r-large    xlm-r-large-0   \n",
       "1    18/08/2023 16:54:08    xlm-r-large    xlm-r-large-1   \n",
       "2    18/08/2023 17:40:13     xlm-r-base     xlm-r-base-0   \n",
       "3    18/08/2023 17:50:32     xlm-r-base     xlm-r-base-1   \n",
       "4    22/08/2023 09:38:41  xlmrb_bcms-12  xlmrb_bcms-12-0   \n",
       "..                   ...            ...              ...   \n",
       "211  25/08/2023 08:25:06  xlmrb_bcms-72  xlmrb_bcms-72-1   \n",
       "212  25/08/2023 08:28:53  xlmrb_bcms-84  xlmrb_bcms-84-0   \n",
       "213  25/08/2023 08:32:19  xlmrb_bcms-84  xlmrb_bcms-84-1   \n",
       "214  25/08/2023 08:36:07  xlmrb_bcms-96  xlmrb_bcms-96-0   \n",
       "215  25/08/2023 08:39:32  xlmrb_bcms-96  xlmrb_bcms-96-1   \n",
       "\n",
       "                                         Dataset  Micro F1  Macro F1  \\\n",
       "0         datasets/hr500k.conllup_extracted.json  0.990291  0.918266   \n",
       "1         datasets/hr500k.conllup_extracted.json  0.990350  0.920143   \n",
       "2         datasets/hr500k.conllup_extracted.json  0.988611  0.909217   \n",
       "3         datasets/hr500k.conllup_extracted.json  0.988572  0.903684   \n",
       "4         datasets/hr500k.conllup_extracted.json  0.989627  0.914450   \n",
       "..                                           ...       ...       ...   \n",
       "211  datasets/set.sr.plus.conllup_extracted.json  0.990982  0.922962   \n",
       "212  datasets/set.sr.plus.conllup_extracted.json  0.990719  0.929880   \n",
       "213  datasets/set.sr.plus.conllup_extracted.json  0.990456  0.924627   \n",
       "214  datasets/set.sr.plus.conllup_extracted.json  0.990719  0.923429   \n",
       "215  datasets/set.sr.plus.conllup_extracted.json  0.991419  0.927826   \n",
       "\n",
       "                                          Label Report  \n",
       "0    {'B-deriv-per': {'precision': 0.92105263157894...  \n",
       "1    {'B-deriv-per': {'precision': 0.92307692307692...  \n",
       "2    {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "3    {'B-deriv-per': {'precision': 0.91891891891891...  \n",
       "4    {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "..                                                 ...  \n",
       "211  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "212  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "213  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "214  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "215  {'B-deriv-per': {'precision': 1.0, 'recall': 0...  \n",
       "\n",
       "[216 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the txt with results\n",
    "import pandas as pd\n",
    "\n",
    "#results = pd.read_csv(\"ner-results.txt\", sep=\"\\t\")\n",
    "#results = pd.read_csv(\"ner-results-our-models.txt\", sep=\"\\t\")\n",
    "results = pd.read_csv(\"ner-results-all-models.txt\", sep=\"\\t\")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Model</th>\n",
       "      <th>Run</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Label Report</th>\n",
       "      <th>model-dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18/08/2023 16:39:46</td>\n",
       "      <td>xlm-r-large</td>\n",
       "      <td>xlm-r-large-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.918266</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.92105263157894...</td>\n",
       "      <td>xlm-r-large-datasets/hr500k.conllup_extracted....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18/08/2023 16:54:08</td>\n",
       "      <td>xlm-r-large</td>\n",
       "      <td>xlm-r-large-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.990350</td>\n",
       "      <td>0.920143</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.92307692307692...</td>\n",
       "      <td>xlm-r-large-datasets/hr500k.conllup_extracted....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18/08/2023 17:40:13</td>\n",
       "      <td>xlm-r-base</td>\n",
       "      <td>xlm-r-base-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.988611</td>\n",
       "      <td>0.909217</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "      <td>xlm-r-base-datasets/hr500k.conllup_extracted.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18/08/2023 17:50:32</td>\n",
       "      <td>xlm-r-base</td>\n",
       "      <td>xlm-r-base-1</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.988572</td>\n",
       "      <td>0.903684</td>\n",
       "      <td>{'B-deriv-per': {'precision': 0.91891891891891...</td>\n",
       "      <td>xlm-r-base-datasets/hr500k.conllup_extracted.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22/08/2023 09:38:41</td>\n",
       "      <td>xlmrb_bcms-12</td>\n",
       "      <td>xlmrb_bcms-12-0</td>\n",
       "      <td>datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.989627</td>\n",
       "      <td>0.914450</td>\n",
       "      <td>{'B-deriv-per': {'precision': 1.0, 'recall': 0...</td>\n",
       "      <td>xlmrb_bcms-12-datasets/hr500k.conllup_extracte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date          Model              Run  \\\n",
       "0  18/08/2023 16:39:46    xlm-r-large    xlm-r-large-0   \n",
       "1  18/08/2023 16:54:08    xlm-r-large    xlm-r-large-1   \n",
       "2  18/08/2023 17:40:13     xlm-r-base     xlm-r-base-0   \n",
       "3  18/08/2023 17:50:32     xlm-r-base     xlm-r-base-1   \n",
       "4  22/08/2023 09:38:41  xlmrb_bcms-12  xlmrb_bcms-12-0   \n",
       "\n",
       "                                  Dataset  Micro F1  Macro F1  \\\n",
       "0  datasets/hr500k.conllup_extracted.json  0.990291  0.918266   \n",
       "1  datasets/hr500k.conllup_extracted.json  0.990350  0.920143   \n",
       "2  datasets/hr500k.conllup_extracted.json  0.988611  0.909217   \n",
       "3  datasets/hr500k.conllup_extracted.json  0.988572  0.903684   \n",
       "4  datasets/hr500k.conllup_extracted.json  0.989627  0.914450   \n",
       "\n",
       "                                        Label Report  \\\n",
       "0  {'B-deriv-per': {'precision': 0.92105263157894...   \n",
       "1  {'B-deriv-per': {'precision': 0.92307692307692...   \n",
       "2  {'B-deriv-per': {'precision': 1.0, 'recall': 0...   \n",
       "3  {'B-deriv-per': {'precision': 0.91891891891891...   \n",
       "4  {'B-deriv-per': {'precision': 1.0, 'recall': 0...   \n",
       "\n",
       "                                       model-dataset  \n",
       "0  xlm-r-large-datasets/hr500k.conllup_extracted....  \n",
       "1  xlm-r-large-datasets/hr500k.conllup_extracted....  \n",
       "2  xlm-r-base-datasets/hr500k.conllup_extracted.json  \n",
       "3  xlm-r-base-datasets/hr500k.conllup_extracted.json  \n",
       "4  xlmrb_bcms-12-datasets/hr500k.conllup_extracte...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join information for model and dataset\n",
    "results[\"model-dataset\"] = [x[0]+\"-\"+x[1] for x in list(zip(results[\"Model\"].to_list(), results[\"Dataset\"].to_list()))]\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model-dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bertic-datasets/hr500k.conllup_extracted.json</th>\n",
       "      <td>0.907610</td>\n",
       "      <td>0.010927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertic-datasets/reldi-normtagner-hr.conllup_extracted.json</th>\n",
       "      <td>0.754102</td>\n",
       "      <td>0.045028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertic-datasets/reldi-normtagner-sr.conllup_extracted.json</th>\n",
       "      <td>0.682172</td>\n",
       "      <td>0.056300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertic-datasets/set.sr.plus.conllup_extracted.json</th>\n",
       "      <td>0.834696</td>\n",
       "      <td>0.038375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>csebert-datasets/hr500k.conllup_extracted.json</th>\n",
       "      <td>0.914205</td>\n",
       "      <td>0.001012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmrl_sl-bcms-48-datasets/set.sr.plus.conllup_extracted.json</th>\n",
       "      <td>0.941438</td>\n",
       "      <td>0.002079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmrl_sl-bcms-6-datasets/hr500k.conllup_extracted.json</th>\n",
       "      <td>0.924280</td>\n",
       "      <td>0.001058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmrl_sl-bcms-6-datasets/reldi-normtagner-hr.conllup_extracted.json</th>\n",
       "      <td>0.781909</td>\n",
       "      <td>0.001797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmrl_sl-bcms-6-datasets/reldi-normtagner-sr.conllup_extracted.json</th>\n",
       "      <td>0.796086</td>\n",
       "      <td>0.009761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmrl_sl-bcms-6-datasets/set.sr.plus.conllup_extracted.json</th>\n",
       "      <td>0.939614</td>\n",
       "      <td>0.001209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Macro F1       Std\n",
       "model-dataset                                                         \n",
       "bertic-datasets/hr500k.conllup_extracted.json       0.907610  0.010927\n",
       "bertic-datasets/reldi-normtagner-hr.conllup_ext...  0.754102  0.045028\n",
       "bertic-datasets/reldi-normtagner-sr.conllup_ext...  0.682172  0.056300\n",
       "bertic-datasets/set.sr.plus.conllup_extracted.json  0.834696  0.038375\n",
       "csebert-datasets/hr500k.conllup_extracted.json      0.914205  0.001012\n",
       "...                                                      ...       ...\n",
       "xlmrl_sl-bcms-48-datasets/set.sr.plus.conllup_e...  0.941438  0.002079\n",
       "xlmrl_sl-bcms-6-datasets/hr500k.conllup_extract...  0.924280  0.001058\n",
       "xlmrl_sl-bcms-6-datasets/reldi-normtagner-hr.co...  0.781909  0.001797\n",
       "xlmrl_sl-bcms-6-datasets/reldi-normtagner-sr.co...  0.796086  0.009761\n",
       "xlmrl_sl-bcms-6-datasets/set.sr.plus.conllup_ex...  0.939614  0.001209\n",
       "\n",
       "[108 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_results = pd.concat([results.groupby(\"model-dataset\")[\"Macro F1\"].mean(), results.groupby(\"model-dataset\")[\"Macro F1\"].std()], axis = 1)\n",
    "\n",
    "# Rename columns\n",
    "agg_results.columns = [\"Macro F1\", \"Std\"]\n",
    "agg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model-dataset</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bertic-datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.907610</td>\n",
       "      <td>0.010927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bertic-datasets/reldi-normtagner-hr.conllup_ex...</td>\n",
       "      <td>0.754102</td>\n",
       "      <td>0.045028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bertic-datasets/reldi-normtagner-sr.conllup_ex...</td>\n",
       "      <td>0.682172</td>\n",
       "      <td>0.056300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bertic-datasets/set.sr.plus.conllup_extracted....</td>\n",
       "      <td>0.834696</td>\n",
       "      <td>0.038375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>csebert-datasets/hr500k.conllup_extracted.json</td>\n",
       "      <td>0.914205</td>\n",
       "      <td>0.001012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       model-dataset  Macro F1       Std\n",
       "0      bertic-datasets/hr500k.conllup_extracted.json  0.907610  0.010927\n",
       "1  bertic-datasets/reldi-normtagner-hr.conllup_ex...  0.754102  0.045028\n",
       "2  bertic-datasets/reldi-normtagner-sr.conllup_ex...  0.682172  0.056300\n",
       "3  bertic-datasets/set.sr.plus.conllup_extracted....  0.834696  0.038375\n",
       "4     csebert-datasets/hr500k.conllup_extracted.json  0.914205  0.001012"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset index\n",
    "agg_results.reset_index(inplace=True)\n",
    "\n",
    "agg_results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>hr500k.conllup_extracted.json-Macro F1</th>\n",
       "      <th>reldi-normtagner-hr.conllup_extracted.json-Macro F1</th>\n",
       "      <th>reldi-normtagner-sr.conllup_extracted.json-Macro F1</th>\n",
       "      <th>set.sr.plus.conllup_extracted.json-Macro F1</th>\n",
       "      <th>hr500k.conllup_extracted.json-Std</th>\n",
       "      <th>reldi-normtagner-hr.conllup_extracted.json-Std</th>\n",
       "      <th>reldi-normtagner-sr.conllup_extracted.json-Std</th>\n",
       "      <th>set.sr.plus.conllup_extracted.json-Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bertic</td>\n",
       "      <td>0.907610</td>\n",
       "      <td>0.754102</td>\n",
       "      <td>0.682172</td>\n",
       "      <td>0.834696</td>\n",
       "      <td>0.010927</td>\n",
       "      <td>0.045028</td>\n",
       "      <td>0.056300</td>\n",
       "      <td>0.038375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>csebert</td>\n",
       "      <td>0.914205</td>\n",
       "      <td>0.747209</td>\n",
       "      <td>0.726654</td>\n",
       "      <td>0.906812</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>0.021106</td>\n",
       "      <td>0.019947</td>\n",
       "      <td>0.001758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xlm-r-base</td>\n",
       "      <td>0.906450</td>\n",
       "      <td>0.745884</td>\n",
       "      <td>0.599863</td>\n",
       "      <td>0.897582</td>\n",
       "      <td>0.003913</td>\n",
       "      <td>0.019984</td>\n",
       "      <td>0.068809</td>\n",
       "      <td>0.004102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xlm-r-large</td>\n",
       "      <td>0.919204</td>\n",
       "      <td>0.773746</td>\n",
       "      <td>0.770779</td>\n",
       "      <td>0.932916</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.029353</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.002198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xlmrb_bcms-12</td>\n",
       "      <td>0.914144</td>\n",
       "      <td>0.767933</td>\n",
       "      <td>0.764008</td>\n",
       "      <td>0.906272</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.036886</td>\n",
       "      <td>0.016555</td>\n",
       "      <td>0.004063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  hr500k.conllup_extracted.json-Macro F1  \\\n",
       "0         bertic                                0.907610   \n",
       "1        csebert                                0.914205   \n",
       "2     xlm-r-base                                0.906450   \n",
       "3    xlm-r-large                                0.919204   \n",
       "4  xlmrb_bcms-12                                0.914144   \n",
       "\n",
       "   reldi-normtagner-hr.conllup_extracted.json-Macro F1  \\\n",
       "0                                           0.754102     \n",
       "1                                           0.747209     \n",
       "2                                           0.745884     \n",
       "3                                           0.773746     \n",
       "4                                           0.767933     \n",
       "\n",
       "   reldi-normtagner-sr.conllup_extracted.json-Macro F1  \\\n",
       "0                                           0.682172     \n",
       "1                                           0.726654     \n",
       "2                                           0.599863     \n",
       "3                                           0.770779     \n",
       "4                                           0.764008     \n",
       "\n",
       "   set.sr.plus.conllup_extracted.json-Macro F1  \\\n",
       "0                                     0.834696   \n",
       "1                                     0.906812   \n",
       "2                                     0.897582   \n",
       "3                                     0.932916   \n",
       "4                                     0.906272   \n",
       "\n",
       "   hr500k.conllup_extracted.json-Std  \\\n",
       "0                           0.010927   \n",
       "1                           0.001012   \n",
       "2                           0.003913   \n",
       "3                           0.001327   \n",
       "4                           0.000433   \n",
       "\n",
       "   reldi-normtagner-hr.conllup_extracted.json-Std  \\\n",
       "0                                        0.045028   \n",
       "1                                        0.021106   \n",
       "2                                        0.019984   \n",
       "3                                        0.029353   \n",
       "4                                        0.036886   \n",
       "\n",
       "   reldi-normtagner-sr.conllup_extracted.json-Std  \\\n",
       "0                                        0.056300   \n",
       "1                                        0.019947   \n",
       "2                                        0.068809   \n",
       "3                                        0.002844   \n",
       "4                                        0.016555   \n",
       "\n",
       "   set.sr.plus.conllup_extracted.json-Std  \n",
       "0                                0.038375  \n",
       "1                                0.001758  \n",
       "2                                0.004102  \n",
       "3                                0.002198  \n",
       "4                                0.004063  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the 'model_dataset' column into 'model' and 'dataset' columns\n",
    "agg_results[['Model', 'Dataset']] = agg_results['model-dataset'].str.split('-datasets/', n=1, expand=True)\n",
    "\n",
    "# Pivot the DataFrame to the desired structure\n",
    "pivot_agg_results = agg_results.pivot(index='Model', columns='Dataset', values=['Macro F1', 'Std'])\n",
    "\n",
    "# Flatten the column MultiIndex\n",
    "pivot_agg_results.columns = [f'{col[1]}-{col[0]}' for col in pivot_agg_results.columns]\n",
    "\n",
    "# Reset index and display the final DataFrame\n",
    "final_agg_results = pivot_agg_results.reset_index()\n",
    "\n",
    "final_agg_results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "final_agg_results.to_csv(\"aggregated-results-all-models.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Model'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get average micro and macro F1\n",
    "dataset = \"datasets/hr500k.conllup_extracted.json\"\n",
    "\n",
    "# Define the dataset to inspect\n",
    "import matplotlib as plt\n",
    "results[results[\"Dataset\"] == dataset].groupby(\"Model\")[\"Micro F1\"].mean().plot(kind=\"line\", color=\"blue\")\n",
    "results[results[\"Dataset\"] == dataset].groupby(\"Model\")[\"Macro F1\"].mean().plot(kind=\"line\",color=\"orange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataset</th>\n",
       "      <th>Run</th>\n",
       "      <th>datasets/hr500k.conllup_extracted.json</th>\n",
       "      <th>datasets/reldi-normtagner-hr.conllup_extracted.json</th>\n",
       "      <th>datasets/reldi-normtagner-sr.conllup_extracted.json</th>\n",
       "      <th>datasets/set.sr.plus.conllup_extracted.json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bertic-0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bertic-1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>csebert-0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>csebert-1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xlm-r-base-0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xlm-r-base-1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xlm-r-large-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xlm-r-large-1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xlmrb_bcms-12-0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xlmrb_bcms-12-1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>xlmrb_bcms-24-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>xlmrb_bcms-24-1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xlmrb_bcms-36-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>xlmrb_bcms-36-1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>xlmrb_bcms-48-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>xlmrb_bcms-48-1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>xlmrb_bcms-60-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>xlmrb_bcms-60-1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>xlmrb_bcms-72-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>xlmrb_bcms-72-1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>xlmrb_bcms-84-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>xlmrb_bcms-84-1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>xlmrb_bcms-96-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>xlmrb_bcms-96-1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>xlmrl_bcms-12-0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>xlmrl_bcms-12-1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>xlmrl_bcms-18-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>xlmrl_bcms-18-1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>xlmrl_bcms-24-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>xlmrl_bcms-24-1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>xlmrl_bcms-30-0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>xlmrl_bcms-30-1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>xlmrl_bcms-36-0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>xlmrl_bcms-36-1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>xlmrl_bcms-42-0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>xlmrl_bcms-42-1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>xlmrl_bcms-48-0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>xlmrl_bcms-48-1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>xlmrl_bcms-6-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>xlmrl_bcms-6-1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>xlmrl_sl-bcms-12-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>xlmrl_sl-bcms-12-1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>xlmrl_sl-bcms-18-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>xlmrl_sl-bcms-18-1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>xlmrl_sl-bcms-24-0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>xlmrl_sl-bcms-24-1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>xlmrl_sl-bcms-30-0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>xlmrl_sl-bcms-30-1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>xlmrl_sl-bcms-42-0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>xlmrl_sl-bcms-42-1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>xlmrl_sl-bcms-48-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>xlmrl_sl-bcms-48-1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>xlmrl_sl-bcms-6-0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>xlmrl_sl-bcms-6-1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset                 Run  datasets/hr500k.conllup_extracted.json  \\\n",
       "0                  bertic-0                                    0.90   \n",
       "1                  bertic-1                                    0.92   \n",
       "2                 csebert-0                                    0.91   \n",
       "3                 csebert-1                                    0.91   \n",
       "4              xlm-r-base-0                                    0.91   \n",
       "5              xlm-r-base-1                                    0.90   \n",
       "6             xlm-r-large-0                                    0.92   \n",
       "7             xlm-r-large-1                                    0.92   \n",
       "8           xlmrb_bcms-12-0                                    0.91   \n",
       "9           xlmrb_bcms-12-1                                    0.91   \n",
       "10          xlmrb_bcms-24-0                                    0.92   \n",
       "11          xlmrb_bcms-24-1                                    0.92   \n",
       "12          xlmrb_bcms-36-0                                    0.92   \n",
       "13          xlmrb_bcms-36-1                                    0.92   \n",
       "14          xlmrb_bcms-48-0                                    0.92   \n",
       "15          xlmrb_bcms-48-1                                    0.91   \n",
       "16          xlmrb_bcms-60-0                                    0.92   \n",
       "17          xlmrb_bcms-60-1                                    0.92   \n",
       "18          xlmrb_bcms-72-0                                    0.92   \n",
       "19          xlmrb_bcms-72-1                                    0.92   \n",
       "20          xlmrb_bcms-84-0                                    0.92   \n",
       "21          xlmrb_bcms-84-1                                    0.92   \n",
       "22          xlmrb_bcms-96-0                                    0.92   \n",
       "23          xlmrb_bcms-96-1                                    0.92   \n",
       "24          xlmrl_bcms-12-0                                    0.93   \n",
       "25          xlmrl_bcms-12-1                                    0.92   \n",
       "26          xlmrl_bcms-18-0                                    0.92   \n",
       "27          xlmrl_bcms-18-1                                    0.93   \n",
       "28          xlmrl_bcms-24-0                                    0.92   \n",
       "29          xlmrl_bcms-24-1                                    0.93   \n",
       "30          xlmrl_bcms-30-0                                    0.93   \n",
       "31          xlmrl_bcms-30-1                                    0.92   \n",
       "32          xlmrl_bcms-36-0                                    0.93   \n",
       "33          xlmrl_bcms-36-1                                    0.93   \n",
       "34          xlmrl_bcms-42-0                                    0.93   \n",
       "35          xlmrl_bcms-42-1                                    0.93   \n",
       "36          xlmrl_bcms-48-0                                    0.93   \n",
       "37          xlmrl_bcms-48-1                                    0.93   \n",
       "38           xlmrl_bcms-6-0                                    0.92   \n",
       "39           xlmrl_bcms-6-1                                    0.92   \n",
       "40       xlmrl_sl-bcms-12-0                                    0.92   \n",
       "41       xlmrl_sl-bcms-12-1                                    0.93   \n",
       "42       xlmrl_sl-bcms-18-0                                    0.92   \n",
       "43       xlmrl_sl-bcms-18-1                                    0.93   \n",
       "44       xlmrl_sl-bcms-24-0                                    0.93   \n",
       "45       xlmrl_sl-bcms-24-1                                    0.93   \n",
       "46       xlmrl_sl-bcms-30-0                                    0.93   \n",
       "47       xlmrl_sl-bcms-30-1                                    0.93   \n",
       "48       xlmrl_sl-bcms-42-0                                    0.93   \n",
       "49       xlmrl_sl-bcms-42-1                                    0.92   \n",
       "50       xlmrl_sl-bcms-48-0                                    0.92   \n",
       "51       xlmrl_sl-bcms-48-1                                    0.93   \n",
       "52        xlmrl_sl-bcms-6-0                                    0.92   \n",
       "53        xlmrl_sl-bcms-6-1                                    0.93   \n",
       "\n",
       "Dataset  datasets/reldi-normtagner-hr.conllup_extracted.json  \\\n",
       "0                                                     0.79     \n",
       "1                                                     0.72     \n",
       "2                                                     0.73     \n",
       "3                                                     0.76     \n",
       "4                                                     0.76     \n",
       "5                                                     0.73     \n",
       "6                                                     0.79     \n",
       "7                                                     0.75     \n",
       "8                                                      NaN     \n",
       "9                                                      NaN     \n",
       "10                                                     NaN     \n",
       "11                                                     NaN     \n",
       "12                                                     NaN     \n",
       "13                                                     NaN     \n",
       "14                                                     NaN     \n",
       "15                                                     NaN     \n",
       "16                                                     NaN     \n",
       "17                                                     NaN     \n",
       "18                                                     NaN     \n",
       "19                                                     NaN     \n",
       "20                                                     NaN     \n",
       "21                                                     NaN     \n",
       "22                                                     NaN     \n",
       "23                                                     NaN     \n",
       "24                                                     NaN     \n",
       "25                                                     NaN     \n",
       "26                                                     NaN     \n",
       "27                                                     NaN     \n",
       "28                                                     NaN     \n",
       "29                                                     NaN     \n",
       "30                                                     NaN     \n",
       "31                                                     NaN     \n",
       "32                                                     NaN     \n",
       "33                                                     NaN     \n",
       "34                                                     NaN     \n",
       "35                                                     NaN     \n",
       "36                                                     NaN     \n",
       "37                                                     NaN     \n",
       "38                                                     NaN     \n",
       "39                                                     NaN     \n",
       "40                                                     NaN     \n",
       "41                                                     NaN     \n",
       "42                                                     NaN     \n",
       "43                                                     NaN     \n",
       "44                                                     NaN     \n",
       "45                                                     NaN     \n",
       "46                                                     NaN     \n",
       "47                                                     NaN     \n",
       "48                                                     NaN     \n",
       "49                                                     NaN     \n",
       "50                                                     NaN     \n",
       "51                                                     NaN     \n",
       "52                                                     NaN     \n",
       "53                                                     NaN     \n",
       "\n",
       "Dataset  datasets/reldi-normtagner-sr.conllup_extracted.json  \\\n",
       "0                                                     0.64     \n",
       "1                                                     0.72     \n",
       "2                                                     0.71     \n",
       "3                                                     0.74     \n",
       "4                                                     0.65     \n",
       "5                                                     0.55     \n",
       "6                                                     0.77     \n",
       "7                                                     0.77     \n",
       "8                                                      NaN     \n",
       "9                                                      NaN     \n",
       "10                                                     NaN     \n",
       "11                                                     NaN     \n",
       "12                                                     NaN     \n",
       "13                                                     NaN     \n",
       "14                                                     NaN     \n",
       "15                                                     NaN     \n",
       "16                                                     NaN     \n",
       "17                                                     NaN     \n",
       "18                                                     NaN     \n",
       "19                                                     NaN     \n",
       "20                                                     NaN     \n",
       "21                                                     NaN     \n",
       "22                                                     NaN     \n",
       "23                                                     NaN     \n",
       "24                                                     NaN     \n",
       "25                                                     NaN     \n",
       "26                                                     NaN     \n",
       "27                                                     NaN     \n",
       "28                                                     NaN     \n",
       "29                                                     NaN     \n",
       "30                                                     NaN     \n",
       "31                                                     NaN     \n",
       "32                                                     NaN     \n",
       "33                                                     NaN     \n",
       "34                                                     NaN     \n",
       "35                                                     NaN     \n",
       "36                                                     NaN     \n",
       "37                                                     NaN     \n",
       "38                                                     NaN     \n",
       "39                                                     NaN     \n",
       "40                                                     NaN     \n",
       "41                                                     NaN     \n",
       "42                                                     NaN     \n",
       "43                                                     NaN     \n",
       "44                                                     NaN     \n",
       "45                                                     NaN     \n",
       "46                                                     NaN     \n",
       "47                                                     NaN     \n",
       "48                                                     NaN     \n",
       "49                                                     NaN     \n",
       "50                                                     NaN     \n",
       "51                                                     NaN     \n",
       "52                                                     NaN     \n",
       "53                                                     NaN     \n",
       "\n",
       "Dataset  datasets/set.sr.plus.conllup_extracted.json  \n",
       "0                                               0.86  \n",
       "1                                               0.81  \n",
       "2                                               0.91  \n",
       "3                                               0.91  \n",
       "4                                               0.89  \n",
       "5                                               0.90  \n",
       "6                                               0.93  \n",
       "7                                               0.93  \n",
       "8                                                NaN  \n",
       "9                                                NaN  \n",
       "10                                               NaN  \n",
       "11                                               NaN  \n",
       "12                                               NaN  \n",
       "13                                               NaN  \n",
       "14                                               NaN  \n",
       "15                                               NaN  \n",
       "16                                               NaN  \n",
       "17                                               NaN  \n",
       "18                                               NaN  \n",
       "19                                               NaN  \n",
       "20                                               NaN  \n",
       "21                                               NaN  \n",
       "22                                               NaN  \n",
       "23                                               NaN  \n",
       "24                                               NaN  \n",
       "25                                               NaN  \n",
       "26                                               NaN  \n",
       "27                                               NaN  \n",
       "28                                               NaN  \n",
       "29                                               NaN  \n",
       "30                                               NaN  \n",
       "31                                               NaN  \n",
       "32                                               NaN  \n",
       "33                                               NaN  \n",
       "34                                               NaN  \n",
       "35                                               NaN  \n",
       "36                                               NaN  \n",
       "37                                               NaN  \n",
       "38                                               NaN  \n",
       "39                                               NaN  \n",
       "40                                               NaN  \n",
       "41                                               NaN  \n",
       "42                                               NaN  \n",
       "43                                               NaN  \n",
       "44                                               NaN  \n",
       "45                                               NaN  \n",
       "46                                               NaN  \n",
       "47                                               NaN  \n",
       "48                                               NaN  \n",
       "49                                               NaN  \n",
       "50                                               NaN  \n",
       "51                                               NaN  \n",
       "52                                               NaN  \n",
       "53                                               NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results[\"Dataset\"] == dataset].groupby(\"Model\")[\"Macro F1\"].mean().round(2)\n",
    "\n",
    "results[\"Macro F1\"] = results[\"Macro F1\"].round(2)\n",
    "\n",
    "# Pivot the DataFrame to rearrange columns into rows\n",
    "pivot_df = results.pivot(index='Run', columns='Dataset', values='Macro F1')\n",
    "\n",
    "# Reset the index to have 'Model' as a column\n",
    "pivot_df.reset_index(inplace=True)\n",
    "\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the df\n",
    "pivot_df.to_csv(\"ner-results-summary-table.csv\")\n",
    "#pivot_df.to_csv(\"ner-results-summary-table-our-models.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's analyze the df with all the predictions\n",
    "import numpy as np\n",
    "\n",
    "pred_df = pd.read_csv(\"datasets/hr500k.conllup_extracted.json-test_df-with-predictions.csv\", index_col = 0)\n",
    "\n",
    "# Analyze instances where models are wrong\n",
    "pred_df[\"match\"] = np.where(pred_df[\"labels\"] != pred_df[\"y_pred_xlm-r-large_0\"], \"no\", \"yes\")\n",
    "pred_df.match.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Analysis: analysis of summary table of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run</th>\n",
       "      <th>datasets/hr500k.conllup_extracted.json</th>\n",
       "      <th>datasets/reldi-normtagner-hr.conllup_extracted.json</th>\n",
       "      <th>datasets/reldi-normtagner-sr.conllup_extracted.json</th>\n",
       "      <th>datasets/set.sr.plus.conllup_extracted.json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bertic-0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bertic-1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>csebert-0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>csebert-1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xlm-r-base-0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Run  datasets/hr500k.conllup_extracted.json  \\\n",
       "0      bertic-0                                    0.90   \n",
       "1      bertic-1                                    0.92   \n",
       "2     csebert-0                                    0.91   \n",
       "3     csebert-1                                    0.91   \n",
       "4  xlm-r-base-0                                    0.91   \n",
       "\n",
       "   datasets/reldi-normtagner-hr.conllup_extracted.json  \\\n",
       "0                                               0.79     \n",
       "1                                               0.72     \n",
       "2                                               0.73     \n",
       "3                                               0.76     \n",
       "4                                               0.76     \n",
       "\n",
       "   datasets/reldi-normtagner-sr.conllup_extracted.json  \\\n",
       "0                                               0.64     \n",
       "1                                               0.72     \n",
       "2                                               0.71     \n",
       "3                                               0.74     \n",
       "4                                               0.65     \n",
       "\n",
       "   datasets/set.sr.plus.conllup_extracted.json  \n",
       "0                                         0.86  \n",
       "1                                         0.81  \n",
       "2                                         0.91  \n",
       "3                                         0.91  \n",
       "4                                         0.89  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the summary\n",
    "import pandas as pd\n",
    "\n",
    "sum_df = pd.read_csv(\"ner-results-summary-table.csv\", index_col = 0)\n",
    "\n",
    "sum_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
